{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767203aa-33b8-4f16-94e0-ec46614a89a6",
   "metadata": {},
   "source": [
    "#  Descriptive Statistics\n",
    "\n",
    "Introduzione\n",
    "\n",
    "La statistica descrittiva √® una branca della statistica che si occupa di raccogliere, organizzare, analizzare e presentare i dati in modo significativo. A differenza della statistica inferenziale, che si concentra sul fare previsioni basate su un campione di dati, la statistica descrittiva aiuta a comprendere le caratteristiche fondamentali dei dati a disposizione.\n",
    "\n",
    "1. Tipi di Statistica Descrittiva\n",
    "\n",
    "La statistica descrittiva pu√≤ essere suddivisa in tre categorie principali:\n",
    "\n",
    "Misure di tendenza centrale: indicano il valore intorno al quale i dati tendono a concentrarsi.\n",
    "\n",
    "Misure di dispersione: descrivono quanto i dati sono sparsi attorno alla tendenza centrale.\n",
    "\n",
    "Misure di forma: indicano la distribuzione dei dati (asimmetria e curtosi).\n",
    "\n",
    "### üìä **Measures of Central Tendency: Lezione Completa**  \n",
    "\n",
    "Le **misure di tendenza centrale** sono strumenti statistici utilizzati per descrivere un insieme di dati con un solo valore rappresentativo. Sono fondamentali nell'analisi dei dati perch√© forniscono un‚Äôindicazione sulla posizione del \"centro\" di una distribuzione.\n",
    "\n",
    "---\n",
    "## üìå **1. Tipologie di Misure di Tendenza Centrale**\n",
    "Le tre principali misure di tendenza centrale sono:\n",
    "1. **Media (Mean)**\n",
    "2. **Mediana (Median)**\n",
    "3. **Moda (Mode)**\n",
    "\n",
    "Ognuna di queste ha caratteristiche, vantaggi e limiti specifici. Vediamole nel dettaglio.  \n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ **2. Media (Mean)**  \n",
    "La **media aritmetica** √® la somma di tutti i valori divisa per il numero totale di osservazioni.\n",
    "\n",
    "### üìå **Formula della Media**  \n",
    "$$ \n",
    "x\n",
    "Àâ = \\frac{\\sum x_i}{n}\n",
    "$$\n",
    "Dove:\n",
    "\n",
    "ùë•\n",
    "Àâ\n",
    "x\n",
    "Àâ\n",
    "  = media\n",
    "ùë•\n",
    "ùëñ\n",
    "x \n",
    "i\n",
    "‚Äã\n",
    "  = valori dei dati\n",
    "ùëõ\n",
    "n = numero totale di osservazioni\n",
    "‚úÖ Esempio Pratico\n",
    "Supponiamo di avere i seguenti voti di uno studente:  \n",
    "**8, 9, 7, 10, 6**  \n",
    "\n",
    "La media sar√†:  \n",
    "\\[$$\n",
    "\\bar{x} = \\frac{8+9+7+10+6}{5} = \\frac{40}{5} = 8$$\n",
    "\\]\n",
    "\n",
    "üîπ **Pro:** Facile da calcolare, tiene conto di tutti i valori.  \n",
    "üîπ **Contro:** Sensibile ai valori estremi (**outliers**).\n",
    "\n",
    "---\n",
    "## üìâ **3. Mediana (Median)**  \n",
    "La **mediana** √® il valore centrale di un insieme di dati ordinati. Se il numero di osservazioni √® pari, la mediana √® la media dei due valori centrali.\n",
    "\n",
    "### ‚úÖ **Esempio 1 (Numero Dispari di Osservazioni)**  \n",
    "Dati: **3, 5, 7, 9, 11**  \n",
    "La mediana √® **7** perch√© √® il valore centrale.\n",
    "\n",
    "### ‚úÖ **Esempio 2 (Numero Pari di Osservazioni)**  \n",
    "Dati: **2, 4, 6, 8, 10, 12**  \n",
    "I due valori centrali sono **6** e **8**, quindi la mediana √®:  \n",
    "\\[\n",
    "\\frac{6+8}{2} = 7\n",
    "\\]\n",
    "\n",
    "üîπ **Pro:** Non √® influenzata dai valori estremi.  \n",
    "üîπ **Contro:** Non tiene conto di tutti i valori nel calcolo.\n",
    "\n",
    "---\n",
    "## üéØ **4. Moda (Mode)**  \n",
    "La **moda** √® il valore che compare pi√π frequentemente in un dataset.  \n",
    "\n",
    "### ‚úÖ **Esempio 1**  \n",
    "Dati: **2, 3, 3, 5, 7, 3, 8**  \n",
    "La moda √® **3** perch√© appare pi√π volte.\n",
    "\n",
    "### ‚úÖ **Esempio 2 (Distribuzione Bimodale)**  \n",
    "Dati: **4, 4, 6, 6, 8, 9**  \n",
    "Qui abbiamo due valori con la stessa frequenza massima: **4 e 6**.  \n",
    "‚û°Ô∏è La distribuzione √® **bimodale**.\n",
    "\n",
    "üîπ **Pro:** Utile per dati categorici e distribuzioni irregolari.  \n",
    "üîπ **Contro:** Pu√≤ non esistere o esserci pi√π di una moda.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **5. Confronto tra Media, Mediana e Moda**\n",
    "| Propriet√†  | Media | Mediana | Moda |\n",
    "|------------|------|---------|------|\n",
    "| **Uso tipico** | Dati numerici continui | Dati numerici con outliers | Dati categorici o distribuzioni non normali |\n",
    "| **Sensibile agli outliers?** | ‚úÖ S√¨ | ‚ùå No | ‚ùå No |\n",
    "| **Facilit√† di calcolo** | ‚úÖ Facile | ‚úÖ Facile | ‚ö†Ô∏è A volte complesso |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **6. Quando Usare Ciascuna Misura?**\n",
    "- **Media**: Quando i dati sono distribuiti in modo normale e non ci sono outliers.  \n",
    "- **Mediana**: Quando ci sono outliers o la distribuzione √® asimmetrica.  \n",
    "- **Moda**: Quando analizziamo dati categorici (es. il colore pi√π scelto da un campione di persone).\n",
    "\n",
    "---\n",
    "\n",
    "## üîé **7. Esempio Pratico in Python**\n",
    "Vediamo come calcolare queste misure con Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Dataset\n",
    "dati = [8, 9, 7, 10, 6, 100]  # Notiamo un outlier (100)\n",
    "\n",
    "# Calcolo delle misure di tendenza centrale\n",
    "media = np.mean(dati)\n",
    "mediana = np.median(dati)\n",
    "moda = stats.mode(dati, keepdims=True).mode[0]\n",
    "\n",
    "print(f\"Media: {media}\")\n",
    "print(f\"Mediana: {mediana}\")\n",
    "print(f\"Moda: {moda}\")\n",
    "```\n",
    "\n",
    "üîπ **Output:**\n",
    "```\n",
    "Media: 23.333\n",
    "Mediana: 8.5\n",
    "Moda: 6\n",
    "```\n",
    "üìå **Nota:** L'outlier (100) ha distorto la media, mentre la mediana rimane pi√π stabile!\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **8. Conclusione**\n",
    "Le **misure di tendenza centrale** sono fondamentali per riassumere i dati in modo efficace. La scelta della misura giusta dipende dal contesto e dalla distribuzione dei dati.\n",
    "\n",
    "## üìä **Measures of Dispersion: Concetti, Formule ed Esempi**  \n",
    "\n",
    "Le **misure di dispersione** (o **variabilit√†**) descrivono quanto i dati siano sparpagliati o distanti tra loro rispetto a una misura di tendenza centrale (come la media o la mediana). Sono fondamentali per capire la distribuzione di un dataset.  \n",
    "\n",
    "### üîπ **Perch√© sono importanti?**\n",
    "- Permettono di confrontare la variabilit√† di diversi dataset.\n",
    "- Aiutano a identificare la presenza di valori anomali (outlier).\n",
    "- Sono essenziali per interpretare correttamente i risultati statistici.\n",
    "\n",
    "## üöÄ **Tipologie di Measures of Dispersion**  \n",
    "\n",
    "### **1Ô∏è‚É£ Range (Intervallo)**\n",
    "üìå **Definizione**: √à la differenza tra il valore massimo e il valore minimo di un dataset.  \n",
    "üìå **Formula**:  \n",
    "\\[$$\n",
    "\\text{Range} = \\max(X) - \\min(X)$$\n",
    "\\]\n",
    "üìå **Esempio**:  \n",
    "Dati: \\($$ X = \\{3, 7, 8, 5, 12\\} \\)  $$\n",
    "\\[$$\n",
    "\\text{Range} = 12 - 3 = 9$$\n",
    "\\]\n",
    "üìå **Limiti**:\n",
    "- Dipende solo dai valori estremi (non considera la distribuzione dei dati).\n",
    "- Sensibile agli **outlier**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2Ô∏è‚É£ Variance (Varianza)**\n",
    "üìå **Definizione**: Misura la dispersione dei dati rispetto alla loro media.  \n",
    "üìå **Formula per la popolazione**:  \n",
    "\\[$$\n",
    "\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}$$\n",
    "\\]\n",
    "üìå **Formula per il campione**:  \n",
    "\\[$$\n",
    "s^2 = \\frac{\\sum (X_i - \\bar{X})^2}{n-1}$$\n",
    "\\]\n",
    "Dove:\n",
    "- \\($$ \\sigma^2 $$\\) = varianza della popolazione  \n",
    "- \\($$ s^2 $$\\) = varianza del campione  \n",
    "- \\( $$\\mu $$\\) = media della popolazione  \n",
    "- \\( $$\\bar{X}$$ \\) = media del campione  \n",
    "- \\( $$N $$\\), \\( $$n $$\\) = dimensione della popolazione/campione  \n",
    "\n",
    "üìå **Esempio** (per un campione):  \n",
    "Dati: \\( $$X = \\{4, 8, 6\\} $$\\)  \n",
    "1. **Media**:  \n",
    "\\[$$\n",
    "\\bar{X} = \\frac{4+8+6}{3} = 6$$\n",
    "\\]\n",
    "2. **Scarti quadrati dalla media**:  \n",
    "\\[$$\n",
    "(4-6)^2 = 4, \\quad (8-6)^2 = 4, \\quad (6-6)^2 = 0\n",
    "$$\\]\n",
    "3. **Varianza**:  \n",
    "\\[$$\n",
    "s^2 = \\frac{4+4+0}{3-1} = \\frac{8}{2} = 4\n",
    "$$\\]\n",
    "\n",
    "üìå **Pro e Contro**:\n",
    "‚úÖ Usa tutti i dati ‚Üí pi√π affidabile del range  \n",
    "‚ùå L‚Äôunit√† di misura √® elevata al quadrato  \n",
    "\n",
    "---\n",
    "\n",
    "### **3Ô∏è‚É£ Standard Deviation (Deviazione standard)**\n",
    "üìå **Definizione**: Radice quadrata della varianza, riporta la dispersione all‚Äôunit√† originale dei dati.  \n",
    "üìå **Formule**:\n",
    "\\[$$\n",
    "\\sigma = \\sqrt{\\sigma^2} \\quad \\text{(popolazione)}, \\quad s = \\sqrt{s^2} \\quad \\text{(campione)}\n",
    "$$\\]\n",
    "üìå **Esempio**:  \n",
    "Se la varianza \\( $$s^2 = 4$$ \\), allora la deviazione standard √®:  \n",
    "\\[$$\n",
    "s = \\sqrt{4} = 2\n",
    "$$\\]\n",
    "üìå **Vantaggi**:\n",
    "- √à nella stessa unit√† di misura dei dati originali.\n",
    "- Facilmente interpretabile.\n",
    "\n",
    "---\n",
    "\n",
    "### **4Ô∏è‚É£ Interquartile Range (IQR - Intervallo Interquartile)**\n",
    "üìå **Definizione**: Misura la dispersione considerando solo i dati centrali, eliminando gli outlier.  \n",
    "üìå **Formula**:  \n",
    "\\[$$\n",
    "IQR = Q3 - Q1\n",
    "$$\\]\n",
    "Dove:\n",
    "- **Q1 (Primo Quartile)**: il 25% dei dati √® inferiore a questo valore.\n",
    "- **Q3 (Terzo Quartile)**: il 75% dei dati √® inferiore a questo valore.\n",
    "\n",
    "üìå **Esempio**:  \n",
    "Dati ordinati: \\( $$X = \\{1, 3, 5, 7, 9\\} $$\\)  \n",
    "- **Q1** = 3  \n",
    "- **Q3** = 7  \n",
    "\\[$$\n",
    "IQR = 7 - 3 = 4\n",
    "$$\\]\n",
    "üìå **Vantaggi**:\n",
    "- Resistente agli outlier.  \n",
    "- Utile per capire la distribuzione centrale dei dati.\n",
    "\n",
    "---\n",
    "\n",
    "### **5Ô∏è‚É£ Coefficient of Variation (Coefficiente di Variazione - CV)**\n",
    "üìå **Definizione**: Misura la dispersione relativa alla media, utile per confrontare dati con scale diverse.  \n",
    "üìå **Formula**:  \n",
    "\\[$$\n",
    "CV = \\frac{\\sigma}{\\mu} \\times 100\\%\n",
    "$$\\]\n",
    "üìå **Esempio**:  \n",
    "Se \\( $$\\mu = 50 $$\\) e \\( $$\\sigma = 5$$ \\), allora  \n",
    "\\[$$\n",
    "CV = \\frac{5}{50} \\times 100 = 10\\%\n",
    "$$\\]\n",
    "üìå **Vantaggi**:\n",
    "- Permette di confrontare dispersioni tra dataset con medie diverse.\n",
    "\n",
    "---\n",
    "\n",
    "## üî• **Riepilogo delle Measures of Dispersion**\n",
    "| Misura | Formula | Sensibile agli outlier? | Unit√† di misura |\n",
    "|--------|---------|----------------|--------------|\n",
    "| **Range** | \\($ \\max(X) - \\min(X) $\\) | ‚úÖ S√¨ | Stessa dei dati |\n",
    "| **Varianza** | \\( $\\frac{\\sum (X_i - \\mu)^2}{N} $\\) | ‚úÖ S√¨ | Quadrata rispetto ai dati |\n",
    "| **Dev. Standard** | \\($ \\sqrt{\\sigma^2} $\\) | ‚úÖ S√¨ | Stessa dei dati |\n",
    "| **IQR** | \\( $Q3 - Q1 $\\) | ‚ùå No | Stessa dei dati |\n",
    "| **CV** | \\( $\\frac{\\sigma}{\\mu} \\times 100\\% $\\) | ‚úÖ S√¨ | Percentuale |\n",
    "\n",
    "---\n",
    "\n",
    "## üìå **Quando usare quale misura?**\n",
    "- **Range** ‚Üí Quando serve una misura semplice, ma con dati senza outlier.\n",
    "- **Varianza & Deviazione standard** ‚Üí Quando servono misure precise e dettagliate della dispersione.\n",
    "- **IQR** ‚Üí Quando i dati contengono outlier e vogliamo una misura robusta.\n",
    "- **CV** ‚Üí Quando vogliamo confrontare la dispersione di dataset con unit√† di misura diverse.\n",
    "\n",
    "---\n",
    "## **Lezione Dettagliata sulle Frequency Distributions**  \n",
    "\n",
    "### **1. Introduzione alle Distribuzioni di Frequenza**  \n",
    "Una **distribuzione di frequenza** √® un metodo per organizzare i dati in modo che sia possibile vedere con quale frequenza ciascun valore o intervallo di valori appare in un dataset. √à una delle tecniche fondamentali nell'analisi dei dati e nella statistica descrittiva.\n",
    "\n",
    "### **2. Tipi di Frequenze**  \n",
    "Quando analizziamo un dataset, possiamo calcolare diverse tipologie di frequenze:  \n",
    "- **Frequenza Assoluta (fi)**: il numero di volte in cui un valore specifico appare nei dati.  \n",
    "- **Frequenza Relativa (fr)**: la frequenza assoluta divisa per il numero totale di osservazioni.  \n",
    "  \\[$\n",
    "  f_r = \\frac{f_i}{N}\n",
    "  $\\]\n",
    "- **Frequenza Percentuale**: la frequenza relativa moltiplicata per 100.  \n",
    "  \\[$\n",
    "  f_p = f_r \\times 100\n",
    "  $\\]\n",
    "- **Frequenza Cumulata**: la somma progressiva delle frequenze assolute. Indica quante osservazioni hanno un valore uguale o inferiore a un certo limite.  \n",
    "- **Frequenza Cumulata Relativa**: la frequenza cumulata divisa per il totale delle osservazioni.  \n",
    "\n",
    "### **3. Creazione di una Distribuzione di Frequenza**  \n",
    "#### **3.1 Distribuzione per dati discreti**  \n",
    "Esempio: Un dataset con il numero di caff√® bevuti al giorno da 20 persone:\n",
    "\n",
    "| Caff√® al giorno | Frequenza assoluta (fi) |\n",
    "|-----------------|-------------------------|\n",
    "| 0              | 3                         |\n",
    "| 1              | 5                         |\n",
    "| 2              | 6                         |\n",
    "| 3              | 4                         |\n",
    "| 4              | 2                         |\n",
    "\n",
    "#### **3.2 Distribuzione per dati continui (creazione di classi)**  \n",
    "Per dati continui, i valori devono essere raggruppati in classi.  \n",
    "Passaggi:\n",
    "1. **Determinare l‚Äôampiezza della classe**  \n",
    "   \\[$\n",
    "   \\text{Ampiezza} = \\frac{\\text{Valore massimo} - \\text{Valore minimo}}{\\text{Numero di classi desiderato}}\n",
    "   $\\]\n",
    "2. **Creare le classi** (intervalli di valori)  \n",
    "3. **Contare le osservazioni in ogni classe**  \n",
    "\n",
    "Esempio: Supponiamo di avere 50 dati sull'et√† dei partecipanti a un sondaggio e vogliamo creare una tabella di distribuzione di frequenza con 5 classi.\n",
    "\n",
    "| Classe (Et√†) | Frequenza assoluta (fi) | Frequenza relativa (fr) | Frequenza cumulata (Fc) |\n",
    "|-------------|-------------------------|-------------------------|-------------------------|\n",
    "| 20 - 30    | 8                         | 0.16                     | 8                      |\n",
    "| 30 - 40    | 12                        | 0.24                     | 20                     |\n",
    "| 40 - 50    | 15                        | 0.30                     | 35                     |\n",
    "| 50 - 60    | 9                         | 0.18                     | 44                     |\n",
    "| 60 - 70    | 6                         | 0.12                     | 50                     |\n",
    "\n",
    "### **4. Rappresentazione Grafica**\n",
    "Una volta creata la distribuzione di frequenza, possiamo visualizzarla in diversi modi:\n",
    "- **Istogramma**: rappresenta le classi con barre la cui altezza √® proporzionale alla frequenza.\n",
    "- **Poligono di frequenza**: collega i punti centrali delle barre di un istogramma con linee.\n",
    "- **Grafico a barre**: utile per dati discreti.\n",
    "- **Curva di frequenza cumulata**: mostra la crescita della frequenza cumulata.\n",
    "\n",
    "### **5. Applicazione in Python**\n",
    "Possiamo calcolare e visualizzare distribuzioni di frequenza con **Pandas e Matplotlib**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esempio di dati\n",
    "data = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 40, 30, 50, 45, 55, 35, 60, 40, 30]\n",
    "\n",
    "# Creare intervalli di classi\n",
    "bins = [20, 30, 40, 50, 60, 70]\n",
    "labels = [\"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\"]\n",
    "\n",
    "# Creare tabella di frequenza\n",
    "df = pd.DataFrame(data, columns=[\"Et√†\"])\n",
    "df[\"Classe\"] = pd.cut(df[\"Et√†\"], bins=bins, labels=labels, right=False)\n",
    "freq_table = df[\"Classe\"].value_counts().sort_index()\n",
    "\n",
    "# Visualizzazione\n",
    "plt.bar(freq_table.index, freq_table.values, color='skyblue')\n",
    "plt.xlabel(\"Classi di et√†\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "plt.title(\"Distribuzione di frequenza dell'et√†\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **6. Conclusione**  \n",
    "Le distribuzioni di frequenza sono essenziali per riassumere e comprendere i dati, sia che si tratti di fenomeni semplici come il numero di caff√® bevuti, sia che si tratti di dati sanitari. Con strumenti come Python e librerie come Pandas, possiamo automatizzare l'analisi e la rappresentazione grafica in modo efficace.\n",
    "\n",
    "## **Introduzione alla Probabilit√†**\n",
    "\n",
    "La **probabilit√†** √® un ramo della matematica che quantifica l'incertezza e misura la possibilit√† che un evento si verifichi. Viene espressa come un numero compreso tra 0 e 1, dove:\n",
    "- **0** significa che l'evento √® impossibile.\n",
    "- **1** significa che l'evento √® certo.\n",
    "\n",
    "La probabilit√† viene utilizzata in molteplici ambiti, dalla statistica alla scienza dei dati, dall'ingegneria alla finanza, e persino nella medicina e nell'intelligenza artificiale.\n",
    "\n",
    "---\n",
    "\n",
    "### **Concetti Chiave**\n",
    "Per comprendere la probabilit√†, √® necessario familiarizzare con alcuni concetti fondamentali.\n",
    "\n",
    "### **1. Esperimento (Experiment)**\n",
    "Un **esperimento** √® un'azione o un processo che produce un risultato osservabile. Pu√≤ essere:\n",
    "- **Deterministico**: sempre lo stesso risultato (es. mescolare acqua e zucchero).\n",
    "- **Casuale (o aleatorio)**: pu√≤ avere pi√π risultati possibili (es. lanciare un dado, estrarre una carta da un mazzo).\n",
    "\n",
    "üîπ **Esempio**: Lanciare un dado a sei facce √® un esperimento casuale, perch√© ogni lancio pu√≤ dare un numero da 1 a 6.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Esito (Outcome)**\n",
    "Un **esito** √® un singolo possibile risultato di un esperimento.\n",
    "\n",
    "üîπ **Esempio**: Se lanciamo un dado e otteniamo \"4\", questo √® un esito.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Spazio Campionario (Sample Space)**\n",
    "Lo **spazio campionario** (o universo) √® l'insieme di tutti i possibili esiti di un esperimento.\n",
    "\n",
    "üîπ **Esempi**:\n",
    "- **Lancio di un dado**: \\( $S = \\{1, 2, 3, 4, 5, 6\\} $\\)\n",
    "- **Lancio di due dadi**: \\( $S = \\{(1,1), (1,2), (1,3), ..., (6,6)\\}$ \\), con 36 possibili risultati.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Evento (Event)**\n",
    "Un **evento** √® un sottoinsieme dello spazio campionario, cio√® un gruppo di uno o pi√π esiti.\n",
    "\n",
    "üîπ **Esempi**:\n",
    "- Nel lancio di un dado, l'evento **\"ottenere un numero pari\"** √®: \\($ A = \\{2, 4, 6\\}$ \\).\n",
    "- Nell'estrazione di una carta da un mazzo, l'evento **\"pescare un asso\"** √®: \\($ A = \\{\\text{Asso di cuori}, \\text{Asso di quadri}, \\text{Asso di picche}, \\text{Asso di fiori}\\} $\\).\n",
    "\n",
    "Se un evento contiene un solo esito (es. ottenere un \"3\" in un dado), si chiama **evento elementare**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Probabilit√† di un Evento**\n",
    "La **probabilit√†** di un evento \\($ A $\\) √® definita come:\n",
    "\n",
    "\\[$\n",
    "P(A) = \\frac{\\text{Numero di esiti favorevoli ad A}}{\\text{Numero totale di esiti possibili}}\n",
    "$\\]\n",
    "\n",
    "üîπ **Esempio**: Nel lancio di un dado, la probabilit√† di ottenere un numero pari √®:\n",
    "\n",
    "\\[$\n",
    "P(A) = \\frac{3}{6} = \\frac{1}{2} = 0.5\n",
    "$\\]\n",
    "\n",
    "---\n",
    "\n",
    "## **Tipologie di Probabilit√†**\n",
    "Ci sono tre approcci principali alla probabilit√†:\n",
    "\n",
    "1. **Classica** (o definizione di Laplace)  \n",
    "   Si applica quando tutti gli esiti sono equiprobabili, cio√® hanno la stessa possibilit√† di verificarsi.\n",
    "\n",
    "   \\[$   P(A) = \\frac{\\text{Numero di esiti favorevoli}}{\\text{Numero totale di esiti possibili}}\n",
    "   $\\]\n",
    "\n",
    "   *Esempio*: La probabilit√† di ottenere testa in un lancio di moneta √® \\( P(A) = \\frac{1}{2} \\).\n",
    "\n",
    "2. **Frequentista**  \n",
    "   Si basa sulla ripetizione dell'esperimento. Se ripetiamo molte volte un esperimento, la probabilit√† di un evento √® la frequenza relativa con cui si verifica.\n",
    "\n",
    "   \\[$\n",
    "   P(A) \\approx \\frac{\\text{Numero di volte in cui A si verifica}}{\\text{Numero totale di prove}}\n",
    "   $\\]\n",
    "\n",
    "   *Esempio*: Se lanci una moneta 1000 volte e ottieni testa 510 volte, la probabilit√† stimata √® \\( P(A) = \\frac{510}{1000} = 0.51 \\).\n",
    "\n",
    "3. **Soggettiva**  \n",
    "   Basata su opinioni personali e stime. Spesso usata in scenari con incertezza elevata, come previsioni economiche o diagnosi mediche.\n",
    "\n",
    "---\n",
    "\n",
    "## **Propriet√† della Probabilit√†**\n",
    "- **0 ‚â§ P(A) ‚â§ 1** per ogni evento \\( A \\).\n",
    "- **P(S) = 1**, la probabilit√† dell'intero spazio campionario √® 1 (un evento certo).\n",
    "- **P(‚àÖ) = 0**, la probabilit√† di un evento impossibile √® 0.\n",
    "- **Se due eventi sono complementari (cio√® A e il suo complementare ƒÄ), allora**:\n",
    "\n",
    "  \\[$\n",
    "  P(A) + P(\\overline{A}) = 1\n",
    "  $\\]\n",
    "\n",
    "  *Esempio*: Se la probabilit√† di pioggia domani √® 0.3, la probabilit√† che non piova √® 0.7.\n",
    "\n",
    "---\n",
    "\n",
    "## **Esercizio Pratico**\n",
    "### **Domanda**  \n",
    "Se peschi una carta da un mazzo di 52 carte, qual √® la probabilit√† di pescare una carta di cuori?\n",
    "\n",
    "### **Soluzione**\n",
    "- Lo spazio campionario \\( S \\) ha 52 carte.\n",
    "- Ci sono 13 carte di cuori.\n",
    "- Probabilit√† di pescare una carta di cuori:\n",
    "\n",
    "  \\[$\n",
    "  P(A) = \\frac{13}{52} = \\frac{1}{4} = 0.25\n",
    "  $\\]\n",
    "\n",
    "\n",
    "## üìö **Lezione Dettagliata sulle Regole di Probabilit√†**  \n",
    "\n",
    "La probabilit√† √® la branca della matematica che studia il verificarsi di eventi in condizioni di incertezza. In questa lezione approfondiremo le principali regole della probabilit√† e il loro utilizzo pratico.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **1. Concetti Fondamentali**\n",
    "1. **Spazio campionario (\\(\\Omega\\))**: l'insieme di tutti i possibili risultati di un esperimento casuale.  \n",
    "   - Esempio: nel lancio di un dado a 6 facce, lo spazio campionario √® \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n",
    "\n",
    "2. **Evento (\\(A\\))**: un sottoinsieme dello spazio campionario, ovvero uno o pi√π risultati possibili.  \n",
    "   - Esempio: nel lancio di un dado, l'evento \"ottenere un numero pari\" √® \\(A = \\{2, 4, 6\\}\\).\n",
    "\n",
    "3. **Probabilit√† di un evento (\\(P(A)\\))**: misura numerica dell‚Äôincertezza di un evento. Se tutti gli esiti sono ugualmente probabili, si calcola come:\n",
    "   \\[$\n",
    "   P(A) = \\frac{\\text{numero di casi favorevoli a } A}{\\text{numero di casi totali nello spazio campionario}}\n",
    "   $\\]\n",
    "\n",
    "   - Esempio: nel lancio di un dado, la probabilit√† di ottenere un numero pari √®:\n",
    "     \\[$\n",
    "     P(A) = \\frac{3}{6} = 0.5\n",
    "     $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **2. Propriet√† Fondamentali della Probabilit√†**\n",
    "1. **Regola dell‚Äôintervallo della probabilit√†**: per ogni evento \\( A \\), la probabilit√† √® compresa tra 0 e 1:\n",
    "   \\[$\n",
    "   0 \\leq P(A) \\leq 1\n",
    "   $\\]\n",
    "   - \\($ P(A) = 0 $\\) significa che l'evento √® impossibile.\n",
    "   - \\( $P(A) = 1 $\\) significa che l'evento √® certo.\n",
    "\n",
    "2. **Probabilit√† dell'evento complementare**: se \\($ A $\\) √® un evento, allora il suo complemento \\($ A^c $\\) √® l'insieme degli eventi che non appartengono ad \\($ A $\\).  \n",
    "   La relazione tra \\( $A $\\) e \\($ A^c$ \\) √®:\n",
    "   \\[$\n",
    "   P(A^c) = 1 - P(A)\n",
    "   $\\]\n",
    "   - Esempio: la probabilit√† di NON ottenere un numero pari lanciando un dado √®:\n",
    "     \\[$\n",
    "     P(A^c) = 1 - P(A) = 1 - 0.5 = 0.5\n",
    "     $\\]\n",
    "\n",
    "3. **Additivit√† della probabilit√† per eventi mutuamente esclusivi**: se due eventi \\( A \\) e \\( B \\) sono **mutuamente esclusivi** (cio√® non possono verificarsi insieme), allora:\n",
    "   \\[$\n",
    "   P(A \\cup B) = P(A) + P(B)\n",
    "   $\\]\n",
    "   - Esempio: nel lancio di un dado, la probabilit√† di ottenere un 2 o un 3 √®:\n",
    "     \\[$\n",
    "     P(\\{2\\} \\cup \\{3\\}) = P(2) + P(3) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = 0.333\n",
    "     $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **3. Regola della Probabilit√† Totale**\n",
    "Se un evento \\( A \\) pu√≤ avvenire in modi diversi, allora la sua probabilit√† totale si ottiene sommando le probabilit√† dei singoli modi in cui pu√≤ verificarsi.\n",
    "\n",
    "\\[$\n",
    "P(A) = P(A \\cap B) + P(A \\cap B^c)\n",
    "$\\]\n",
    "\n",
    "- Esempio: Supponiamo di avere una classe con 60% di studenti maschi e 40% di studentesse. Il 30% dei maschi e il 50% delle femmine indossa gli occhiali.  \n",
    "  Qual √® la probabilit√† che uno studente scelto a caso indossi gli occhiali?\n",
    "  \\[$\n",
    "  P(G) = P(G | M) P(M) + P(G | F) P(F) = (0.3 \\times 0.6) + (0.5 \\times 0.4) = 0.18 + 0.2 = 0.38\n",
    "  $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **4. Regola del Prodotto (Probabilit√† Condizionata)**\n",
    "La **probabilit√† condizionata** misura la probabilit√† che un evento \\( A \\) si verifichi, dato che sappiamo che si √® verificato un altro evento \\( B \\):\n",
    "\n",
    "\\[$\n",
    "P(A | B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$\\]\n",
    "\n",
    "- Esempio: se il 10% delle persone in un'azienda sono manager (\\(P(M) = 0.1\\)) e il 70% dei manager ha una laurea (\\(P(L | M) = 0.7\\)), qual √® la probabilit√† che una persona sia sia manager che laureata?\n",
    "  \\[$\n",
    "  P(M \\cap L) = P(L | M) P(M) = 0.7 \\times 0.1 = 0.07\n",
    "  $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **5. Regola della Moltiplicazione (Indipendenza)**\n",
    "Due eventi \\( A \\) e \\( B \\) sono **indipendenti** se il verificarsi di uno non influenza la probabilit√† dell'altro, ovvero:\n",
    "\n",
    "\\[$\n",
    "P(A \\cap B) = P(A) P(B)\n",
    "$\\]\n",
    "\n",
    "- Esempio: Se lanciamo una moneta e un dado, la probabilit√† di ottenere \"Testa\" (\\(P(T) = 0.5\\)) e un 6 (\\(P(6) = 1/6\\)) √®:\n",
    "  \\[$\n",
    "  P(T \\cap 6) = P(T) P(6) = 0.5 \\times \\frac{1}{6} = \\frac{1}{12}\n",
    "  $\\]\n",
    "\n",
    "Se invece gli eventi non sono indipendenti, usiamo la regola pi√π generale:\n",
    "\\[$\n",
    "P(A \\cap B) = P(A | B) P(B)\n",
    "$\\]\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **6. Teorema di Bayes**\n",
    "Il **Teorema di Bayes** permette di calcolare la probabilit√† di un evento basandosi su informazioni condizionate:\n",
    "\n",
    "\\[$\n",
    "P(A | B) = \\frac{P(B | A) P(A)}{P(B)}\n",
    "$\\]\n",
    "\n",
    "- Esempio: Supponiamo che il 2% della popolazione abbia una malattia (\\(P(M) = 0.02\\)). Un test diagnostico ha il 95% di accuratezza (\\(P(T | M) = 0.95\\)), ma ha anche un 5% di falsi positivi (\\(P(T | M^c) = 0.05\\)).  \n",
    "  Se una persona risulta positiva al test, qual √® la probabilit√† che sia effettivamente malata?\n",
    "\n",
    "  \\[$\n",
    "  P(M | T) = \\frac{P(T | M) P(M)}{P(T | M) P(M) + P(T | M^c) P(M^c)}\n",
    "  $\\]\n",
    "\n",
    "  \\[$  = \\frac{(0.95 \\times 0.02)}{(0.95 \\times 0.02) + (0.05 \\times 0.98)}\n",
    "  $\\]\n",
    "\n",
    "  \\[$\n",
    "  = \\frac{0.019}{0.019 + 0.049} = \\frac{0.019}{0.068} \\approx 0.28\n",
    "  $\\]\n",
    "\n",
    "  Quindi, nonostante il test sia positivo, la probabilit√† che la persona sia effettivamente malata √® solo il 28%!\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Conclusione**\n",
    "Le regole della probabilit√† sono strumenti fondamentali in Data Science, Machine Learning e Medicina. Comprendere questi concetti aiuta a interpretare meglio i dati e prendere decisioni pi√π informate.\n",
    "\n",
    "\n",
    "### La **probabilit√† condizionata** \n",
    "\n",
    "√® un concetto fondamentale in probabilit√† che ci permette di calcolare la probabilit√† che un evento si verifichi dato che un altro evento √® gi√† accaduto. Si scrive matematicamente come \\( P(A|B) \\), che rappresenta la probabilit√† dell'evento \\( A \\) dato che l'evento \\( B \\) si √® verificato.\n",
    "\n",
    "### Formula della Probabilit√† Condizionata\n",
    "\n",
    "La formula per calcolare la probabilit√† condizionata di \\( A \\) dato \\( B \\) √®:\n",
    "\n",
    "\\[$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\($ P(A|B)$ \\) √® la probabilit√† che \\( A \\) si verifichi dato che \\( B \\) √® accaduto.\n",
    "- \\( $P(A \\cap B)$ \\) √® la probabilit√† che entrambi gli eventi \\( A \\) e \\( B \\) si verifichino contemporaneamente.\n",
    "- \\($ P(B)$ \\) √® la probabilit√† che l'evento \\( B \\) si verifichi (nota che \\( P(B) > 0 \\)).\n",
    "\n",
    "### Significato della Formula\n",
    "La formula dice che per calcolare la probabilit√† di \\( A \\) condizionata su \\( B \\), dobbiamo:\n",
    "1. Trovare la probabilit√† che entrambi gli eventi \\( A \\) e \\( B \\) si verifichino simultaneamente.\n",
    "2. Dividere questa probabilit√† per la probabilit√† che l'evento \\( B \\) si verifichi.\n",
    "\n",
    "### Esempio di Probabilit√† Condizionata\n",
    "\n",
    "Immagina di lanciare un dado a sei facce. Definiamo gli eventi:\n",
    "- \\( A \\): il numero uscito √® pari.\n",
    "- \\( B \\): il numero uscito √® maggiore di 2.\n",
    "\n",
    "Se vogliamo calcolare \\( P(A|B) \\), ovvero la probabilit√† che il numero sia pari dato che √® maggiore di 2, possiamo procedere come segue:\n",
    "\n",
    "- L'insieme di \\( B \\) (i numeri maggiori di 2) √®: \\( \\{3, 4, 5, 6\\} \\).\n",
    "- L'insieme di \\( A \\cap B \\) (i numeri che sono sia pari che maggiori di 2) √®: \\( \\{4, 6\\} \\).\n",
    "\n",
    "Ora possiamo applicare la formula:\n",
    "\n",
    "\\[$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{6}}{\\frac{4}{6}} = \\frac{2}{4} = 0.5\n",
    "$\\]\n",
    "\n",
    "Quindi, la probabilit√† di ottenere un numero pari dato che √® maggiore di 2 √® 0.5.\n",
    "\n",
    "### Legge di Bayes\n",
    "\n",
    "Una delle applicazioni pi√π importanti della probabilit√† condizionata √® la **legge di Bayes**, che permette di calcolare la probabilit√† di un evento \\( B \\) dato un altro evento \\( A \\). La formula di Bayes √®:\n",
    "\n",
    "\\[$\n",
    "P(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( P(B|A) \\) √® la probabilit√† che \\( B \\) si verifichi dato che \\( A \\) √® accaduto.\n",
    "- \\( P(A|B) \\) √® la probabilit√† che \\( A \\) si verifichi dato che \\( B \\) √® accaduto.\n",
    "- \\( P(B) \\) √® la probabilit√† di \\( B \\).\n",
    "- \\( P(A) \\) √® la probabilit√† di \\( A \\).\n",
    "\n",
    "La legge di Bayes √® fondamentale in molti campi, tra cui l'intelligenza artificiale, la statistica e la medicina, per aggiornare le probabilit√† a mano a mano che si ottengono nuovi dati.\n",
    "\n",
    "### Applicazioni della Probabilit√† Condizionata\n",
    "La probabilit√† condizionata ha numerose applicazioni pratiche, come ad esempio:\n",
    "1. **Diagnosi medica**: Calcolare la probabilit√† che un paziente abbia una malattia dato che presenta un certo sintomo.\n",
    "2. **Machine Learning**: Viene utilizzata per la classificazione, come nel caso del **Naive Bayes**, che √® un algoritmo basato sulla probabilit√† condizionata.\n",
    "3. **Reti Bayesian**: Sono modelli probabilistici che rappresentano variabili casuali e le loro probabilit√† condizionate.\n",
    "\n",
    "### Propriet√† della Probabilit√† Condizionata\n",
    "Alcune propriet√† importanti della probabilit√† condizionata sono:\n",
    "\n",
    "1. **Non-negativit√†**: \\( P(A|B) \\geq 0 \\).\n",
    "2. **Normalizzazione**: La probabilit√† condizionata deve essere normalizzata, cio√® la somma delle probabilit√† condizionate su tutti gli eventi possibili deve essere uguale a 1.\n",
    "   \n",
    "   \\[$\n",
    "   \\sum_{i} P(A_i | B) = 1\n",
    "   $\\]\n",
    "\n",
    "3. **Indipendenza**: Se gli eventi \\( A \\) e \\( B \\) sono indipendenti, allora \\( P(A|B) = P(A) \\).\n",
    "\n",
    "### Riflessione sull'Indipendenza\n",
    "\n",
    "L'indipendenza tra due eventi \\( A \\) e \\( B \\) implica che la probabilit√† di \\( A \\) dato \\( B \\) sia la stessa di \\( A \\), cio√®:\n",
    "\n",
    "\\[$\n",
    "P(A|B) = P(A)\n",
    "$\\]\n",
    "\n",
    "Questo succede quando il verificarsi di \\( B \\) non ha alcun effetto sulla probabilit√† che \\( A \\) si verifichi, e viceversa.\n",
    "\n",
    "### Conclusione\n",
    "\n",
    "La probabilit√† condizionata √® uno strumento potente per analizzare la relazione tra eventi, ed √® utilizzata in numerosi contesti pratici. La comprensione di come calcolare e applicare questa probabilit√† √® essenziale per risolvere problemi complessi in statistica, data science, e machine learning.\n",
    "\n",
    "# **Probability Distributions** (Distribuzioni di probabilit√†).\n",
    "\n",
    "### 1. Cos'√® una distribuzione di probabilit√†?\n",
    "\n",
    "Una **distribuzione di probabilit√†** √® una funzione che descrive la probabilit√† di occorrenza di eventi possibili in un esperimento casuale. Essa fornisce la probabilit√† associata a ciascun risultato (o intervallo di risultati) di un esperimento.\n",
    "\n",
    "In altre parole, una distribuzione di probabilit√† pu√≤ essere vista come una \"mappa\" che collega ciascun possibile risultato di un esperimento alla sua probabilit√†.\n",
    "\n",
    "Esistono due principali categorie di distribuzioni di probabilit√†:\n",
    "\n",
    "- **Distribuzioni discrete**: dove il numero di possibili risultati √® finito o numerabile (come il lancio di un dado).\n",
    "- **Distribuzioni continue**: dove il numero di possibili risultati √® infinito e non numerabile (come la misurazione della temperatura).\n",
    "\n",
    "### 2. Distribuzioni di probabilit√† discrete\n",
    "\n",
    "Le distribuzioni di probabilit√† discrete sono associate a variabili casuali discrete, cio√® variabili che possono assumere solo valori specifici (ad esempio, numeri interi). Ecco alcune delle distribuzioni discrete pi√π comuni:\n",
    "\n",
    "#### a. Distribuzione di Bernoulli\n",
    "\n",
    "La distribuzione di **Bernoulli** descrive un esperimento che ha solo due risultati possibili: successo o insuccesso (ad esempio, testa o croce in un lancio di moneta). La variabile casuale pu√≤ assumere il valore 1 (successo) o 0 (insuccesso), con probabilit√† \\( p \\) per il successo e \\( 1 - p \\) per l'insuccesso.\n",
    "\n",
    "Funzione di probabilit√†:  \n",
    "\\[$\n",
    "P(X = 1) = p, \\quad P(X = 0) = 1 - p\n",
    "$\\]\n",
    "\n",
    "#### b. Distribuzione binomiale\n",
    "\n",
    "La distribuzione **binomiale** generalizza la distribuzione di Bernoulli per esperimenti ripetuti. Se eseguiamo un esperimento di Bernoulli \\( n \\) volte, la distribuzione binomiale descrive la probabilit√† di ottenere \\( k \\) successi in \\( n \\) prove indipendenti.\n",
    "\n",
    "Funzione di probabilit√†:  \n",
    "\\[$\n",
    "P(X = k) = \\binom{n}{k} p^k (1 - p)^{n-k}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( n \\) √® il numero di prove,\n",
    "- \\( k \\) √® il numero di successi desiderati,\n",
    "- \\( p \\) √® la probabilit√† di successo in ogni prova.\n",
    "\n",
    "#### c. Distribuzione di Poisson\n",
    "\n",
    "La distribuzione di **Poisson** √® utile per modellare eventi che accadono in un intervallo di tempo o in uno spazio continuo, ma che si verificano in modo casuale e indipendente. √à utilizzata per eventi che accadono con una certa frequenza media, ma in modo casuale.\n",
    "\n",
    "Funzione di probabilit√†:  \n",
    "\\[$\n",
    "P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( \\lambda \\) √® la media o il tasso di occorrenza dell'evento,\n",
    "- \\( k \\) √® il numero di eventi osservati.\n",
    "\n",
    "#### d. Distribuzione geometrica\n",
    "\n",
    "La distribuzione **geometrica** descrive il numero di prove necessarie per ottenere il primo successo in una sequenza di esperimenti di Bernoulli.\n",
    "\n",
    "Funzione di probabilit√†:  \n",
    "\\[$\n",
    "P(X = k) = (1 - p)^{k-1} p\n",
    "$\\]\n",
    "\n",
    "Dove \\( p \\) √® la probabilit√† di successo in ogni prova e \\( k \\) √® il numero di prove prima del primo successo.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Distribuzioni di probabilit√† continue\n",
    "\n",
    "Le distribuzioni di probabilit√† continue sono associate a variabili casuali che possono assumere qualsiasi valore in un intervallo continuo, ad esempio la temperatura, l'altezza o il peso. Le distribuzioni pi√π comuni includono:\n",
    "\n",
    "#### a. Distribuzione normale (Gaussiana)\n",
    "\n",
    "La distribuzione **normale** √® una delle distribuzioni pi√π importanti e ampiamente utilizzate in statistica. √à una distribuzione continua a forma di campana che √® simmetrica attorno al suo valore medio.\n",
    "\n",
    "Funzione di densit√† di probabilit√†:  \n",
    "\\[$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( \\mu \\) √® la media,\n",
    "- \\( \\sigma^2 \\) √® la varianza.\n",
    "\n",
    "La distribuzione normale √® utilizzata per modellare fenomeni come l'altezza di un gruppo di persone o gli errori di misurazione.\n",
    "\n",
    "#### b. Distribuzione uniforme\n",
    "\n",
    "La distribuzione **uniforme** descrive una variabile casuale che ha uguale probabilit√† di assumere qualsiasi valore in un intervallo definito. Ad esempio, il lancio di un dado.\n",
    "\n",
    "Funzione di densit√† di probabilit√†:  \n",
    "\\[$\n",
    "f(x) = \\frac{1}{b - a}, \\quad \\text{per } a \\leq x \\leq b\n",
    "$\\]\n",
    "\n",
    "Dove \\( a \\) e \\( b \\) sono i limiti inferiore e superiore dell'intervallo.\n",
    "\n",
    "#### c. Distribuzione esponenziale\n",
    "\n",
    "La distribuzione **esponenziale** √® utilizzata per modellare il tempo che intercorre tra due eventi che accadono in un processo di Poisson (ad esempio, il tempo tra le chiamate a un call center).\n",
    "\n",
    "Funzione di densit√† di probabilit√†:  \n",
    "\\[$\n",
    "f(x) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0\n",
    "$\\]\n",
    "\n",
    "Dove \\( \\lambda \\) √® il tasso di arrivo degli eventi.\n",
    "\n",
    "#### d. Distribuzione t di Student\n",
    "\n",
    "La distribuzione **t di Student** √® utilizzata quando si stima la media di una popolazione da un campione, in particolare quando la dimensione del campione √® piccola e la deviazione standard della popolazione √® sconosciuta.\n",
    "\n",
    "Funzione di densit√† di probabilit√†:  \n",
    "La distribuzione t ha una forma simile alla normale, ma con code pi√π spesse. La sua funzione di densit√† dipende da un parametro chiamato **gradi di libert√†**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Parametri delle distribuzioni\n",
    "\n",
    "Ogni distribuzione di probabilit√† √® descritta da una serie di parametri che definiscono la sua forma e propriet√†. I parametri comuni includono:\n",
    "\n",
    "- **Media (\\( \\mu \\))**: la posizione centrale della distribuzione.\n",
    "- **Varianza (\\( \\sigma^2 \\))**: la misura della dispersione dei dati intorno alla media.\n",
    "- **Deviazione standard (\\( \\sigma \\))**: la radice quadrata della varianza, che √® pi√π facilmente interpretabile rispetto alla varianza.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Applicazioni delle distribuzioni di probabilit√†\n",
    "\n",
    "Le distribuzioni di probabilit√† sono fondamentali in molte aree delle scienze, ingegneria, economia, e medicina. Ad esempio:\n",
    "- **In statistica inferenziale**: per stimare parametri della popolazione e fare test statistici.\n",
    "- **In finanza**: per modellare i ritorni degli investimenti e il rischio.\n",
    "- **In machine learning**: per comprendere e costruire modelli probabilistici (es. Naive Bayes, distribuzioni gaussiane in modelli di regressione).\n",
    "- **In medicina**: per modellare la probabilit√† di successo di un trattamento o l'andamento di una malattia.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Conclusione\n",
    "\n",
    "Le distribuzioni di probabilit√† forniscono una base solida per analizzare e comprendere fenomeni casuali in vari contesti. La comprensione delle diverse distribuzioni e dei loro parametri √® essenziale per affrontare problemi pratici e applicare correttamente la statistica e la probabilit√† in diverse discipline.\n",
    "\n",
    "# **Inferential Statistics** (Statistica Inferenziale) \n",
    "√® una branca della statistica che si occupa di fare inferenze o previsioni su una popolazione a partire da un campione di dati. A differenza della statistica descrittiva, che si limita a riassumere e descrivere i dati (mediante medie, deviazioni standard, ecc.), la statistica inferenziale cerca di trarre conclusioni o di fare predizioni basate su un insieme di dati pi√π limitato. Questo processo si basa su teorie probabilistiche per fare stime e testare ipotesi.\n",
    "\n",
    "### Concetti Fondamentali della Statistica Inferenziale\n",
    "\n",
    "1. **Popolazione vs. Campione**:\n",
    "   - **Popolazione**: √à l'intero gruppo di elementi che si desidera studiare.\n",
    "   - **Campione**: √à un sottoinsieme di elementi prelevato dalla popolazione. Poich√© √® spesso difficile o impossibile studiare tutta la popolazione, si utilizza un campione per fare delle inferenze.\n",
    "   - √à essenziale che il campione sia rappresentativo della popolazione per ottenere stime accurate.\n",
    "\n",
    "2. **Inferenze Statistiche**:\n",
    "   Le inferenze statistiche includono:\n",
    "   - **Stima**: Stimare valori sconosciuti (parametri) della popolazione, come la media o la proporzione.\n",
    "   - **Test di ipotesi**: Valutare un'ipotesi sulla popolazione basandosi sul campione, determinando se ci sono prove sufficienti per accettare o rifiutare l'ipotesi.\n",
    "\n",
    "3. **Distribuzione Campionaria**:\n",
    "   La distribuzione campionaria √® la distribuzione di una statistica (ad esempio, la media campionaria) ottenuta da campioni ripetuti estratti dalla stessa popolazione. √à importante capire come queste distribuzioni si comportano per fare inferenze valide. Una delle teorie centrali qui √® il **Teorema del Limite Centrale**, che afferma che, sotto certe condizioni, la distribuzione delle medie campionarie tende ad essere normale, indipendentemente dalla forma della distribuzione della popolazione, man mano che il campione cresce.\n",
    "\n",
    "4. **Intervallo di Confidenza (Confidence Interval)**:\n",
    "   Un intervallo di confidenza √® un range di valori che, con un certo livello di probabilit√†, contiene il vero parametro della popolazione. Ad esempio, un intervallo di confidenza del 95% significa che, se si ripetessero gli esperimenti molte volte, il parametro della popolazione sarebbe contenuto nell'intervallo il 95% delle volte.\n",
    "   \n",
    "   Formula dell'intervallo di confidenza per la media:\n",
    "   \\[$\n",
    "   \\text{Intervallo di Confidenza} = \\hat{\\mu} \\pm Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\n",
    "   $\\]\n",
    "   Dove:\n",
    "   - \\($\\hat{\\mu}\\$) √® la media campionaria,\n",
    "   - \\($Z_{\\alpha/2}\\$) √® il valore critico per un dato livello di confidenza (ad esempio, 1.96 per il 95% di confidenza),\n",
    "   - \\($\\sigma$\\) √® la deviazione standard della popolazione (o quella campionaria, se la popolazione √® sconosciuta),\n",
    "   - \\($n$\\) √® la dimensione del campione.\n",
    "\n",
    "5. **Test di Ipotesi**:\n",
    "   Un test di ipotesi √® un processo che consente di verificare se una certa affermazione su una popolazione √® vera, basandosi su dati campionari. Si definiscono due ipotesi:\n",
    "   - **Ipotesi nulla (H‚ÇÄ)**: L'affermazione da testare, solitamente una dichiarazione di \"nessun effetto\" o \"nessuna differenza\".\n",
    "   - **Ipotesi alternativa (H‚ÇÅ)**: L'affermazione che si vuole sostenere, ovvero una differenza significativa o un effetto.\n",
    "   \n",
    "   Esempio di un test di ipotesi:\n",
    "   - **H‚ÇÄ**: La media della popolazione √® uguale a 50.\n",
    "   - **H‚ÇÅ**: La media della popolazione non √® uguale a 50.\n",
    "   \n",
    "   Un test di ipotesi si conclude con una decisione basata sul calcolo di una statistica di test e il suo confronto con un valore critico o tramite il p-value:\n",
    "   - **p-value**: √à la probabilit√† di ottenere un risultato uguale o pi√π estremo di quello osservato, assumendo che l'ipotesi nulla sia vera. Un p-value basso (solitamente inferiore a 0.05) porta al rifiuto dell'ipotesi nulla.\n",
    "\n",
    "6. **Tipo di Errori nei Test di Ipotesi**:\n",
    "   - **Errore di Tipo I (Œ±)**: Rifiutare erroneamente l'ipotesi nulla quando √® vera (falso positivo).\n",
    "   - **Errore di Tipo II (Œ≤)**: Non rifiutare l'ipotesi nulla quando √® falsa (falso negativo).\n",
    "\n",
    "7. **Distribuzioni di Probabilit√† Utilizzate**:\n",
    "   In statistica inferenziale, le distribuzioni di probabilit√† sono utilizzate per modellare l'incertezza associata alle stime. Le principali distribuzioni includono:\n",
    "   - **Distribuzione Normale**: Utilizzata quando i dati seguono una distribuzione continua simmetrica.\n",
    "   - **Distribuzione t di Student**: Usata quando il campione √® di dimensioni piccole e la deviazione standard della popolazione √® sconosciuta.\n",
    "   - **Distribuzione Chi-quadro**: Spesso usata per testare la bont√† di adattamento o l'indipendenza in tabelle di contingenza.\n",
    "   - **Distribuzione F**: Utilizzata per confrontare varianze in test di analisi della varianza (ANOVA).\n",
    "\n",
    "### Applicazioni della Statistica Inferenziale\n",
    "\n",
    "1. **Ricerca scientifica**: La statistica inferenziale √® fondamentale nelle scienze per fare inferenze sui dati sperimentali e trarre conclusioni generali.\n",
    "2. **Business e Marketing**: Per analizzare i comportamenti dei consumatori e fare previsioni sulle vendite o sul successo di un prodotto.\n",
    "3. **Medicina**: Per determinare l'efficacia di un trattamento o per stimare la prevalenza di una malattia.\n",
    "4. **Politica**: Per fare sondaggi e inferenze sui comportamenti degli elettori.\n",
    "\n",
    "### Riepilogo\n",
    "\n",
    "La statistica inferenziale √® un potente strumento per prendere decisioni e fare previsioni sui dati. Utilizzando campioni di dati, √® possibile fare inferenze sulla popolazione, stimare parametri, testare ipotesi e calcolare intervalli di confidenza. Le tecniche di inferenza, come il test di ipotesi e gli intervalli di confidenza, si basano su una solida comprensione delle distribuzioni di probabilit√† e delle caratteristiche dei campioni.\n",
    "\n",
    "# **campionamento** (sampling) \n",
    "√® una tecnica fondamentale in statistica e data science che consiste nel selezionare un sottoinsieme rappresentativo da un insieme di dati pi√π grande (popolazione). L'obiettivo √® raccogliere informazioni sufficienti da questo sottoinsieme per fare inferenze valide sulla popolazione. √à una tecnica usata per risparmiare tempo e risorse, ma deve essere eseguita con attenzione per evitare distorsioni nei risultati.\n",
    "\n",
    "### 1. **Tipi di Campionamento**\n",
    "\n",
    "Esistono diversi metodi di campionamento, che si possono suddividere in due categorie principali: **campionamento probabilistico** e **campionamento non probabilistico**.\n",
    "\n",
    "#### A. Campionamento Probabilistico\n",
    "\n",
    "Nel campionamento probabilistico, ogni elemento della popolazione ha una probabilit√† conosciuta di essere selezionato. Questi metodi garantiscono che il campione sia rappresentativo della popolazione.\n",
    "\n",
    "1. **Campionamento casuale semplice (Simple Random Sampling - SRS)**:\n",
    "   - Ogni individuo della popolazione ha la stessa probabilit√† di essere selezionato.\n",
    "   - Pu√≤ essere effettuato senza reinserimento (quando un elemento selezionato non viene rimesso nel campione) o con reinserimento (quando un elemento selezionato viene rimesso nel campione).\n",
    "   - **Esempio**: Se hai una popolazione di 100 persone e vuoi selezionare un campione di 10 persone, estrai casualmente 10 persone dalla lista.\n",
    "\n",
    "2. **Campionamento sistematico (Systematic Sampling)**:\n",
    "   - Si seleziona un punto di partenza casuale, e poi ogni k-esimo elemento della popolazione viene selezionato. \n",
    "   - **Formula**: \\( k = \\frac{N}{n} \\), dove \\( N \\) √® la dimensione totale della popolazione e \\( n \\) √® la dimensione del campione.\n",
    "   - **Esempio**: Se vuoi selezionare 10 persone da una popolazione di 100, puoi scegliere ogni 10a persona.\n",
    "\n",
    "3. **Campionamento stratificato (Stratified Sampling)**:\n",
    "   - La popolazione viene suddivisa in sottogruppi (strati) omogenei, e successivamente si seleziona un campione da ciascun strato. \n",
    "   - Si garantisce che tutte le caratteristiche della popolazione siano rappresentate in modo proporzionale.\n",
    "   - **Esempio**: Se una popolazione √® suddivisa in gruppi in base all'et√† (18-30, 31-40, ecc.), un campione stratificato selezioner√† un numero proporzionale di persone da ogni gruppo.\n",
    "\n",
    "4. **Campionamento a grappolo (Cluster Sampling)**:\n",
    "   - La popolazione viene suddivisa in gruppi (grappoli), e poi si selezionano alcuni grappoli in modo casuale. Tutti gli elementi di ogni grappolo selezionato vengono inclusi nel campione.\n",
    "   - √à utile quando √® difficile accedere a tutti gli individui della popolazione, ma √® possibile accedere facilmente ai grappoli.\n",
    "   - **Esempio**: Se vuoi studiare gli studenti di diverse scuole, potresti selezionare casualmente alcune scuole (grappoli) e includere tutti gli studenti di quelle scuole nel campione.\n",
    "\n",
    "5. **Campionamento a probabilit√† proporzionale al peso (Probability Proportional to Size - PPS)**:\n",
    "   - √à una variante del campionamento a grappolo, in cui la probabilit√† di selezionare un grappolo √® proporzionale alla sua dimensione.\n",
    "   - **Esempio**: Se un grappolo √® composto da 500 persone e un altro da 50 persone, il grappolo pi√π grande avr√† pi√π probabilit√† di essere selezionato.\n",
    "\n",
    "#### B. Campionamento Non Probabilistico\n",
    "\n",
    "Nel campionamento non probabilistico, non tutti gli individui della popolazione hanno la stessa probabilit√† di essere selezionati. Questi metodi non sono adatti a fare inferenze generalizzabili, ma possono essere utili quando non √® possibile utilizzare metodi probabilistici.\n",
    "\n",
    "1. **Campionamento di convenienza (Convenience Sampling)**:\n",
    "   - Si selezionano gli individui pi√π facili da raggiungere, senza considerare la loro rappresentativit√†.\n",
    "   - **Esempio**: Se selezioni i partecipanti alla tua ricerca tra coloro che sono facilmente disponibili, come amici o colleghi.\n",
    "\n",
    "2. **Campionamento per giudizio (Judgmental or Purposive Sampling)**:\n",
    "   - Il ricercatore seleziona deliberatamente i membri del campione sulla base di conoscenze o caratteristiche specifiche.\n",
    "   - **Esempio**: Se stai studiando l'efficacia di un trattamento per una malattia rara, selezionerai solo i pazienti che soffrono di quella malattia.\n",
    "\n",
    "3. **Campionamento a valanga (Snowball Sampling)**:\n",
    "   - Un membro selezionato del campione viene utilizzato per identificare altri membri del campione, e cos√¨ via. √à utile per campionare popolazioni difficili da raggiungere o nascoste.\n",
    "   - **Esempio**: Se stai cercando intervistare persone in un gruppo sociale specifico e non conosci personalmente nessuno di loro, puoi chiedere a una persona di raccomandarti altre persone.\n",
    "\n",
    "### 2. **Esempi di Applicazione del Campionamento**\n",
    "\n",
    "- **In ricerche sociali**: Per raccogliere opinioni o comportamenti di una popolazione pi√π grande senza dover intervistare ogni singolo individuo.\n",
    "- **In studi clinici**: Per testare un trattamento o una terapia, si seleziona un campione di pazienti rappresentativi dalla popolazione.\n",
    "- **In analisi dei dati**: Quando lavoriamo con set di dati molto grandi, possiamo applicare il campionamento per ridurre la complessit√† computazionale senza perdere informazioni cruciali.\n",
    "\n",
    "### 3. **Vantaggi e Svantaggi**\n",
    "\n",
    "#### Vantaggi:\n",
    "- Riduce il costo e il tempo rispetto a un censimento completo.\n",
    "- √à pi√π pratico quando la popolazione √® troppo grande per essere studiata interamente.\n",
    "- Se eseguito correttamente, pu√≤ produrre risultati che riflettono accuratamente la popolazione.\n",
    "\n",
    "#### Svantaggi:\n",
    "- Il campione potrebbe non essere perfettamente rappresentativo se non scelto correttamente.\n",
    "- I metodi non probabilistici possono introdurre bias.\n",
    "- L'errore di campionamento √® una parte intrinseca dei campioni, e pu√≤ limitare l'affidabilit√† delle inferenze.\n",
    "\n",
    "### 4. **Errori nel Campionamento**\n",
    "\n",
    "- **Errore di campionamento**: La differenza tra il risultato osservato nel campione e quello che sarebbe stato ottenuto se si fosse osservata l'intera popolazione.\n",
    "- **Bias di selezione**: Quando il campione non rappresenta adeguatamente la popolazione, influenzando i risultati.\n",
    "  \n",
    "### 5. **Leggi del Campionamento**\n",
    "\n",
    "Esistono alcune leggi matematiche che determinano la quantit√† di dati da campionare per ottenere un buon risultato statistico:\n",
    "\n",
    "- **Legge dei grandi numeri**: Con l'aumento della dimensione del campione, la media campionaria si avvicina alla media della popolazione.\n",
    "- **Teorema del limite centrale**: Con un numero sufficientemente grande di campioni, la distribuzione della media campionaria tende ad essere normale, indipendentemente dalla distribuzione della popolazione.\n",
    "\n",
    "### Conclusioni\n",
    "\n",
    "Il campionamento √® una tecnica potente e fondamentale in statistica e data science. La scelta del metodo di campionamento dipende dal tipo di dati, dalla disponibilit√† della popolazione e dallo scopo della ricerca. √à essenziale essere consapevoli dei potenziali bias e dell'errore di campionamento che possono influenzare la validit√† dei risultati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33309653-2441-4dd1-8695-37abaef03b58",
   "metadata": {},
   "source": [
    "# **Legge dei Grandi Numeri**\n",
    "\n",
    "## **Introduzione**\n",
    "La **Legge dei Grandi Numeri** (LLN, Law of Large Numbers) √® un concetto fondamentale nella teoria della probabilit√† e nella statistica. Stabilisce che, man mano che il numero di osservazioni aumenta, la media campionaria dei valori osservati tende a convergere verso il valore atteso (la media vera della popolazione).\n",
    "\n",
    "Questa propriet√† √® essenziale perch√© giustifica l'uso delle medie campionarie per stimare le medie della popolazione in molte applicazioni pratiche, dalla statistica inferenziale all'apprendimento automatico.\n",
    "\n",
    "---\n",
    "## **Definizione Formale**\n",
    "Sia \\( $X_1, X_2, \\dots, X_n$ \\) una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.), con valore atteso (media):( $mu$) e varianza finita \\( $sigma^2$ ). La media campionaria √® definita come:\n",
    "\n",
    "\\[\n",
    "$\\bar{X_n} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n",
    "\\$]\n",
    "\n",
    "La Legge dei Grandi Numeri afferma che:\n",
    "\n",
    "\\[\n",
    "$\\lim_{n \\to \\infty} \\bar{X_n} = \\mu\n",
    "\\$]\n",
    "\n",
    "con probabilit√† pari a 1, ovvero, la media campionaria converge alla media della popolazione quando \\( n \\) tende a infinito.\n",
    "\n",
    "---\n",
    "## **Tipi di Legge dei Grandi Numeri**\n",
    "Esistono due versioni principali della LLN:\n",
    "\n",
    "1. **Legge dei Grandi Numeri Debole (WLLN - Weak Law of Large Numbers)**\n",
    "   - Stabilisce che la media campionaria \\( \\bar{X_n} \\) converge in probabilit√† alla media della popolazione \\$( \\mu \\$), ovvero:\n",
    "     \n",
    "     \\[\n",
    "     $P(|\\bar{X_n} - \\mu| \\geq \\varepsilon) \\to 0 \\quad \\text{per ogni} \\quad \\varepsilon > 0, \\text{quando} \\quad n \\to \\infty.$\n",
    "     \\]\n",
    "     \n",
    "   - Questo significa che all'aumentare del numero di osservazioni, la probabilit√† che la media campionaria sia distante da \\$( \\mu \\$) diventa sempre pi√π piccola.\n",
    "\n",
    "2. **Legge dei Grandi Numeri Forte (SLLN - Strong Law of Large Numbers)**\n",
    "   - Stabilisce che la media campionaria converge quasi certamente a \\( \\mu \\), ovvero:\n",
    "     \n",
    "     \\[\n",
    "     $P(\\lim_{n \\to \\infty} \\bar{X_n} = \\mu) = 1.$\n",
    "     \\]\n",
    "     \n",
    "   - Ci√≤ implica che, con probabilit√† 1, la successione \\$( \\bar{X_n} \\)$ si avvicina a \\$( \\mu \\$) e non si allontana mai pi√π significativamente.\n",
    "\n",
    "---\n",
    "## **Esempio Intuitivo**\n",
    "Un classico esempio per comprendere la Legge dei Grandi Numeri √® il lancio di una moneta equa.\n",
    "\n",
    "- Se lanciamo una moneta, abbiamo probabilit√† \\( p = 0.5 \\) di ottenere testa e \\( 1 - p = 0.5 \\) di ottenere croce.\n",
    "- Se lanciamo la moneta poche volte (ad esempio 10 lanci), la proporzione di teste potrebbe discostarsi molto da 0.5.\n",
    "- Se aumentiamo il numero di lanci a 100, 1000, 10.000, la proporzione delle teste tender√† a stabilizzarsi attorno a 0.5.\n",
    "\n",
    "---\n",
    "## **Implementazione in Python**\n",
    "Ecco un codice Python che simula la Legge dei Grandi Numeri con il lancio di una moneta.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Impostiamo il seme per la riproducibilit√†\n",
    "np.random.seed(1)\n",
    "\n",
    "# Parametri della simulazione\n",
    "p = 0.5  # Probabilit√† di ottenere \"Testa\"\n",
    "n_trials = 10000  # Numero di lanci della moneta\n",
    "\n",
    "# Generazione dei risultati casuali (0 = Croce, 1 = Testa)\n",
    "results = np.random.choice([0, 1], size=n_trials)\n",
    "\n",
    "# Calcolo della media cumulativa\n",
    "cumulative_mean = np.cumsum(results) / np.arange(1, n_trials + 1)\n",
    "\n",
    "# Visualizzazione della convergenza\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cumulative_mean, label='Media Cumulativa')\n",
    "plt.axhline(p, color='red', linestyle='--', label='Media Vera (0.5)')\n",
    "plt.title(\"Legge dei Grandi Numeri\")\n",
    "plt.xlabel(\"Numero di Lanci\")\n",
    "plt.ylabel(\"Media Cumulativa\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **Spiegazione del Codice**\n",
    "1. **np.random.seed(1)**: Imposta un seme per rendere i risultati riproducibili.\n",
    "2. **np.random.choice([0, 1], size=n_trials)**: Genera un array di 0 e 1 casuali, simulando i lanci della moneta.\n",
    "3. **np.cumsum(results) / np.arange(1, n_trials + 1)**: Calcola la media cumulativa per ogni passo della simulazione.\n",
    "4. **plt.plot(cumulative_mean)**: Disegna il grafico della media cumulativa per mostrare la convergenza.\n",
    "5. **plt.axhline(p, color='red', linestyle='--')**: Traccia una linea orizzontale alla media teorica attesa (0.5).\n",
    "\n",
    "---\n",
    "## **Osservazioni dai Risultati**\n",
    "- Nei primi tentativi, la media cumulativa oscilla notevolmente, perch√© il campione √® piccolo.\n",
    "- Con l'aumentare del numero di prove, la media cumulativa si stabilizza vicino a 0.5.\n",
    "- Questo dimostra empiricamente la Legge dei Grandi Numeri: pi√π osservazioni si raccolgono, pi√π la media campionaria si avvicina alla media teorica.\n",
    "\n",
    "---\n",
    "## **Applicazioni della Legge dei Grandi Numeri**\n",
    "1. **Statistica e inferenza**: Le medie campionarie vengono utilizzate per stimare parametri di popolazione.\n",
    "2. **Assicurazioni**: Le compagnie assicurative usano questa legge per prevedere i costi futuri.\n",
    "3. **Finanza**: Nell‚Äôanalisi del rischio e nella previsione dei rendimenti.\n",
    "4. **Apprendimento automatico**: Usata per comprendere il comportamento dei modelli con grandi dataset.\n",
    "5. **Scienze mediche**: Studi clinici usano grandi campioni per stimare con precisione gli effetti dei trattamenti.\n",
    "\n",
    "---\n",
    "## **Conclusione**\n",
    "La Legge dei Grandi Numeri √® un concetto chiave della probabilit√† che garantisce che le medie campionarie convergano verso la media vera quando il numero di osservazioni cresce. Questa propriet√† √® alla base di molte applicazioni pratiche, dalla statistica all'intelligenza artificiale, ed √® verificabile empiricamente attraverso simulazioni come quella vista sopra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e7f0c-0dfa-4ea9-9901-e9a99b501b7d",
   "metadata": {},
   "source": [
    "# Metodi Monte Carlo: Una Guida Dettagliata\n",
    "\n",
    "## Introduzione ai Metodi Monte Carlo\n",
    "I metodi Monte Carlo sono una classe di algoritmi computazionali che utilizzano campionamenti casuali ripetuti per ottenere risultati numerici. Questi metodi si basano sulla probabilit√† e sulla statistica per approssimare soluzioni a problemi complessi, spesso impossibili da risolvere analiticamente.\n",
    "\n",
    "Questi metodi prendono il nome dal famoso casin√≤ di Monte Carlo a Monaco, noto per il gioco d'azzardo, poich√© si basano sull'uso di numeri casuali proprio come nei giochi di fortuna.\n",
    "\n",
    "## Fondamenti Matematici\n",
    "I metodi Monte Carlo sfruttano il **Teorema del Limite Centrale** e la **Legge dei Grandi Numeri**:\n",
    "- **Legge dei Grandi Numeri**: Se un esperimento viene ripetuto un numero sufficiente di volte, la media dei risultati ottenuti tende al valore atteso teorico.\n",
    "- **Teorema del Limite Centrale**: La distribuzione della media campionaria di variabili casuali indipendenti e identicamente distribuite tende a una distribuzione normale quando il numero di campioni √® grande.\n",
    "\n",
    "Questi principi permettono di stimare con alta precisione il valore atteso di una variabile aleatoria anche quando la funzione analitica √® sconosciuta.\n",
    "\n",
    "## Passaggi Fondamentali dell'Algoritmo Monte Carlo\n",
    "Un algoritmo Monte Carlo segue questi passaggi:\n",
    "1. **Definizione del Problema**: Identificare il dominio del problema e la quantit√† da stimare.\n",
    "2. **Generazione di Campioni Casuali**: Creare un insieme di numeri casuali che rappresentano il sistema.\n",
    "3. **Esecuzione del Modello**: Utilizzare i campioni casuali per eseguire calcoli e ottenere risultati.\n",
    "4. **Aggregazione e Analisi dei Risultati**: Calcolare statistiche dai risultati per ottenere una stima dell'incognita.\n",
    "\n",
    "## Applicazioni dei Metodi Monte Carlo\n",
    "I metodi Monte Carlo sono utilizzati in diversi ambiti, tra cui:\n",
    "\n",
    "### 1. **Fisica e Chimica Computazionale**\n",
    "- Simulazione del comportamento di sistemi complessi (es. dinamica molecolare, fisica delle particelle, reazioni chimiche).\n",
    "- Modellazione della diffusione di particelle in un fluido.\n",
    "\n",
    "### 2. **Finanza Quantitativa**\n",
    "- Valutazione di derivati finanziari e opzioni.\n",
    "- Stima del rischio di portafoglio.\n",
    "- Ottimizzazione di strategie di investimento.\n",
    "\n",
    "### 3. **Machine Learning e AI**\n",
    "- Ottimizzazione bayesiana per il tuning di iperparametri.\n",
    "- Generazione di dati sintetici per il training di modelli.\n",
    "\n",
    "### 4. **Scienze della Salute e Epidemiologia**\n",
    "- Simulazione della diffusione di malattie infettive.\n",
    "- Analisi della farmacodinamica e farmacocinetica di nuovi farmaci.\n",
    "\n",
    "### 5. **Ingegneria e Scienze dei Materiali**\n",
    "- Modellazione di sistemi termodinamici complessi.\n",
    "- Simulazione di processi di produzione e ottimizzazione delle catene di fornitura.\n",
    "\n",
    "## Esempio Pratico: Calcolo di Pi Greco con Monte Carlo\n",
    "Uno degli esempi pi√π noti di metodo Monte Carlo √® il calcolo del valore di œÄ.\n",
    "\n",
    "### Procedura:\n",
    "1. Disegnare un quadrato di lato 2 e un cerchio inscritto di raggio 1.\n",
    "2. Generare punti casuali all'interno del quadrato.\n",
    "3. Contare quanti punti cadono all'interno del cerchio.\n",
    "4. Stimare œÄ usando la proporzione tra i punti nel cerchio e quelli totali:\n",
    "\n",
    "   \\[ $\\pi \\approx 4 \\times \\frac{N_{cerchio}}{N_{totale}} $\\]\n",
    "\n",
    "### Implementazione in Python:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10000  # Numero di punti\n",
    "x = np.random.uniform(-1, 1, N)\n",
    "y = np.random.uniform(-1, 1, N)\n",
    "\n",
    "inside_circle = x**2 + y**2 <= 1\n",
    "pi_estimate = (np.sum(inside_circle) / N) * 4\n",
    "\n",
    "print(f\"Stima di Pi Greco: {pi_estimate}\")\n",
    "```\n",
    "\n",
    "## Vantaggi e Svantaggi dei Metodi Monte Carlo\n",
    "\n",
    "### **Vantaggi**:\n",
    "- **Flessibilit√†**: Possono essere applicati a una vasta gamma di problemi.\n",
    "- **Semplicit√† di Implementazione**: Facili da scrivere e comprendere.\n",
    "- **Scalabilit√†**: Funzionano bene con grandi dataset e problemi complessi.\n",
    "\n",
    "### **Svantaggi**:\n",
    "- **Alto Costo Computazionale**: Richiedono molte iterazioni per ottenere risultati precisi.\n",
    "- **Dipendenza dalla Generazione di Numeri Casuali**: La qualit√† dei risultati dipende dalla qualit√† dei numeri casuali generati.\n",
    "- **Convergenza Lenta**: Rispetto ad altri metodi numerici, pu√≤ essere meno efficiente in alcune applicazioni.\n",
    "\n",
    "## Conclusione\n",
    "I metodi Monte Carlo rappresentano uno strumento potente per la simulazione e l'analisi di problemi complessi in molteplici discipline. Il loro principio di base, fondato su campionamenti casuali e stime statistiche, li rende versatili e ampiamente utilizzati in applicazioni scientifiche, finanziarie e ingegneristiche.\n",
    "\n",
    "Se utilizzati correttamente e con un numero adeguato di campioni, i metodi Monte Carlo forniscono risultati accurati e affidabili, contribuendo a migliorare la comprensione e la risoluzione di problemi difficili da affrontare con metodi analitici tradizionali.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb5a18-a64a-4e91-a7fd-0afa2a7ca0d7",
   "metadata": {},
   "source": [
    "Ecco una spiegazione riga per riga del codice:\n",
    "\n",
    "---\n",
    "\n",
    "### **Definizione della Funzione `roulette_spin()`**\n",
    "```python\n",
    "def roulette_spin():\n",
    "    wheel = [i for i in range(0, 37)]\n",
    "    result = np.random.choice(wheel)\n",
    "    return result\n",
    "```\n",
    "1. **`wheel = [i for i in range(0, 37)]`**  \n",
    "   - Crea una lista contenente i numeri della roulette europea, che vanno da 0 a 36.  \n",
    "\n",
    "2. **`result = np.random.choice(wheel)`**  \n",
    "   - Seleziona casualmente un numero dalla lista `wheel` simulando un giro di roulette.  \n",
    "\n",
    "3. **`return result`**  \n",
    "   - Restituisce il numero uscito dalla roulette.\n",
    "\n",
    "---\n",
    "\n",
    "### **Definizione della Funzione `play_roulette_game(n_spins)`**\n",
    "```python\n",
    "def play_roulette_game(n_spins):\n",
    "    \n",
    "    balance = 0\n",
    "    bet = 1\n",
    "```\n",
    "4. **`balance = 0`**  \n",
    "   - Inizializza il saldo del giocatore a 0‚Ç¨.  \n",
    "\n",
    "5. **`bet = 1`**  \n",
    "   - Fissa la puntata iniziale a 1‚Ç¨.  \n",
    "\n",
    "---\n",
    "```python\n",
    "    for _ in range(n_spins):\n",
    "        result = roulette_spin()\n",
    "```\n",
    "6. **`for _ in range(n_spins):`**  \n",
    "   - Ripete il ciclo `n_spins` volte (numero di giri della roulette).  \n",
    "\n",
    "7. **`result = roulette_spin()`**  \n",
    "   - Simula un giro della roulette e salva il numero uscito in `result`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Determinazione del Colore del Numero Uscito**\n",
    "```python\n",
    "        if result in range(1, 11) or result in range(19, 29):\n",
    "            if result % 2 == 0:  # Win condition (black)\n",
    "                balance += bet\n",
    "            else:  # Lose condition (red)\n",
    "                balance -= bet\n",
    "```\n",
    "8. **`if result in range(1, 11) or result in range(19, 29):`**  \n",
    "   - Se il numero √® tra **1-10 o 19-28**, si applicano le seguenti regole di colore:  \n",
    "     - I numeri pari sono **neri**  \n",
    "     - I numeri dispari sono **rossi**  \n",
    "\n",
    "9. **`if result % 2 == 0:`**  \n",
    "   - Se il numero √® pari (nero), il giocatore vince e il saldo aumenta di 1‚Ç¨.  \n",
    "\n",
    "10. **`else:`**  \n",
    "   - Se il numero √® dispari (rosso), il giocatore perde e il saldo diminuisce di 1‚Ç¨.  \n",
    "\n",
    "---\n",
    "```python\n",
    "        elif result in range(11, 19) or result in range(29, 37):\n",
    "            if result % 2 != 0:  # Win condition (black)\n",
    "                balance += bet\n",
    "            else:  # Lose condition (red)\n",
    "                balance -= bet\n",
    "```\n",
    "11. **`elif result in range(11, 19) or result in range(29, 37):`**  \n",
    "    - Se il numero √® tra **11-18 o 29-36**, si applicano le seguenti regole di colore:  \n",
    "      - I numeri dispari sono **neri**  \n",
    "      - I numeri pari sono **rossi**  \n",
    "\n",
    "12. **`if result % 2 != 0:`**  \n",
    "    - Se il numero √® dispari (nero), il giocatore vince e guadagna 1‚Ç¨.  \n",
    "\n",
    "13. **`else:`**  \n",
    "    - Se il numero √® pari (rosso), il giocatore perde 1‚Ç¨.  \n",
    "\n",
    "---\n",
    "```python\n",
    "        else:  # Zero\n",
    "            balance -= bet  # The house wins\n",
    "```\n",
    "14. **Se il numero √® 0**  \n",
    "    - Il giocatore perde automaticamente, quindi il saldo diminuisce di 1‚Ç¨.  \n",
    "\n",
    "---\n",
    "```python\n",
    "    return balance\n",
    "```\n",
    "15. **Restituisce il saldo finale** dopo `n_spins` giri.\n",
    "\n",
    "---\n",
    "\n",
    "### **Simulazione Monte Carlo**\n",
    "```python\n",
    "n_simulations = 10000\n",
    "n_spins = 100\n",
    "```\n",
    "16. **`n_simulations = 10000`**  \n",
    "    - Simula 10.000 partite di roulette.  \n",
    "\n",
    "17. **`n_spins = 100`**  \n",
    "    - Ogni partita consiste in 100 giri di roulette.  \n",
    "\n",
    "---\n",
    "```python\n",
    "results = [play_roulette_game(n_spins) for _ in range(n_simulations)]\n",
    "```\n",
    "18. **`[play_roulette_game(n_spins) for _ in range(n_simulations)]`**  \n",
    "    - Esegue `play_roulette_game(n_spins)` 10.000 volte e salva i risultati nella lista `results`.\n",
    "\n",
    "---\n",
    "```python\n",
    "mean_balance = np.mean(results)\n",
    "std_dev_balance = np.std(results)\n",
    "```\n",
    "19. **`np.mean(results)`**  \n",
    "    - Calcola il saldo medio dopo 100 giri di roulette.  \n",
    "\n",
    "20. **`np.std(results)`**  \n",
    "    - Calcola la deviazione standard dei saldi finali.  \n",
    "\n",
    "---\n",
    "### **Grafico della Distribuzione dei Risultati**\n",
    "```python\n",
    "plt.hist(results, bins=38, color='green', alpha=0.7, edgecolor='black')\n",
    "```\n",
    "21. **`plt.hist(results, bins=38, color='green', alpha=0.7, edgecolor='black')`**  \n",
    "    - Crea un istogramma con 38 bin (uno per ogni possibile saldo finale).  \n",
    "    - Il colore del grafico √® verde con trasparenza 0.7 e bordi neri.  \n",
    "\n",
    "---\n",
    "```python\n",
    "plt.axvline(mean_balance, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_balance:.2f}')\n",
    "```\n",
    "22. **`plt.axvline(mean_balance, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_balance:.2f}')`**  \n",
    "    - Disegna una linea verticale rossa tratteggiata che indica il saldo medio.  \n",
    "\n",
    "---\n",
    "```python\n",
    "plt.title(f\"Monte Carlo Simulation of Roulette Game\\nAverage final balance after {n_spins} spins\")\n",
    "plt.xlabel(\"Final Balance ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "23. **Titolo e etichette del grafico**  \n",
    "    - **`plt.title(...)`** ‚Üí Imposta il titolo del grafico.  \n",
    "    - **`plt.xlabel(\"Final Balance ($)\")`** ‚Üí Etichetta dell'asse X (saldo finale).  \n",
    "    - **`plt.ylabel(\"Frequency\")`** ‚Üí Etichetta dell'asse Y (frequenza).  \n",
    "    - **`plt.legend()`** ‚Üí Mostra la legenda.  \n",
    "    - **`plt.show()`** ‚Üí Mostra il grafico.  \n",
    "\n",
    "---\n",
    "### **Stampa dei Risultati**\n",
    "```python\n",
    "print(f\"Average balance after {n_spins} spins: ${mean_balance:.2f}\")\n",
    "print(f\"Standard deviation of balance: ${std_dev_balance:.2f}\")\n",
    "```\n",
    "24. **Stampa del saldo medio e deviazione standard**  \n",
    "    - Il saldo medio finale dopo 100 giri viene stampato con due decimali.  \n",
    "    - La deviazione standard indica la variabilit√† nei risultati.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusione**\n",
    "Questo codice esegue una **simulazione Monte Carlo** su un gioco di roulette in cui il giocatore punta sempre sul nero. I risultati mostrano come il saldo finale varia tra le partite e come, nel lungo periodo, la casa tende ad avere un vantaggio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064218ee-66aa-4f78-bbf7-db124653734b",
   "metadata": {},
   "source": [
    "# Teorema del Limite Centrale (Central Limit Theorem - CLT)\n",
    "\n",
    "## Introduzione\n",
    "Il **Teorema del Limite Centrale (CLT - Central Limit Theorem)** √® uno dei concetti fondamentali della statistica inferenziale. Esso afferma che, indipendentemente dalla distribuzione della popolazione di partenza, la distribuzione della media campionaria si avvicina sempre di pi√π a una distribuzione normale all'aumentare della dimensione del campione.\n",
    "\n",
    "Questo teorema √® essenziale perch√© permette di applicare metodi statistici basati sulla normalit√† anche quando la distribuzione originale dei dati non √® normale. In particolare, ci consente di effettuare inferenze sulle popolazioni basandoci solo su campioni.\n",
    "\n",
    "## Dichiarazione formale del CLT\n",
    "Data una popolazione con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), se estraiamo molti campioni casuali di grandezza \\(n\\) e calcoliamo la media di ciascun campione, allora:\n",
    "\n",
    "1. La distribuzione delle medie campionarie tender√† a seguire una **distribuzione normale** man mano che \\(n\\) aumenta (tipicamente \\(n \\geq 30\\) √® sufficiente).\n",
    "2. La media della distribuzione delle medie campionarie sar√† uguale alla media della popolazione:  \n",
    "   \\[$\\mu_{\\bar{x}} = \\mu$\\]\n",
    "3. La deviazione standard della distribuzione delle medie campionarie, nota come **errore standard della media**, sar√† pari a:  \n",
    "   \\[$\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}$\\]\n",
    "\n",
    "### Implicazioni del CLT\n",
    "- Anche se la popolazione originale ha una distribuzione non normale, la distribuzione delle medie campionarie sar√† **approssimativamente normale**.\n",
    "- Questo √® fondamentale per l'inferenza statistica, poich√© consente di utilizzare test parametrici basati sulla normalit√†.\n",
    "\n",
    "---\n",
    "\n",
    "## Esempio Pratico con Python\n",
    "Per comprendere meglio il CLT, possiamo fare un esperimento pratico generando dati da una distribuzione **esponenziale** (che non √® normale) e calcolando le medie di campioni ripetuti.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definiamo la dimensione del campione\n",
    "sample_size = 10000\n",
    "\n",
    "# Creiamo 10.000 medie campionarie da una distribuzione esponenziale\n",
    "sample_means = [np.mean(np.random.exponential(1/4, sample_size)) for _ in range(10000)]\n",
    "\n",
    "# Creiamo l'istogramma delle medie campionarie\n",
    "plt.hist(sample_means, bins=30, density=True, color='red', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Central Limit Theorem\")\n",
    "plt.xlabel(\"Sample means\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Spiegazione del codice\n",
    "1. Generiamo una popolazione da una distribuzione esponenziale con tasso \\(\\lambda = 4\\) (che ha una forma fortemente asimmetrica).\n",
    "2. Estraiamo 10.000 campioni di dimensione \\(n = 10000\\) e calcoliamo la media di ciascun campione.\n",
    "3. Plottiamo l'istogramma delle medie campionarie.\n",
    "4. Osserviamo che la distribuzione risultante √® **approssimativamente normale**, nonostante la distribuzione di partenza fosse esponenziale.\n",
    "\n",
    "---\n",
    "\n",
    "## Dimostrazione del CLT tramite Simulazione\n",
    "Per dimostrare ulteriormente il CLT, possiamo provare con diverse distribuzioni di partenza e osservare come si comporta la distribuzione delle medie campionarie.\n",
    "\n",
    "### 1. Distribuzione Uniforme\n",
    "```python\n",
    "sample_size = 100\n",
    "sample_means = [np.mean(np.random.uniform(0, 10, sample_size)) for _ in range(10000)]\n",
    "plt.hist(sample_means, bins=30, density=True, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"CLT con distribuzione uniforme\")\n",
    "plt.xlabel(\"Sample means\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. Distribuzione di Poisson\n",
    "```python\n",
    "sample_size = 50\n",
    "sample_means = [np.mean(np.random.poisson(5, sample_size)) for _ in range(10000)]\n",
    "plt.hist(sample_means, bins=30, density=True, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"CLT con distribuzione di Poisson\")\n",
    "plt.xlabel(\"Sample means\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Come si pu√≤ vedere, indipendentemente dalla distribuzione originale (uniforme, esponenziale, Poisson), la distribuzione delle medie campionarie tende a una **distribuzione normale**.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusioni\n",
    "Il **Teorema del Limite Centrale** √® un principio fondamentale della statistica che permette di trattare molte situazioni pratiche con strumenti basati sulla normalit√†. In particolare:\n",
    "\n",
    "- √à alla base delle tecniche di inferenza statistica.\n",
    "- Ci permette di stimare intervalli di confidenza e condurre test statistici parametrici.\n",
    "- Dimostra che, anche se i dati originali non sono normali, le medie campionarie lo saranno per campioni sufficientemente grandi.\n",
    "\n",
    "Il CLT √® un potente strumento per analizzare dati reali e fare inferenze affidabili, motivo per cui √® uno dei concetti pi√π importanti per chiunque lavori con la statistica e l'analisi dei dati.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069853a1-fd3c-4004-a22d-01252e254391",
   "metadata": {},
   "source": [
    "# Errori Standard e Intervalli di Confidenza\n",
    "\n",
    "## 1. Introduzione\n",
    "\n",
    "L'inferenza statistica ci permette di fare delle stime educative su un parametro della popolazione basandoci su un campione. Tuttavia, a causa della variabilit√† del campionamento, ogni stima (statistica) basata su un campione non sar√† esattamente uguale al vero parametro della popolazione. Per quantificare questa incertezza, utilizziamo l'**errore standard (SE)** e gli **intervalli di confidenza (CI)**.\n",
    "\n",
    "### Errore Standard (SE)\n",
    "L'**errore standard** misura la variabilit√† di una statistica campionaria da un campione all'altro. Quantifica quanto una stima del campione √® destinata a fluttuare a causa del campionamento casuale.\n",
    "\n",
    "Matematicamente, l'errore standard della media (SEM) √® dato da:\n",
    "\\[$\n",
    "SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$\\]\n",
    "dove:\n",
    "- \\($ \\sigma $\\) √® la deviazione standard della popolazione\n",
    "- \\($ n $\\) √® la dimensione del campione\n",
    "\n",
    "Se la deviazione standard della popolazione \\( \\sigma \\) √® sconosciuta, la stimiamo utilizzando la deviazione standard del campione \\( s \\):\n",
    "\\[$\n",
    "SE = \\frac{s}{\\sqrt{n}}\n",
    "$\\]\n",
    "\n",
    "L'errore standard √® fondamentale perch√© determina la precisione della nostra stima del campione. Un SE pi√π piccolo indica una stima pi√π precisa.\n",
    "\n",
    "---\n",
    "## 2. Intervalli di Confidenza (CI)\n",
    "Un **intervallo di confidenza** fornisce un intervallo di valori plausibili per un parametro della popolazione con un livello di confidenza specificato (ad esempio, 95%). Esso √® composto da una **stima** pi√π o meno un **margine di errore (ME)**.\n",
    "\n",
    "### Formula Generale per gli Intervalli di Confidenza\n",
    "\\[$\n",
    "CI = \\text{stima} \\pm (\\text{valore critico} \\times \\text{errore standard})\n",
    "$\\]\n",
    "\n",
    "Ad esempio, l'intervallo di confidenza per la media della popolazione \\( \\mu \\) √® dato da:\n",
    "\\[$\n",
    "CI = \\bar{x} \\pm (z^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "- \\($ \\bar{x} $\\) √® la media del campione\n",
    "- \\($ z^*$ \\) √® il valore critico dalla distribuzione normale standard (per campioni grandi, o quando la varianza della popolazione √® conosciuta)\n",
    "- \\($ SE $\\) √® l'errore standard\n",
    "\n",
    "Se la varianza della popolazione √® sconosciuta e la dimensione del campione √® piccola (tipicamente \\( n < 30 \\)), si utilizza la **distribuzione t** invece della distribuzione normale:\n",
    "\\[$\n",
    "CI = \\bar{x} \\pm (t^* \\times SE)\n",
    "$\\]\n",
    "dove \\($ t^* $\\) √® il valore critico dalla **distribuzione t** con \\($ n - 1$ \\) gradi di libert√†.\n",
    "\n",
    "### Scelta del Valore Critico\n",
    "Il valore critico corrisponde al livello di **confidenza desiderato (CL)**. I livelli di confidenza pi√π comuni e i loro valori critici corrispondenti (per una distribuzione normale) sono:\n",
    "\n",
    "| Livello di Confidenza | Valore \\( z^* \\) |\n",
    "|-----------------------|------------------|\n",
    "| 90%                   | 1.645            |\n",
    "| 95%                   | 1.960            |\n",
    "| 99%                   | 2.576            |\n",
    "\n",
    "Per campioni piccoli, i valori \\( t^* \\) si ottengono da tabelle statistiche.\n",
    "\n",
    "---\n",
    "## 3. Interpretazione degli Intervalli di Confidenza\n",
    "Un **intervallo di confidenza del 95%** significa che se ripetessimo il nostro processo di campionamento molte volte, circa il 95% degli intervalli risultanti conterranno il vero parametro della popolazione.\n",
    "\n",
    "### Esempio:\n",
    "Supponiamo di raccogliere un campione di 50 individui per stimare l'altezza media in una popolazione. La media del campione √® di \\( 170 \\) cm, e la deviazione standard del campione √® di \\( 10 \\) cm.\n",
    "\n",
    "1. Calcoliamo l'errore standard (SE):\n",
    "   \\[$\n",
    "   SE = \\frac{10}{\\sqrt{50}} = 1.414\n",
    "   $\\]\n",
    "2. Determiniamo il valore critico per un intervallo di confidenza al 95%: \\( z^* = 1.96 \\)\n",
    "3. Calcoliamo il margine di errore (ME):\n",
    "   \\[$\n",
    "   ME = 1.96 \\times 1.414 = 2.77\n",
    "  $ \\]\n",
    "4. Calcoliamo l'intervallo di confidenza:\n",
    "   \\[$\n",
    "   170 \\pm 2.77 = (167.23, 172.77)\n",
    "  $ \\]\n",
    "Pertanto, stimiamo con il 95% di confidenza che la vera altezza media nella popolazione sia tra **167.23 cm e 172.77 cm**.\n",
    "\n",
    "---\n",
    "## 4. Fattori che Influenzano gli Intervalli di Confidenza\n",
    "Diversi fattori influenzano la larghezza di un intervallo di confidenza:\n",
    "1. **Dimensione del campione (n):** Un campione pi√π grande riduce l'errore standard, portando a un **intervallo di confidenza pi√π stretto**.\n",
    "2. **Livello di confidenza:** Livelli di confidenza pi√π alti (ad esempio, 99%) aumentano il valore critico, portando a un **intervallo di confidenza pi√π ampio**.\n",
    "3. **Variabilit√† nei dati:** Maggiore variabilit√† (deviazione standard pi√π alta) porta a un **intervallo di confidenza pi√π ampio**.\n",
    "\n",
    "---\n",
    "## 5. Intervalli di Confidenza per Altre Statistiche\n",
    "### 5.1. Intervallo di Confidenza per una Proporzione\n",
    "Per una proporzione della popolazione \\( p \\), l'intervallo di confidenza si calcola come:\n",
    "\\[$\n",
    "CI = \\hat{p} \\pm (z^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "- \\( $\\hat{p}$ \\) √® la proporzione del campione\n",
    "- \\($ SE = \\sqrt{\\frac{\\hat{p} (1 - \\hat{p})}{n}} $\\)\n",
    "\n",
    "### 5.2. Intervallo di Confidenza per la Differenza tra Due Medie\n",
    "Quando si confrontano due gruppi indipendenti (ad esempio, trattamento vs. controllo), l'intervallo di confidenza per la differenza tra le medie √®:\n",
    "\\[$\n",
    "CI = (\\bar{x}_1 - \\bar{x}_2) \\pm (t^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "\\[$$\n",
    "SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n",
    "\\]\n",
    "e \\($ s_1, s_2 $\\) sono le deviazioni standard dei campioni.\n",
    "\n",
    "### 5.3. Intervallo di Confidenza per la Differenza tra Due Proporzioni\n",
    "Per due proporzioni della popolazione \\( p_1 \\) e \\( p_2 \\):\n",
    "\\[$\n",
    "CI = (\\hat{p}_1 - \\hat{p}_2) \\pm (z^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "\\[$\n",
    "SE = \\sqrt{\\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}}\n",
    "$\\]\n",
    "\n",
    "---\n",
    "## 6. Conclusione\n",
    "Gli intervalli di confidenza forniscono un metodo essenziale per quantificare l'incertezza delle stime basate su un campione. Essi dipendono dall'errore standard, dalla dimensione del campione e dal livello di confidenza scelto. Una comprensione corretta e l'applicazione degli intervalli di confidenza consentono di prendere decisioni informate nella ricerca scientifica, nell'analisi aziendale e negli studi sanitari.\n",
    "\n",
    "Padroneggiando gli errori standard e gli intervalli di confidenza, √® possibile valutare l'affidabilit√† dei dati e trarre conclusioni significative dalle analisi statistiche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a991a-e043-4e57-9c76-3dfcc00de40c",
   "metadata": {},
   "source": [
    "Ecco una spiegazione riga per riga del codice:\n",
    "\n",
    "---\n",
    "\n",
    "### **Importazione delle librerie**\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "- `scipy.stats`: Modulo di `SciPy` per calcolare il valore critico della distribuzione normale.\n",
    "- `numpy`: Utilizzato per generare dati casuali e calcolare statistiche.\n",
    "- `matplotlib.pyplot`: Serve per creare il grafico delle confidence intervals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Generazione della popolazione**\n",
    "```python\n",
    "population = np.random.normal(loc=100, scale=15, size=100000)\n",
    "```\n",
    "- Generiamo una **popolazione** di 100.000 elementi da una distribuzione **normale** con:\n",
    "  - Media (`loc=100`)\n",
    "  - Deviazione standard (`scale=15`)\n",
    "  - Dimensione (`size=100000`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Campionamento senza sostituzione**\n",
    "```python\n",
    "sample_size = 100000\n",
    "sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "```\n",
    "- Estraiamo un **campione** di dimensione 100.000 **senza sostituzione** (`replace=False`) dalla popolazione.\n",
    "\n",
    "---\n",
    "\n",
    "### **Calcolo delle statistiche campionarie**\n",
    "```python\n",
    "sample_mean = np.mean(sample)\n",
    "sample_std = np.std(sample, ddof=1)\n",
    "standard_error = sample_std / np.sqrt(sample_size)\n",
    "```\n",
    "- `sample_mean`: Media del campione.\n",
    "- `sample_std`: Deviazione standard del campione, con `ddof=1` per applicare la **correzione di Bessel** (utilizzata per stimare la deviazione standard della popolazione).\n",
    "- `standard_error`: L'**errore standard** della media √® calcolato come:\n",
    "  \\[\n",
    "  SE = \\frac{\\text{sample_std}}{\\sqrt{\\text{sample_size}}}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Determinazione del valore critico z per il 95% CI**\n",
    "```python\n",
    "confidence_level = 0.95\n",
    "z_critical = stats.norm.ppf((1 + confidence_level) / 2)\n",
    "```\n",
    "- Il **valore critico z** (z-score) per un intervallo di confidenza del **95%** viene calcolato usando `stats.norm.ppf()`, che restituisce il quantile della distribuzione normale.\n",
    "- Poich√© il livello di confidenza √® **95%**, calcoliamo il quantile corrispondente a:\n",
    "  \\[\n",
    "  \\frac{1 + 0.95}{2} = 0.975\n",
    "  \\]\n",
    "  Il valore di **z** per il 95% √® **circa 1.96**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Calcolo del margine di errore e intervallo di confidenza**\n",
    "```python\n",
    "margin_of_error = z_critical * standard_error\n",
    "ci_lower, ci_upper = sample_mean - margin_of_error, sample_mean + margin_of_error\n",
    "```\n",
    "- `margin_of_error`: Determina l'ampiezza dell'intervallo di confidenza.\n",
    "  \\[\n",
    "  ME = z^* \\times SE\n",
    "  \\]\n",
    "- `ci_lower`, `ci_upper`: Calcoliamo il **limite inferiore** e **superiore** dell'intervallo di confidenza.\n",
    "\n",
    "---\n",
    "\n",
    "### **Stampa dei risultati**\n",
    "```python\n",
    "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "```\n",
    "- Stampiamo la **media campionaria** e l'**intervallo di confidenza** con due cifre decimali.\n",
    "\n",
    "---\n",
    "\n",
    "### **Simulazione di pi√π intervalli di confidenza**\n",
    "```python\n",
    "n_simulations = 100  # Number of confidence intervals to generate\n",
    "sample_size = 50\n",
    "true_mean = np.mean(population)\n",
    "```\n",
    "- `n_simulations = 100`: Generiamo **100** intervalli di confidenza.\n",
    "- `sample_size = 50`: La dimensione del campione per ogni simulazione √® **50**.\n",
    "- `true_mean = np.mean(population)`: Calcoliamo la **vera media della popolazione**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Creazione del grafico**\n",
    "```python\n",
    "plt.figure(figsize=(8, 6))\n",
    "```\n",
    "- Imposta la dimensione del grafico **8x6**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Generazione degli intervalli di confidenza multipli**\n",
    "```python\n",
    "for i in range(n_simulations):\n",
    "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "    sample_mean = np.mean(sample)\n",
    "    standard_error = np.std(sample, ddof=1) / np.sqrt(sample_size)\n",
    "    margin_of_error = z_critical * standard_error\n",
    "    ci_lower, ci_upper = sample_mean - margin_of_error, sample_mean + margin_of_error\n",
    "```\n",
    "- Per **ogni simulazione**, eseguiamo i seguenti passi:\n",
    "  1. **Estrazione di un campione** di 50 osservazioni dalla popolazione.\n",
    "  2. **Calcolo della media campionaria**.\n",
    "  3. **Calcolo dell'errore standard**.\n",
    "  4. **Determinazione del margine di errore** e dei **limiti dell'intervallo di confidenza**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Plot degli intervalli di confidenza**\n",
    "```python\n",
    "plt.plot([ci_lower, ci_upper], [i, i], color='blue' if (ci_lower <= true_mean <= ci_upper) else 'red')\n",
    "plt.plot(sample_mean, i, 'bo')  # Sample mean point\n",
    "```\n",
    "- Disegniamo **una linea orizzontale** per ogni intervallo di confidenza:\n",
    "  - Se l'intervallo contiene la vera media della popolazione (`true_mean`), la linea √® **blu**.\n",
    "  - Se l'intervallo **non** contiene la vera media, la linea √® **rossa** (questo dovrebbe accadere in circa il 5% dei casi, in base alla teoria degli intervalli di confidenza al 95%).\n",
    "- `plt.plot(sample_mean, i, 'bo')`: Plotta la **media campionaria** come un punto **blu**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Linea della media della popolazione**\n",
    "```python\n",
    "plt.axvline(true_mean, color='black', linestyle=\"--\", label=\"True Mean\")\n",
    "```\n",
    "- Disegniamo una **linea verticale tratteggiata nera** per rappresentare la **vera media della popolazione**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Etichette e visualizzazione del grafico**\n",
    "```python\n",
    "plt.xlabel(\"Sample Mean with Confidence Interval\")\n",
    "plt.ylabel(\"Simulation Index\")\n",
    "plt.title(\"Multiple 95% Confidence Intervals\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "- `plt.xlabel(\"Sample Mean with Confidence Interval\")`: Etichetta dell'asse X.\n",
    "- `plt.ylabel(\"Simulation Index\")`: Etichetta dell'asse Y.\n",
    "- `plt.title(\"Multiple 95% Confidence Intervals\")`: Titolo del grafico.\n",
    "- `plt.legend()`: Aggiunge la legenda.\n",
    "- `plt.show()`: Mostra il grafico.\n",
    "\n",
    "---\n",
    "\n",
    "### **Risultato atteso**\n",
    "- Il grafico mostra **100 intervalli di confidenza**.\n",
    "- Circa **95 su 100** dovrebbero contenere la vera media della popolazione (**blu**).\n",
    "- Circa **5 su 100** potrebbero **non** contenere la vera media (**rosso**).\n",
    "\n",
    "Questa simulazione aiuta a **visualizzare il concetto degli intervalli di confidenza** e a comprendere l'incertezza nelle stime statistiche. üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b1b41-a53c-4c0f-811e-18e607ad0555",
   "metadata": {},
   "source": [
    "# **Lezione dettagliata sul Bootstrap**\n",
    "\n",
    "## **Introduzione**\n",
    "\n",
    "Il **Bootstrap** √® un metodo di **ri campionamento** utilizzato per stimare la distribuzione di una statistica (media, mediana, varianza, ecc.) attraverso campionamenti ripetuti con riposizionamento (*with replacement*) dai dati originali.\n",
    "\n",
    "Questa tecnica √® particolarmente utile quando:\n",
    "- La distribuzione della popolazione √® **sconosciuta** o complessa.\n",
    "- La dimensione del campione √® **piccola** e i metodi teorici tradizionali potrebbero non essere affidabili.\n",
    "- Si desidera **costruire intervalli di confidenza** o stimare l'errore standard di una statistica senza dover fare assunzioni parametriche.\n",
    "\n",
    "## **Principi Fondamentali**\n",
    "\n",
    "1. **Campionamento con riposizionamento**: ogni osservazione ha la possibilit√† di essere selezionata pi√π volte in ogni campione bootstrap.\n",
    "2. **Ripetizione del processo**: si ripete il processo di campionamento molte volte (tipicamente 1000 o pi√π iterazioni).\n",
    "3. **Calcolo delle statistiche**: su ogni campione estratto si calcola la statistica di interesse (es. media, mediana, varianza).\n",
    "4. **Distribuzione delle statistiche**: dopo aver generato molti valori della statistica, possiamo approssimare la sua distribuzione empirica.\n",
    "5. **Stima dell'incertezza**: si usano i dati ottenuti per calcolare errori standard, intervalli di confidenza e altre misure di incertezza.\n",
    "\n",
    "## **Esempio pratico con Python**\n",
    "\n",
    "Utilizziamo Python per implementare il bootstrap su dati generati da una distribuzione esponenziale.\n",
    "\n",
    "### **Passo 1: Importazione delle librerie**\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "### **Passo 2: Creazione del dataset**\n",
    "Per il nostro esempio, generiamo 100 dati da una distribuzione **esponenziale** con parametro \\( \\lambda = 1/3 \\).\n",
    "```python\n",
    "np.random.seed(42)  # Per rendere i risultati riproducibili\n",
    "lambda_param = 1 / 3\n",
    "\n",
    "# Generazione dei dati\n",
    "n_samples = 100\n",
    "data = np.random.exponential(scale=1/lambda_param, size=n_samples)\n",
    "```\n",
    "\n",
    "### **Passo 3: Implementazione del Bootstrap**\n",
    "Scriviamo una funzione che esegua il ri campionamento bootstrap e calcoli la statistica desiderata (in questo caso la **mediana**).\n",
    "```python\n",
    "def bootstrap_resample(data, statistic_func, n_bootstrap_samples):\n",
    "    \"\"\"\n",
    "    Esegue il Bootstrap per stimare la distribuzione di una statistica.\n",
    "    \n",
    "    Parametri:\n",
    "    - data: array di dati originali\n",
    "    - statistic_func: funzione statistica da applicare ai campioni\n",
    "    - n_bootstrap_samples: numero di campioni bootstrap da generare\n",
    "    \n",
    "    Ritorna:\n",
    "    - Un array contenente i valori della statistica su ogni campione bootstrap\n",
    "    \"\"\"\n",
    "    bootstrap_stats = []\n",
    "    n = len(data)\n",
    "    \n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        sample = np.random.choice(data, size=n, replace=True)  # Estrazione con riposizionamento\n",
    "        bootstrap_stats.append(statistic_func(sample))\n",
    "    \n",
    "    return np.array(bootstrap_stats)\n",
    "```\n",
    "\n",
    "### **Passo 4: Calcolo dell'errore standard e intervallo di confidenza**\n",
    "Ora applichiamo il metodo per stimare la distribuzione della mediana dei dati e calcolare un **intervallo di confidenza del 95%**.\n",
    "```python\n",
    "n_bootstrap_samples = 10000  # Numero di campioni bootstrap\n",
    "bootstrap_medians = bootstrap_resample(data, np.median, n_bootstrap_samples)\n",
    "\n",
    "# Calcolo dell'errore standard\n",
    "standard_error = np.std(bootstrap_medians)\n",
    "\n",
    "# Intervallo di confidenza al 95%\n",
    "ci_lower = np.percentile(bootstrap_medians, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_medians, 97.5)\n",
    "\n",
    "print(f\"Bootstrap Standard Error: {standard_error:.3f}\")\n",
    "print(f\"95% Bootstrap Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "```\n",
    "#### **Risultati attesi (variano leggermente a seconda del campione generato):**\n",
    "```\n",
    "Bootstrap Standard Error: 0.345\n",
    "95% Bootstrap Confidence Interval: [1.193, 2.520]\n",
    "```\n",
    "\n",
    "### **Passo 5: Visualizzazione della distribuzione bootstrap**\n",
    "Per avere un'idea della distribuzione della mediana stimata:\n",
    "```python\n",
    "plt.hist(bootstrap_medians, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(ci_lower, color='red', linestyle='dashed', label='2.5 percentile')\n",
    "plt.axvline(ci_upper, color='red', linestyle='dashed', label='97.5 percentile')\n",
    "plt.xlabel('Mediana Bootstrap')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.title('Distribuzione Bootstrap della Mediana')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## **Vantaggi del Bootstrap**\n",
    "- **Non richiede ipotesi sulla distribuzione**: Funziona bene anche quando la distribuzione dei dati √® sconosciuta.\n",
    "- **Facile da implementare**: Non richiede formule matematiche complesse.\n",
    "- **Adattabile a molte statistiche**: Pu√≤ essere usato per medie, mediane, deviazioni standard e molte altre metriche.\n",
    "- **Utile per piccoli campioni**: Permette di ottenere stime affidabili anche quando il dataset √® ridotto.\n",
    "\n",
    "## **Svantaggi e Limiti**\n",
    "- **Computazionalmente intensivo**: Richiede molte iterazioni, quindi √® pi√π lento rispetto ai metodi analitici tradizionali.\n",
    "- **Non sempre applicabile**: Se i dati hanno forte dipendenza tra loro (es. serie temporali), il metodo potrebbe non essere affidabile.\n",
    "\n",
    "## **Conclusione**\n",
    "Il Bootstrap √® una tecnica estremamente potente e flessibile per stimare la distribuzione di una statistica e costruire intervalli di confidenza senza fare forti assunzioni sui dati. Grazie alla sua semplicit√† e robustezza, √® uno strumento essenziale nell'analisi dei dati e nella statistica computazionale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22102413-0bc1-457f-ad09-12c1080233d0",
   "metadata": {},
   "source": [
    "# Test delle ipotesi e t-test\n",
    "\n",
    "## Introduzione\n",
    "Il **test delle ipotesi** (\n",
    "Hypothesis Testing) √® una tecnica statistica utilizzata per valutare se un'asserzione riguardante un insieme di dati √® supportata dall'evidenza empirica.\n",
    "Esistono diversi tipi di test di significativit√†, che variano a seconda del tipo di dati, del numero di campioni e della misura che si desidera confrontare.\n",
    "Uno dei test pi√π comuni √® il **t-test**, utilizzato per confrontare le medie di due gruppi quando i dati sono numerici e seguono una distribuzione normale.\n",
    "\n",
    "---\n",
    "## Definizione delle ipotesi\n",
    "Prima di condurre un test statistico, si formulano due ipotesi:\n",
    "- **Ipotesi nulla (H‚ÇÄ)**: afferma che non c'√® differenza significativa tra i gruppi.\n",
    "- **Ipotesi alternativa (H‚ÇÅ)**: afferma che esiste una differenza significativa tra i gruppi.\n",
    "\n",
    "Nel caso del nostro esempio:\n",
    "- **H‚ÇÄ**: Il trattamento non ha effetto sulla pressione sanguigna (le due medie sono uguali).\n",
    "- **H‚ÇÅ**: Il trattamento ha un effetto sulla pressione sanguigna (le due medie sono diverse).\n",
    "\n",
    "---\n",
    "## Il t-test per il confronto delle medie\n",
    "Il **t-test indipendente** (\n",
    "t-test for independent samples) viene utilizzato quando vogliamo confrontare le medie di due gruppi indipendenti tra loro.\n",
    "\n",
    "La formula del test t √®:\n",
    "\\[$\n",
    "t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$\\]\n",
    "dove:\n",
    "- \\($\\bar{X_1}\\) e \\(\\bar{X_2}$\\) sono le medie dei due gruppi,\n",
    "- \\($s_1^2\\) e \\(s_2^2$\\) sono le varianze campionarie,\n",
    "- \\($n_1\\) e \\(n_2$\\) sono le dimensioni campionarie dei due gruppi.\n",
    "\n",
    "Il valore di t ottenuto viene confrontato con una distribuzione **t di Student** per determinare se la differenza tra le medie √® statisticamente significativa.\n",
    "\n",
    "---\n",
    "## Implementazione in Python\n",
    "Eseguiamo ora un esempio pratico con Python utilizzando `numpy` e `scipy.stats`.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Impostiamo il seed per la riproducibilit√†\n",
    "np.random.seed(42)\n",
    "\n",
    "# Definiamo la dimensione del campione\n",
    "sample_size = 50\n",
    "\n",
    "# Generiamo dati casuali per due gruppi\n",
    "placebo_group = np.random.normal(loc=120, scale=10, size=sample_size)  # Media 120, deviazione standard 10\n",
    "treatment_group = np.random.normal(loc=115, scale=10, size=sample_size)  # Media 115, deviazione standard 10\n",
    "\n",
    "# Calcoliamo il test t\n",
    "t_stat, p_value = stats.ttest_ind(placebo_group, treatment_group)\n",
    "\n",
    "# Definiamo il livello di significativit√†\n",
    "alpha = 0.05\n",
    "\n",
    "# Interpretazione del risultato\n",
    "test_result = \"Reject H0\" if p_value < alpha else \"Failed to reject H0\"\n",
    "print(test_result)\n",
    "\n",
    "# Visualizziamo la distribuzione t con le regioni critiche\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf = stats.t.pdf(x, df=len(placebo_group) + len(treatment_group) - 2)\n",
    "\n",
    "# Valori critici per il test a due code\n",
    "t_critical_two_tailed = stats.t.ppf(1 - alpha / 2, df=len(placebo_group) + len(treatment_group) - 2)\n",
    "\n",
    "# Grafico\n",
    "plt.plot(x, pdf, label=\"t-Distribution\", color=\"blue\")\n",
    "plt.fill_between(x, pdf, where=(x <= -t_critical_two_tailed) | (x >= t_critical_two_tailed),\n",
    "                 color=\"red\", alpha=0.5, label=\"Rejection Region\")\n",
    "plt.axvline(-t_critical_two_tailed, color=\"red\", linestyle=\"--\", label=f\"Critical Value (-{t_critical_two_tailed:.2f})\")\n",
    "plt.axvline(t_critical_two_tailed, color=\"red\", linestyle=\"--\", label=f\"Critical Value (+{t_critical_two_tailed:.2f})\")\n",
    "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"Test Statistic ({t_stat:.2f})\")\n",
    "plt.title(\"Two-Tailed Test (H‚ÇÄ: No BP Difference)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "## Interpretazione dei risultati\n",
    "Dopo aver eseguito il codice, otteniamo:\n",
    "1. **Valore di t-statistic**: misura la distanza tra le due medie rispetto alla variabilit√† dei dati.\n",
    "2. **p-value**: indica la probabilit√† di ottenere un risultato uguale o pi√π estremo sotto l'ipotesi nulla.\n",
    "3. **Decisione**:\n",
    "   - Se \\($p < \\alpha$\\), rifiutiamo H‚ÇÄ (evidenza a favore dell'effetto del trattamento).\n",
    "   - Se \\($p \\geq \\alpha$\\), non possiamo rifiutare H‚ÇÄ (non abbiamo abbastanza evidenza per affermare che il trattamento abbia effetto).\n",
    "\n",
    "Nel nostro esempio, il test potrebbe concludere con **\"Failed to reject H0\"**, suggerendo che non ci sia abbastanza evidenza per affermare che il trattamento abbia un effetto significativo sulla pressione sanguigna.\n",
    "\n",
    "---\n",
    "## Conclusione\n",
    "Il **t-test** √® uno strumento potente per confrontare le medie di due gruppi indipendenti. Tuttavia, bisogna assicurarsi che le sue **assunzioni** siano soddisfatte:\n",
    "- **Normalit√†**: i dati devono seguire una distribuzione normale (verificabile con un test di Shapiro-Wilk o un grafico Q-Q).\n",
    "- **Omogeneit√† delle varianze**: le varianze dei due gruppi dovrebbero essere simili (verificabile con il test di Levene o Bartlett).\n",
    "\n",
    "Se queste condizioni non sono rispettate, si possono usare test alternativi come il **test di Mann-Whitney U** o test di permutazione.\n",
    "\n",
    "Questa lezione offre una panoramica dettagliata del t-test e della sua implementazione in Python, utile per chiunque voglia approfondire l'analisi statistica nei dati biomedici e farmaceutici.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0df491-ec2b-4816-96dd-737f55163ea4",
   "metadata": {},
   "source": [
    "**Test di Ipotesi**\n",
    "\n",
    "Il test di ipotesi √® un concetto fondamentale in statistica che aiuta a determinare se ci sono prove sufficienti in un campione per inferire una particolare condizione su una popolazione. Esistono numerosi tipi di test di significativit√†, a seconda del tipo di dati, del numero di campioni e di cosa si sta misurando.\n",
    "\n",
    "Uno dei test pi√π comuni √® il **t-test**, utilizzato per confrontare due set di dati numerici.\n",
    "\n",
    "### **Esempio: t-test per l'analisi della pressione sanguigna**\n",
    "\n",
    "Supponiamo che stiamo testando un nuovo trattamento per vedere se ha un effetto sulla pressione sanguigna. Le nostre ipotesi nulla e alternativa sono:\n",
    "\n",
    "- **H‚ÇÄ (Ipotesi Nulla):** Il trattamento non ha effetto sulla pressione sanguigna.\n",
    "- **H‚ÇÅ (Ipotesi Alternativa):** Il trattamento ha effetto sulla pressione sanguigna.\n",
    "\n",
    "#### **Generazione dei Dati del Campione**\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dimensione_campione = 50\n",
    "gruppo_placebo = np.random.normal(loc=120, scale=10, size=dimensione_campione)\n",
    "gruppo_trattamento = np.random.normal(loc=115, scale=10, size=dimensione_campione)\n",
    "```\n",
    "\n",
    "#### **Esecuzione del t-test Indipendente**\n",
    "```python\n",
    "t_stat, p_value = stats.ttest_ind(gruppo_placebo, gruppo_trattamento)\n",
    "```\n",
    "\n",
    "#### **Decisione (Test a Due Code)**\n",
    "```python\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Rifiutiamo H‚ÇÄ\")\n",
    "else:\n",
    "    print(\"Non possiamo rifiutare H‚ÇÄ\")\n",
    "```\n",
    "\n",
    "#### **Visualizzazione della distribuzione t**\n",
    "```python\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf = stats.t.pdf(x, df=len(gruppo_placebo) + len(gruppo_trattamento) - 2)\n",
    "\n",
    "t_critico_due_code = stats.t.ppf(1 - alpha / 2, df=len(gruppo_placebo) + len(gruppo_trattamento) - 2)\n",
    "\n",
    "plt.plot(x, pdf, label=\"Distribuzione t\", color=\"blue\")\n",
    "plt.fill_between(x, pdf, where=(x <= -t_critico_due_code) | (x >= t_critico_due_code),\n",
    "                 color=\"red\", alpha=0.5, label=\"Zona di Rifiuto\")\n",
    "plt.axvline(-t_critico_due_code, color=\"red\", linestyle=\"--\", label=f\"Valore Critico (-{t_critico_due_code:.2f})\")\n",
    "plt.axvline(t_critico_due_code, color=\"red\", linestyle=\"--\", label=f\"Valore Critico (+{t_critico_due_code:.2f})\")\n",
    "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"Statistica del Test ({t_stat:.2f})\")\n",
    "plt.title(\"Test a Due Code (H‚ÇÄ: Nessuna Differenza BP)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Interpretazione:** Se la statistica del test cade nella zona di rifiuto (in rosso), rifiutiamo H‚ÇÄ; altrimenti, non possiamo rifiutarla.\n",
    "\n",
    "---\n",
    "\n",
    "### **t-test a Una Coda**\n",
    "Se vogliamo testare se il trattamento **abbassa** la pressione sanguigna (non solo se ha effetto in qualche modo), eseguiamo un **test a una coda**:\n",
    "\n",
    "```python\n",
    "p_value_una_coda = p_value / 2\n",
    "\n",
    "if p_value_una_coda < alpha:\n",
    "    print(\"Rifiutiamo H‚ÇÄ\")\n",
    "else:\n",
    "    print(\"Non possiamo rifiutare H‚ÇÄ\")\n",
    "```\n",
    "\n",
    "#### **Visualizzazione del Test a Una Coda**\n",
    "```python\n",
    "t_critico_una_coda = stats.t.ppf(1 - alpha, df=len(gruppo_placebo) + len(gruppo_trattamento) - 2)\n",
    "\n",
    "plt.plot(x, pdf, label=\"Distribuzione t\", color=\"blue\")\n",
    "plt.fill_between(x, pdf, where=(x <= -t_critico_una_coda), color=\"red\", alpha=0.5, label=\"Zona di Rifiuto\")\n",
    "plt.axvline(-t_critico_una_coda, color=\"red\", linestyle=\"--\", label=f\"Valore Critico ({-t_critico_una_coda:.2f})\")\n",
    "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"Statistica del Test ({t_stat:.2f})\")\n",
    "plt.title(\"Test a Una Coda (H‚ÇÄ: BP Non Inferiore)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Errore di Tipo I e Tipo II**\n",
    "- **Errore di Tipo I (Falso Positivo):** Rifiutare erroneamente un'ipotesi nulla vera.\n",
    "- **Errore di Tipo II (Falso Negativo):** Non rifiutare un'ipotesi nulla falsa.\n",
    "- **Potenza del Test:** La probabilit√† di rifiutare correttamente H‚ÇÄ quando H‚ÇÅ √® vera.\n",
    "\n",
    "#### **Analisi della Potenza per il t-test**\n",
    "```python\n",
    "import statsmodels.stats.power as smp\n",
    "\n",
    "dimensione_effetto = 0.5  # Dimensione dell'effetto media\n",
    "potenza = 0.8\n",
    "\n",
    "dimensione_campione = smp.tt_ind_solve_power(effect_size=dimensione_effetto, alpha=alpha, power=potenza, alternative='two-sided')\n",
    "dimensione_campione_una_coda = smp.tt_ind_solve_power(effect_size=dimensione_effetto, alpha=alpha, power=potenza, alternative='larger')\n",
    "\n",
    "print(f\"Dimensione del campione richiesta per una potenza dell'80%: {dimensione_campione:.0f}\")\n",
    "print(f\"Dimensione del campione richiesta per una potenza dell'80% nel caso a una coda: {dimensione_campione_una_coda:.0f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ANOVA (Analisi della Varianza)**\n",
    "Per confrontare pi√π di due gruppi, utilizziamo **ANOVA**, basato sulla **statistica F**.\n",
    "\n",
    "```python\n",
    "np.random.seed(42)\n",
    "\n",
    "dieta_1 = np.random.normal(loc=5, scale=2, size=30)\n",
    "dieta_2 = np.random.normal(loc=6, scale=2, size=30)\n",
    "dieta_3 = np.random.normal(loc=7, scale=2, size=30)\n",
    "\n",
    "f_stat, p_value_anova = stats.f_oneway(dieta_1, dieta_2, dieta_3)\n",
    "\n",
    "print(f\"Statistica F ANOVA: {f_stat:.3f}, p-value: {p_value_anova:.3f}\")\n",
    "```\n",
    "\n",
    "Se il p-value √® inferiore a 0.05, rifiutiamo H‚ÇÄ e concludiamo che almeno una media di gruppo √® significativamente diversa.\n",
    "\n",
    "---\n",
    "\n",
    "### **Test Chi-Square per Dati Categoriali**\n",
    "Per i dati categoriali, utilizziamo il **test chi-quadrato** per verificare se c'√® un'associazione tra variabili.\n",
    "\n",
    "```python\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "osservato = np.array([[50, 30],\n",
    "                      [20, 60]])\n",
    "\n",
    "chi2, p_value, _, _ = chi2_contingency(osservato)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Rifiutiamo H‚ÇÄ: C'√® un'associazione significativa tra genere e preferenza di voto.\")\n",
    "else:\n",
    "    print(\"Non possiamo rifiutare H‚ÇÄ: Nessuna associazione significativa rilevata.\")\n",
    "```\n",
    "\n",
    "Se il p-value √® maggiore di 0.05, **non rifiutiamo** H‚ÇÄ, il che significa che non c'√® una relazione significativa tra le due variabili."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841867f-b1a3-4ffa-a586-1bd466561f62",
   "metadata": {},
   "source": [
    "### Correlazione Lineare vs Monotonica\n",
    "\n",
    "1. **Introduzione alla Correlazione**  \n",
    "La correlazione √® una misura statistica che descrive la forza e la direzione della relazione tra due variabili. √à un concetto fondamentale nell'analisi dei dati, poich√© consente di comprendere come due variabili si influenzano reciprocamente.\n",
    "\n",
    "Esistono diversi tipi di correlazione, ma i pi√π comuni sono la correlazione lineare e la correlazione monotona. Questi due tipi di correlazione vengono utilizzati in contesti diversi e hanno applicazioni specifiche.\n",
    "\n",
    "2. **Correlazione Lineare**  \n",
    "La correlazione lineare √® una relazione tra due variabili che segue una retta. In altre parole, quando due variabili sono correlate linearmente, il cambiamento in una variabile √® associato a un cambiamento costante nell'altra variabile. Ad esempio, se una variabile aumenta, anche l'altra aumenter√† (o diminuir√†) in modo prevedibile.\n",
    "\n",
    "Il coefficiente di correlazione di Pearson √® la misura pi√π comune per calcolare la correlazione lineare. Esso assume valori compresi tra -1 e +1:\n",
    "\n",
    "- **+1**: correlazione positiva perfetta (le variabili aumentano insieme in modo proporzionale).\n",
    "- **-1**: correlazione negativa perfetta (una variabile aumenta mentre l'altra diminuisce in modo proporzionale).\n",
    "- **0**: nessuna correlazione lineare.\n",
    "\n",
    "Matematicamente, il coefficiente di Pearson √® definito come:\n",
    "\n",
    "\\[$\n",
    "r = \\frac{n \\sum{x y} - \\left( \\sum{x} \\right) \\left( \\sum{y} \\right)}{\\sqrt{n \\sum{x^2} - \\left( \\sum{x} \\right)^2} \\cdot \\sqrt{n \\sum{y^2} - \\left( \\sum{y} \\right)^2}}\n",
    "$\\]\n",
    "\n",
    "3. **Correlazione Monotona**  \n",
    "La correlazione monotona indica una relazione tra due variabili in cui una variabile tende a crescere o decrescere in modo coerente con l'altra, ma non necessariamente in modo lineare. La funzione che lega le due variabili pu√≤ essere crescente o decrescente, ma la velocit√† di cambiamento pu√≤ non essere costante, come avviene nella correlazione lineare.\n",
    "\n",
    "Il coefficiente di correlazione di Spearman √® utilizzato per misurare la correlazione monotona. La correlazione di Spearman si basa sui ranghi (o posizioni) delle variabili, piuttosto che sui loro valori reali. Anche in questo caso, i valori del coefficiente vanno da -1 a +1:\n",
    "\n",
    "- **+1**: relazione monotona crescente perfetta.\n",
    "- **-1**: relazione monotona decrescente perfetta.\n",
    "- **0**: nessuna correlazione monotona.\n",
    "\n",
    "4. **Differenze tra Correlazione Lineare e Monotona**\n",
    "\n",
    "- **Linearit√†**: La correlazione lineare implica che la relazione tra le variabili sia una retta, mentre la correlazione monotona non richiede una relazione retta.\n",
    "- **Tipo di relazione**: La correlazione lineare misura la relazione in cui il cambiamento di una variabile corrisponde a un cambiamento costante nell'altra variabile. La correlazione monotona, invece, non richiede questa costanza nel cambiamento, ma solo che l'ordine delle variabili sia coerente.\n",
    "- **Resistenza ai valori anomali (outliers)**: La correlazione di Pearson √® pi√π sensibile agli outliers rispetto alla correlazione di Spearman. Se ci sono dati anomali che deviano la relazione lineare, il coefficiente di Pearson potrebbe non essere un buon indicatore, mentre il coefficiente di Spearman pu√≤ essere pi√π robusto.\n",
    "\n",
    "5. **Esempio Pratico con Codice Python**  \n",
    "Nel codice seguente, esploreremo un esempio di dati con una relazione monotona ma non lineare tra due variabili. I dati seguiranno una funzione esponenziale, ma con l'aggiunta di rumore casuale per simulare un comportamento pi√π realistico.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Creiamo un dataset con una relazione monotona ma non lineare\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.exp(x) + np.random.normal(0, 50, size=len(x))  # Relazione esponenziale con rumore\n",
    "\n",
    "# Calcoliamo i coefficienti di Pearson e Spearman\n",
    "pearson_coeff, _ = pearsonr(x, y)\n",
    "spearman_coeff, _ = spearmanr(x, y)\n",
    "\n",
    "# Creiamo il grafico dei dati\n",
    "plt.scatter(x, y, label=f'Pearson Coefficient: {pearson_coeff:.2f}, Spearman Coefficient: {spearman_coeff:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "5.1 **Descrizione del Codice**\n",
    "\n",
    "- **Generazione dei Dati**: In questo esempio, abbiamo creato una variabile `x` che va da 0 a 10 e una variabile `y` che segue una relazione esponenziale con `x`, aggiungendo un po' di rumore casuale per rendere il modello pi√π realistico.\n",
    "- **Calcolo dei Coefficienti di Correlazione**:\n",
    "  - Il coefficiente di Pearson √® calcolato con `pearsonr(x, y)`, che restituisce una misura di quanto la relazione tra `x` e `y` sia lineare.\n",
    "  - Il coefficiente di Spearman √® calcolato con `spearmanr(x, y)`, che misura la forza della relazione monotona tra `x` e `y`, anche se non √® lineare.\n",
    "- **Visualizzazione dei Dati**: Abbiamo visualizzato i dati tramite un grafico a dispersione (scatter plot) per esaminare la relazione tra `x` e `y`.\n",
    "\n",
    "5.2 **Interpretazione del Grafico**\n",
    "\n",
    "Nel grafico, possiamo osservare come i punti siano distribuiti lungo una curva crescente, ma non seguano una retta. Questo suggerisce una relazione monotona crescente, ma non lineare.\n",
    "\n",
    "- **Coefficiente di Pearson**: Il coefficiente di Pearson potrebbe essere relativamente basso (approssimativamente vicino a 0) poich√© la relazione non √® lineare.\n",
    "- **Coefficiente di Spearman**: Il coefficiente di Spearman sar√† invece pi√π alto, indicando che, anche se la relazione non √® lineare, le variabili tendono a seguire un ordine crescente coerente.\n",
    "\n",
    "6. **Conclusione**  \n",
    "La correlazione lineare √® adatta per dati che mostrano una relazione diretta e proporzionale, mentre la correlazione monotona √® utile per misurare relazioni che non sono lineari, ma che comunque seguono un comportamento monotono (ovvero, un aumento o una diminuzione costante).  \n",
    "La correlazione di Pearson √® pi√π adatta per dati lineari, mentre la correlazione di Spearman √® pi√π robusta e utile per dati con una relazione monotona non lineare.  \n",
    "In conclusione, scegliere tra Pearson e Spearman dipende dalla natura dei dati che si stanno analizzando e dal tipo di relazione che si ipotizza tra le variabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3234-0313-4764-9c57-ed5dfe59858f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
