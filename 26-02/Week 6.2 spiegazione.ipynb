{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767203aa-33b8-4f16-94e0-ec46614a89a6",
   "metadata": {},
   "source": [
    "#  Descriptive Statistics\n",
    "\n",
    "Introduzione\n",
    "\n",
    "La statistica descrittiva è una branca della statistica che si occupa di raccogliere, organizzare, analizzare e presentare i dati in modo significativo. A differenza della statistica inferenziale, che si concentra sul fare previsioni basate su un campione di dati, la statistica descrittiva aiuta a comprendere le caratteristiche fondamentali dei dati a disposizione.\n",
    "\n",
    "1. Tipi di Statistica Descrittiva\n",
    "\n",
    "La statistica descrittiva può essere suddivisa in tre categorie principali:\n",
    "\n",
    "Misure di tendenza centrale: indicano il valore intorno al quale i dati tendono a concentrarsi.\n",
    "\n",
    "Misure di dispersione: descrivono quanto i dati sono sparsi attorno alla tendenza centrale.\n",
    "\n",
    "Misure di forma: indicano la distribuzione dei dati (asimmetria e curtosi).\n",
    "\n",
    "### 📊 **Measures of Central Tendency: Lezione Completa**  \n",
    "\n",
    "Le **misure di tendenza centrale** sono strumenti statistici utilizzati per descrivere un insieme di dati con un solo valore rappresentativo. Sono fondamentali nell'analisi dei dati perché forniscono un’indicazione sulla posizione del \"centro\" di una distribuzione.\n",
    "\n",
    "---\n",
    "## 📌 **1. Tipologie di Misure di Tendenza Centrale**\n",
    "Le tre principali misure di tendenza centrale sono:\n",
    "1. **Media (Mean)**\n",
    "2. **Mediana (Median)**\n",
    "3. **Moda (Mode)**\n",
    "\n",
    "Ognuna di queste ha caratteristiche, vantaggi e limiti specifici. Vediamole nel dettaglio.  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔢 **2. Media (Mean)**  \n",
    "La **media aritmetica** è la somma di tutti i valori divisa per il numero totale di osservazioni.\n",
    "\n",
    "### 📌 **Formula della Media**  \n",
    "$$ \n",
    "x\n",
    "ˉ = \\frac{\\sum x_i}{n}\n",
    "$$\n",
    "Dove:\n",
    "\n",
    "𝑥\n",
    "ˉ\n",
    "x\n",
    "ˉ\n",
    "  = media\n",
    "𝑥\n",
    "𝑖\n",
    "x \n",
    "i\n",
    "​\n",
    "  = valori dei dati\n",
    "𝑛\n",
    "n = numero totale di osservazioni\n",
    "✅ Esempio Pratico\n",
    "Supponiamo di avere i seguenti voti di uno studente:  \n",
    "**8, 9, 7, 10, 6**  \n",
    "\n",
    "La media sarà:  \n",
    "\\[$$\n",
    "\\bar{x} = \\frac{8+9+7+10+6}{5} = \\frac{40}{5} = 8$$\n",
    "\\]\n",
    "\n",
    "🔹 **Pro:** Facile da calcolare, tiene conto di tutti i valori.  \n",
    "🔹 **Contro:** Sensibile ai valori estremi (**outliers**).\n",
    "\n",
    "---\n",
    "## 📉 **3. Mediana (Median)**  \n",
    "La **mediana** è il valore centrale di un insieme di dati ordinati. Se il numero di osservazioni è pari, la mediana è la media dei due valori centrali.\n",
    "\n",
    "### ✅ **Esempio 1 (Numero Dispari di Osservazioni)**  \n",
    "Dati: **3, 5, 7, 9, 11**  \n",
    "La mediana è **7** perché è il valore centrale.\n",
    "\n",
    "### ✅ **Esempio 2 (Numero Pari di Osservazioni)**  \n",
    "Dati: **2, 4, 6, 8, 10, 12**  \n",
    "I due valori centrali sono **6** e **8**, quindi la mediana è:  \n",
    "\\[\n",
    "\\frac{6+8}{2} = 7\n",
    "\\]\n",
    "\n",
    "🔹 **Pro:** Non è influenzata dai valori estremi.  \n",
    "🔹 **Contro:** Non tiene conto di tutti i valori nel calcolo.\n",
    "\n",
    "---\n",
    "## 🎯 **4. Moda (Mode)**  \n",
    "La **moda** è il valore che compare più frequentemente in un dataset.  \n",
    "\n",
    "### ✅ **Esempio 1**  \n",
    "Dati: **2, 3, 3, 5, 7, 3, 8**  \n",
    "La moda è **3** perché appare più volte.\n",
    "\n",
    "### ✅ **Esempio 2 (Distribuzione Bimodale)**  \n",
    "Dati: **4, 4, 6, 6, 8, 9**  \n",
    "Qui abbiamo due valori con la stessa frequenza massima: **4 e 6**.  \n",
    "➡️ La distribuzione è **bimodale**.\n",
    "\n",
    "🔹 **Pro:** Utile per dati categorici e distribuzioni irregolari.  \n",
    "🔹 **Contro:** Può non esistere o esserci più di una moda.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 **5. Confronto tra Media, Mediana e Moda**\n",
    "| Proprietà  | Media | Mediana | Moda |\n",
    "|------------|------|---------|------|\n",
    "| **Uso tipico** | Dati numerici continui | Dati numerici con outliers | Dati categorici o distribuzioni non normali |\n",
    "| **Sensibile agli outliers?** | ✅ Sì | ❌ No | ❌ No |\n",
    "| **Facilità di calcolo** | ✅ Facile | ✅ Facile | ⚠️ A volte complesso |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 **6. Quando Usare Ciascuna Misura?**\n",
    "- **Media**: Quando i dati sono distribuiti in modo normale e non ci sono outliers.  \n",
    "- **Mediana**: Quando ci sono outliers o la distribuzione è asimmetrica.  \n",
    "- **Moda**: Quando analizziamo dati categorici (es. il colore più scelto da un campione di persone).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔎 **7. Esempio Pratico in Python**\n",
    "Vediamo come calcolare queste misure con Python:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Dataset\n",
    "dati = [8, 9, 7, 10, 6, 100]  # Notiamo un outlier (100)\n",
    "\n",
    "# Calcolo delle misure di tendenza centrale\n",
    "media = np.mean(dati)\n",
    "mediana = np.median(dati)\n",
    "moda = stats.mode(dati, keepdims=True).mode[0]\n",
    "\n",
    "print(f\"Media: {media}\")\n",
    "print(f\"Mediana: {mediana}\")\n",
    "print(f\"Moda: {moda}\")\n",
    "```\n",
    "\n",
    "🔹 **Output:**\n",
    "```\n",
    "Media: 23.333\n",
    "Mediana: 8.5\n",
    "Moda: 6\n",
    "```\n",
    "📌 **Nota:** L'outlier (100) ha distorto la media, mentre la mediana rimane più stabile!\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 **8. Conclusione**\n",
    "Le **misure di tendenza centrale** sono fondamentali per riassumere i dati in modo efficace. La scelta della misura giusta dipende dal contesto e dalla distribuzione dei dati.\n",
    "\n",
    "## 📊 **Measures of Dispersion: Concetti, Formule ed Esempi**  \n",
    "\n",
    "Le **misure di dispersione** (o **variabilità**) descrivono quanto i dati siano sparpagliati o distanti tra loro rispetto a una misura di tendenza centrale (come la media o la mediana). Sono fondamentali per capire la distribuzione di un dataset.  \n",
    "\n",
    "### 🔹 **Perché sono importanti?**\n",
    "- Permettono di confrontare la variabilità di diversi dataset.\n",
    "- Aiutano a identificare la presenza di valori anomali (outlier).\n",
    "- Sono essenziali per interpretare correttamente i risultati statistici.\n",
    "\n",
    "## 🚀 **Tipologie di Measures of Dispersion**  \n",
    "\n",
    "### **1️⃣ Range (Intervallo)**\n",
    "📌 **Definizione**: È la differenza tra il valore massimo e il valore minimo di un dataset.  \n",
    "📌 **Formula**:  \n",
    "\\[$$\n",
    "\\text{Range} = \\max(X) - \\min(X)$$\n",
    "\\]\n",
    "📌 **Esempio**:  \n",
    "Dati: \\($$ X = \\{3, 7, 8, 5, 12\\} \\)  $$\n",
    "\\[$$\n",
    "\\text{Range} = 12 - 3 = 9$$\n",
    "\\]\n",
    "📌 **Limiti**:\n",
    "- Dipende solo dai valori estremi (non considera la distribuzione dei dati).\n",
    "- Sensibile agli **outlier**.\n",
    "\n",
    "---\n",
    "\n",
    "### **2️⃣ Variance (Varianza)**\n",
    "📌 **Definizione**: Misura la dispersione dei dati rispetto alla loro media.  \n",
    "📌 **Formula per la popolazione**:  \n",
    "\\[$$\n",
    "\\sigma^2 = \\frac{\\sum (X_i - \\mu)^2}{N}$$\n",
    "\\]\n",
    "📌 **Formula per il campione**:  \n",
    "\\[$$\n",
    "s^2 = \\frac{\\sum (X_i - \\bar{X})^2}{n-1}$$\n",
    "\\]\n",
    "Dove:\n",
    "- \\($$ \\sigma^2 $$\\) = varianza della popolazione  \n",
    "- \\($$ s^2 $$\\) = varianza del campione  \n",
    "- \\( $$\\mu $$\\) = media della popolazione  \n",
    "- \\( $$\\bar{X}$$ \\) = media del campione  \n",
    "- \\( $$N $$\\), \\( $$n $$\\) = dimensione della popolazione/campione  \n",
    "\n",
    "📌 **Esempio** (per un campione):  \n",
    "Dati: \\( $$X = \\{4, 8, 6\\} $$\\)  \n",
    "1. **Media**:  \n",
    "\\[$$\n",
    "\\bar{X} = \\frac{4+8+6}{3} = 6$$\n",
    "\\]\n",
    "2. **Scarti quadrati dalla media**:  \n",
    "\\[$$\n",
    "(4-6)^2 = 4, \\quad (8-6)^2 = 4, \\quad (6-6)^2 = 0\n",
    "$$\\]\n",
    "3. **Varianza**:  \n",
    "\\[$$\n",
    "s^2 = \\frac{4+4+0}{3-1} = \\frac{8}{2} = 4\n",
    "$$\\]\n",
    "\n",
    "📌 **Pro e Contro**:\n",
    "✅ Usa tutti i dati → più affidabile del range  \n",
    "❌ L’unità di misura è elevata al quadrato  \n",
    "\n",
    "---\n",
    "\n",
    "### **3️⃣ Standard Deviation (Deviazione standard)**\n",
    "📌 **Definizione**: Radice quadrata della varianza, riporta la dispersione all’unità originale dei dati.  \n",
    "📌 **Formule**:\n",
    "\\[$$\n",
    "\\sigma = \\sqrt{\\sigma^2} \\quad \\text{(popolazione)}, \\quad s = \\sqrt{s^2} \\quad \\text{(campione)}\n",
    "$$\\]\n",
    "📌 **Esempio**:  \n",
    "Se la varianza \\( $$s^2 = 4$$ \\), allora la deviazione standard è:  \n",
    "\\[$$\n",
    "s = \\sqrt{4} = 2\n",
    "$$\\]\n",
    "📌 **Vantaggi**:\n",
    "- È nella stessa unità di misura dei dati originali.\n",
    "- Facilmente interpretabile.\n",
    "\n",
    "---\n",
    "\n",
    "### **4️⃣ Interquartile Range (IQR - Intervallo Interquartile)**\n",
    "📌 **Definizione**: Misura la dispersione considerando solo i dati centrali, eliminando gli outlier.  \n",
    "📌 **Formula**:  \n",
    "\\[$$\n",
    "IQR = Q3 - Q1\n",
    "$$\\]\n",
    "Dove:\n",
    "- **Q1 (Primo Quartile)**: il 25% dei dati è inferiore a questo valore.\n",
    "- **Q3 (Terzo Quartile)**: il 75% dei dati è inferiore a questo valore.\n",
    "\n",
    "📌 **Esempio**:  \n",
    "Dati ordinati: \\( $$X = \\{1, 3, 5, 7, 9\\} $$\\)  \n",
    "- **Q1** = 3  \n",
    "- **Q3** = 7  \n",
    "\\[$$\n",
    "IQR = 7 - 3 = 4\n",
    "$$\\]\n",
    "📌 **Vantaggi**:\n",
    "- Resistente agli outlier.  \n",
    "- Utile per capire la distribuzione centrale dei dati.\n",
    "\n",
    "---\n",
    "\n",
    "### **5️⃣ Coefficient of Variation (Coefficiente di Variazione - CV)**\n",
    "📌 **Definizione**: Misura la dispersione relativa alla media, utile per confrontare dati con scale diverse.  \n",
    "📌 **Formula**:  \n",
    "\\[$$\n",
    "CV = \\frac{\\sigma}{\\mu} \\times 100\\%\n",
    "$$\\]\n",
    "📌 **Esempio**:  \n",
    "Se \\( $$\\mu = 50 $$\\) e \\( $$\\sigma = 5$$ \\), allora  \n",
    "\\[$$\n",
    "CV = \\frac{5}{50} \\times 100 = 10\\%\n",
    "$$\\]\n",
    "📌 **Vantaggi**:\n",
    "- Permette di confrontare dispersioni tra dataset con medie diverse.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔥 **Riepilogo delle Measures of Dispersion**\n",
    "| Misura | Formula | Sensibile agli outlier? | Unità di misura |\n",
    "|--------|---------|----------------|--------------|\n",
    "| **Range** | \\($ \\max(X) - \\min(X) $\\) | ✅ Sì | Stessa dei dati |\n",
    "| **Varianza** | \\( $\\frac{\\sum (X_i - \\mu)^2}{N} $\\) | ✅ Sì | Quadrata rispetto ai dati |\n",
    "| **Dev. Standard** | \\($ \\sqrt{\\sigma^2} $\\) | ✅ Sì | Stessa dei dati |\n",
    "| **IQR** | \\( $Q3 - Q1 $\\) | ❌ No | Stessa dei dati |\n",
    "| **CV** | \\( $\\frac{\\sigma}{\\mu} \\times 100\\% $\\) | ✅ Sì | Percentuale |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 **Quando usare quale misura?**\n",
    "- **Range** → Quando serve una misura semplice, ma con dati senza outlier.\n",
    "- **Varianza & Deviazione standard** → Quando servono misure precise e dettagliate della dispersione.\n",
    "- **IQR** → Quando i dati contengono outlier e vogliamo una misura robusta.\n",
    "- **CV** → Quando vogliamo confrontare la dispersione di dataset con unità di misura diverse.\n",
    "\n",
    "---\n",
    "## **Lezione Dettagliata sulle Frequency Distributions**  \n",
    "\n",
    "### **1. Introduzione alle Distribuzioni di Frequenza**  \n",
    "Una **distribuzione di frequenza** è un metodo per organizzare i dati in modo che sia possibile vedere con quale frequenza ciascun valore o intervallo di valori appare in un dataset. È una delle tecniche fondamentali nell'analisi dei dati e nella statistica descrittiva.\n",
    "\n",
    "### **2. Tipi di Frequenze**  \n",
    "Quando analizziamo un dataset, possiamo calcolare diverse tipologie di frequenze:  \n",
    "- **Frequenza Assoluta (fi)**: il numero di volte in cui un valore specifico appare nei dati.  \n",
    "- **Frequenza Relativa (fr)**: la frequenza assoluta divisa per il numero totale di osservazioni.  \n",
    "  \\[$\n",
    "  f_r = \\frac{f_i}{N}\n",
    "  $\\]\n",
    "- **Frequenza Percentuale**: la frequenza relativa moltiplicata per 100.  \n",
    "  \\[$\n",
    "  f_p = f_r \\times 100\n",
    "  $\\]\n",
    "- **Frequenza Cumulata**: la somma progressiva delle frequenze assolute. Indica quante osservazioni hanno un valore uguale o inferiore a un certo limite.  \n",
    "- **Frequenza Cumulata Relativa**: la frequenza cumulata divisa per il totale delle osservazioni.  \n",
    "\n",
    "### **3. Creazione di una Distribuzione di Frequenza**  \n",
    "#### **3.1 Distribuzione per dati discreti**  \n",
    "Esempio: Un dataset con il numero di caffè bevuti al giorno da 20 persone:\n",
    "\n",
    "| Caffè al giorno | Frequenza assoluta (fi) |\n",
    "|-----------------|-------------------------|\n",
    "| 0              | 3                         |\n",
    "| 1              | 5                         |\n",
    "| 2              | 6                         |\n",
    "| 3              | 4                         |\n",
    "| 4              | 2                         |\n",
    "\n",
    "#### **3.2 Distribuzione per dati continui (creazione di classi)**  \n",
    "Per dati continui, i valori devono essere raggruppati in classi.  \n",
    "Passaggi:\n",
    "1. **Determinare l’ampiezza della classe**  \n",
    "   \\[$\n",
    "   \\text{Ampiezza} = \\frac{\\text{Valore massimo} - \\text{Valore minimo}}{\\text{Numero di classi desiderato}}\n",
    "   $\\]\n",
    "2. **Creare le classi** (intervalli di valori)  \n",
    "3. **Contare le osservazioni in ogni classe**  \n",
    "\n",
    "Esempio: Supponiamo di avere 50 dati sull'età dei partecipanti a un sondaggio e vogliamo creare una tabella di distribuzione di frequenza con 5 classi.\n",
    "\n",
    "| Classe (Età) | Frequenza assoluta (fi) | Frequenza relativa (fr) | Frequenza cumulata (Fc) |\n",
    "|-------------|-------------------------|-------------------------|-------------------------|\n",
    "| 20 - 30    | 8                         | 0.16                     | 8                      |\n",
    "| 30 - 40    | 12                        | 0.24                     | 20                     |\n",
    "| 40 - 50    | 15                        | 0.30                     | 35                     |\n",
    "| 50 - 60    | 9                         | 0.18                     | 44                     |\n",
    "| 60 - 70    | 6                         | 0.12                     | 50                     |\n",
    "\n",
    "### **4. Rappresentazione Grafica**\n",
    "Una volta creata la distribuzione di frequenza, possiamo visualizzarla in diversi modi:\n",
    "- **Istogramma**: rappresenta le classi con barre la cui altezza è proporzionale alla frequenza.\n",
    "- **Poligono di frequenza**: collega i punti centrali delle barre di un istogramma con linee.\n",
    "- **Grafico a barre**: utile per dati discreti.\n",
    "- **Curva di frequenza cumulata**: mostra la crescita della frequenza cumulata.\n",
    "\n",
    "### **5. Applicazione in Python**\n",
    "Possiamo calcolare e visualizzare distribuzioni di frequenza con **Pandas e Matplotlib**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Esempio di dati\n",
    "data = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 40, 30, 50, 45, 55, 35, 60, 40, 30]\n",
    "\n",
    "# Creare intervalli di classi\n",
    "bins = [20, 30, 40, 50, 60, 70]\n",
    "labels = [\"20-30\", \"30-40\", \"40-50\", \"50-60\", \"60-70\"]\n",
    "\n",
    "# Creare tabella di frequenza\n",
    "df = pd.DataFrame(data, columns=[\"Età\"])\n",
    "df[\"Classe\"] = pd.cut(df[\"Età\"], bins=bins, labels=labels, right=False)\n",
    "freq_table = df[\"Classe\"].value_counts().sort_index()\n",
    "\n",
    "# Visualizzazione\n",
    "plt.bar(freq_table.index, freq_table.values, color='skyblue')\n",
    "plt.xlabel(\"Classi di età\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "plt.title(\"Distribuzione di frequenza dell'età\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **6. Conclusione**  \n",
    "Le distribuzioni di frequenza sono essenziali per riassumere e comprendere i dati, sia che si tratti di fenomeni semplici come il numero di caffè bevuti, sia che si tratti di dati sanitari. Con strumenti come Python e librerie come Pandas, possiamo automatizzare l'analisi e la rappresentazione grafica in modo efficace.\n",
    "\n",
    "## **Introduzione alla Probabilità**\n",
    "\n",
    "La **probabilità** è un ramo della matematica che quantifica l'incertezza e misura la possibilità che un evento si verifichi. Viene espressa come un numero compreso tra 0 e 1, dove:\n",
    "- **0** significa che l'evento è impossibile.\n",
    "- **1** significa che l'evento è certo.\n",
    "\n",
    "La probabilità viene utilizzata in molteplici ambiti, dalla statistica alla scienza dei dati, dall'ingegneria alla finanza, e persino nella medicina e nell'intelligenza artificiale.\n",
    "\n",
    "---\n",
    "\n",
    "### **Concetti Chiave**\n",
    "Per comprendere la probabilità, è necessario familiarizzare con alcuni concetti fondamentali.\n",
    "\n",
    "### **1. Esperimento (Experiment)**\n",
    "Un **esperimento** è un'azione o un processo che produce un risultato osservabile. Può essere:\n",
    "- **Deterministico**: sempre lo stesso risultato (es. mescolare acqua e zucchero).\n",
    "- **Casuale (o aleatorio)**: può avere più risultati possibili (es. lanciare un dado, estrarre una carta da un mazzo).\n",
    "\n",
    "🔹 **Esempio**: Lanciare un dado a sei facce è un esperimento casuale, perché ogni lancio può dare un numero da 1 a 6.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Esito (Outcome)**\n",
    "Un **esito** è un singolo possibile risultato di un esperimento.\n",
    "\n",
    "🔹 **Esempio**: Se lanciamo un dado e otteniamo \"4\", questo è un esito.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Spazio Campionario (Sample Space)**\n",
    "Lo **spazio campionario** (o universo) è l'insieme di tutti i possibili esiti di un esperimento.\n",
    "\n",
    "🔹 **Esempi**:\n",
    "- **Lancio di un dado**: \\( $S = \\{1, 2, 3, 4, 5, 6\\} $\\)\n",
    "- **Lancio di due dadi**: \\( $S = \\{(1,1), (1,2), (1,3), ..., (6,6)\\}$ \\), con 36 possibili risultati.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Evento (Event)**\n",
    "Un **evento** è un sottoinsieme dello spazio campionario, cioè un gruppo di uno o più esiti.\n",
    "\n",
    "🔹 **Esempi**:\n",
    "- Nel lancio di un dado, l'evento **\"ottenere un numero pari\"** è: \\($ A = \\{2, 4, 6\\}$ \\).\n",
    "- Nell'estrazione di una carta da un mazzo, l'evento **\"pescare un asso\"** è: \\($ A = \\{\\text{Asso di cuori}, \\text{Asso di quadri}, \\text{Asso di picche}, \\text{Asso di fiori}\\} $\\).\n",
    "\n",
    "Se un evento contiene un solo esito (es. ottenere un \"3\" in un dado), si chiama **evento elementare**.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Probabilità di un Evento**\n",
    "La **probabilità** di un evento \\($ A $\\) è definita come:\n",
    "\n",
    "\\[$\n",
    "P(A) = \\frac{\\text{Numero di esiti favorevoli ad A}}{\\text{Numero totale di esiti possibili}}\n",
    "$\\]\n",
    "\n",
    "🔹 **Esempio**: Nel lancio di un dado, la probabilità di ottenere un numero pari è:\n",
    "\n",
    "\\[$\n",
    "P(A) = \\frac{3}{6} = \\frac{1}{2} = 0.5\n",
    "$\\]\n",
    "\n",
    "---\n",
    "\n",
    "## **Tipologie di Probabilità**\n",
    "Ci sono tre approcci principali alla probabilità:\n",
    "\n",
    "1. **Classica** (o definizione di Laplace)  \n",
    "   Si applica quando tutti gli esiti sono equiprobabili, cioè hanno la stessa possibilità di verificarsi.\n",
    "\n",
    "   \\[$   P(A) = \\frac{\\text{Numero di esiti favorevoli}}{\\text{Numero totale di esiti possibili}}\n",
    "   $\\]\n",
    "\n",
    "   *Esempio*: La probabilità di ottenere testa in un lancio di moneta è \\( P(A) = \\frac{1}{2} \\).\n",
    "\n",
    "2. **Frequentista**  \n",
    "   Si basa sulla ripetizione dell'esperimento. Se ripetiamo molte volte un esperimento, la probabilità di un evento è la frequenza relativa con cui si verifica.\n",
    "\n",
    "   \\[$\n",
    "   P(A) \\approx \\frac{\\text{Numero di volte in cui A si verifica}}{\\text{Numero totale di prove}}\n",
    "   $\\]\n",
    "\n",
    "   *Esempio*: Se lanci una moneta 1000 volte e ottieni testa 510 volte, la probabilità stimata è \\( P(A) = \\frac{510}{1000} = 0.51 \\).\n",
    "\n",
    "3. **Soggettiva**  \n",
    "   Basata su opinioni personali e stime. Spesso usata in scenari con incertezza elevata, come previsioni economiche o diagnosi mediche.\n",
    "\n",
    "---\n",
    "\n",
    "## **Proprietà della Probabilità**\n",
    "- **0 ≤ P(A) ≤ 1** per ogni evento \\( A \\).\n",
    "- **P(S) = 1**, la probabilità dell'intero spazio campionario è 1 (un evento certo).\n",
    "- **P(∅) = 0**, la probabilità di un evento impossibile è 0.\n",
    "- **Se due eventi sono complementari (cioè A e il suo complementare Ā), allora**:\n",
    "\n",
    "  \\[$\n",
    "  P(A) + P(\\overline{A}) = 1\n",
    "  $\\]\n",
    "\n",
    "  *Esempio*: Se la probabilità di pioggia domani è 0.3, la probabilità che non piova è 0.7.\n",
    "\n",
    "---\n",
    "\n",
    "## **Esercizio Pratico**\n",
    "### **Domanda**  \n",
    "Se peschi una carta da un mazzo di 52 carte, qual è la probabilità di pescare una carta di cuori?\n",
    "\n",
    "### **Soluzione**\n",
    "- Lo spazio campionario \\( S \\) ha 52 carte.\n",
    "- Ci sono 13 carte di cuori.\n",
    "- Probabilità di pescare una carta di cuori:\n",
    "\n",
    "  \\[$\n",
    "  P(A) = \\frac{13}{52} = \\frac{1}{4} = 0.25\n",
    "  $\\]\n",
    "\n",
    "\n",
    "## 📚 **Lezione Dettagliata sulle Regole di Probabilità**  \n",
    "\n",
    "La probabilità è la branca della matematica che studia il verificarsi di eventi in condizioni di incertezza. In questa lezione approfondiremo le principali regole della probabilità e il loro utilizzo pratico.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **1. Concetti Fondamentali**\n",
    "1. **Spazio campionario (\\(\\Omega\\))**: l'insieme di tutti i possibili risultati di un esperimento casuale.  \n",
    "   - Esempio: nel lancio di un dado a 6 facce, lo spazio campionario è \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\).\n",
    "\n",
    "2. **Evento (\\(A\\))**: un sottoinsieme dello spazio campionario, ovvero uno o più risultati possibili.  \n",
    "   - Esempio: nel lancio di un dado, l'evento \"ottenere un numero pari\" è \\(A = \\{2, 4, 6\\}\\).\n",
    "\n",
    "3. **Probabilità di un evento (\\(P(A)\\))**: misura numerica dell’incertezza di un evento. Se tutti gli esiti sono ugualmente probabili, si calcola come:\n",
    "   \\[$\n",
    "   P(A) = \\frac{\\text{numero di casi favorevoli a } A}{\\text{numero di casi totali nello spazio campionario}}\n",
    "   $\\]\n",
    "\n",
    "   - Esempio: nel lancio di un dado, la probabilità di ottenere un numero pari è:\n",
    "     \\[$\n",
    "     P(A) = \\frac{3}{6} = 0.5\n",
    "     $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **2. Proprietà Fondamentali della Probabilità**\n",
    "1. **Regola dell’intervallo della probabilità**: per ogni evento \\( A \\), la probabilità è compresa tra 0 e 1:\n",
    "   \\[$\n",
    "   0 \\leq P(A) \\leq 1\n",
    "   $\\]\n",
    "   - \\($ P(A) = 0 $\\) significa che l'evento è impossibile.\n",
    "   - \\( $P(A) = 1 $\\) significa che l'evento è certo.\n",
    "\n",
    "2. **Probabilità dell'evento complementare**: se \\($ A $\\) è un evento, allora il suo complemento \\($ A^c $\\) è l'insieme degli eventi che non appartengono ad \\($ A $\\).  \n",
    "   La relazione tra \\( $A $\\) e \\($ A^c$ \\) è:\n",
    "   \\[$\n",
    "   P(A^c) = 1 - P(A)\n",
    "   $\\]\n",
    "   - Esempio: la probabilità di NON ottenere un numero pari lanciando un dado è:\n",
    "     \\[$\n",
    "     P(A^c) = 1 - P(A) = 1 - 0.5 = 0.5\n",
    "     $\\]\n",
    "\n",
    "3. **Additività della probabilità per eventi mutuamente esclusivi**: se due eventi \\( A \\) e \\( B \\) sono **mutuamente esclusivi** (cioè non possono verificarsi insieme), allora:\n",
    "   \\[$\n",
    "   P(A \\cup B) = P(A) + P(B)\n",
    "   $\\]\n",
    "   - Esempio: nel lancio di un dado, la probabilità di ottenere un 2 o un 3 è:\n",
    "     \\[$\n",
    "     P(\\{2\\} \\cup \\{3\\}) = P(2) + P(3) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = 0.333\n",
    "     $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **3. Regola della Probabilità Totale**\n",
    "Se un evento \\( A \\) può avvenire in modi diversi, allora la sua probabilità totale si ottiene sommando le probabilità dei singoli modi in cui può verificarsi.\n",
    "\n",
    "\\[$\n",
    "P(A) = P(A \\cap B) + P(A \\cap B^c)\n",
    "$\\]\n",
    "\n",
    "- Esempio: Supponiamo di avere una classe con 60% di studenti maschi e 40% di studentesse. Il 30% dei maschi e il 50% delle femmine indossa gli occhiali.  \n",
    "  Qual è la probabilità che uno studente scelto a caso indossi gli occhiali?\n",
    "  \\[$\n",
    "  P(G) = P(G | M) P(M) + P(G | F) P(F) = (0.3 \\times 0.6) + (0.5 \\times 0.4) = 0.18 + 0.2 = 0.38\n",
    "  $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **4. Regola del Prodotto (Probabilità Condizionata)**\n",
    "La **probabilità condizionata** misura la probabilità che un evento \\( A \\) si verifichi, dato che sappiamo che si è verificato un altro evento \\( B \\):\n",
    "\n",
    "\\[$\n",
    "P(A | B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$\\]\n",
    "\n",
    "- Esempio: se il 10% delle persone in un'azienda sono manager (\\(P(M) = 0.1\\)) e il 70% dei manager ha una laurea (\\(P(L | M) = 0.7\\)), qual è la probabilità che una persona sia sia manager che laureata?\n",
    "  \\[$\n",
    "  P(M \\cap L) = P(L | M) P(M) = 0.7 \\times 0.1 = 0.07\n",
    "  $\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **5. Regola della Moltiplicazione (Indipendenza)**\n",
    "Due eventi \\( A \\) e \\( B \\) sono **indipendenti** se il verificarsi di uno non influenza la probabilità dell'altro, ovvero:\n",
    "\n",
    "\\[$\n",
    "P(A \\cap B) = P(A) P(B)\n",
    "$\\]\n",
    "\n",
    "- Esempio: Se lanciamo una moneta e un dado, la probabilità di ottenere \"Testa\" (\\(P(T) = 0.5\\)) e un 6 (\\(P(6) = 1/6\\)) è:\n",
    "  \\[$\n",
    "  P(T \\cap 6) = P(T) P(6) = 0.5 \\times \\frac{1}{6} = \\frac{1}{12}\n",
    "  $\\]\n",
    "\n",
    "Se invece gli eventi non sono indipendenti, usiamo la regola più generale:\n",
    "\\[$\n",
    "P(A \\cap B) = P(A | B) P(B)\n",
    "$\\]\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **6. Teorema di Bayes**\n",
    "Il **Teorema di Bayes** permette di calcolare la probabilità di un evento basandosi su informazioni condizionate:\n",
    "\n",
    "\\[$\n",
    "P(A | B) = \\frac{P(B | A) P(A)}{P(B)}\n",
    "$\\]\n",
    "\n",
    "- Esempio: Supponiamo che il 2% della popolazione abbia una malattia (\\(P(M) = 0.02\\)). Un test diagnostico ha il 95% di accuratezza (\\(P(T | M) = 0.95\\)), ma ha anche un 5% di falsi positivi (\\(P(T | M^c) = 0.05\\)).  \n",
    "  Se una persona risulta positiva al test, qual è la probabilità che sia effettivamente malata?\n",
    "\n",
    "  \\[$\n",
    "  P(M | T) = \\frac{P(T | M) P(M)}{P(T | M) P(M) + P(T | M^c) P(M^c)}\n",
    "  $\\]\n",
    "\n",
    "  \\[$  = \\frac{(0.95 \\times 0.02)}{(0.95 \\times 0.02) + (0.05 \\times 0.98)}\n",
    "  $\\]\n",
    "\n",
    "  \\[$\n",
    "  = \\frac{0.019}{0.019 + 0.049} = \\frac{0.019}{0.068} \\approx 0.28\n",
    "  $\\]\n",
    "\n",
    "  Quindi, nonostante il test sia positivo, la probabilità che la persona sia effettivamente malata è solo il 28%!\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 **Conclusione**\n",
    "Le regole della probabilità sono strumenti fondamentali in Data Science, Machine Learning e Medicina. Comprendere questi concetti aiuta a interpretare meglio i dati e prendere decisioni più informate.\n",
    "\n",
    "\n",
    "### La **probabilità condizionata** \n",
    "\n",
    "è un concetto fondamentale in probabilità che ci permette di calcolare la probabilità che un evento si verifichi dato che un altro evento è già accaduto. Si scrive matematicamente come \\( P(A|B) \\), che rappresenta la probabilità dell'evento \\( A \\) dato che l'evento \\( B \\) si è verificato.\n",
    "\n",
    "### Formula della Probabilità Condizionata\n",
    "\n",
    "La formula per calcolare la probabilità condizionata di \\( A \\) dato \\( B \\) è:\n",
    "\n",
    "\\[$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\($ P(A|B)$ \\) è la probabilità che \\( A \\) si verifichi dato che \\( B \\) è accaduto.\n",
    "- \\( $P(A \\cap B)$ \\) è la probabilità che entrambi gli eventi \\( A \\) e \\( B \\) si verifichino contemporaneamente.\n",
    "- \\($ P(B)$ \\) è la probabilità che l'evento \\( B \\) si verifichi (nota che \\( P(B) > 0 \\)).\n",
    "\n",
    "### Significato della Formula\n",
    "La formula dice che per calcolare la probabilità di \\( A \\) condizionata su \\( B \\), dobbiamo:\n",
    "1. Trovare la probabilità che entrambi gli eventi \\( A \\) e \\( B \\) si verifichino simultaneamente.\n",
    "2. Dividere questa probabilità per la probabilità che l'evento \\( B \\) si verifichi.\n",
    "\n",
    "### Esempio di Probabilità Condizionata\n",
    "\n",
    "Immagina di lanciare un dado a sei facce. Definiamo gli eventi:\n",
    "- \\( A \\): il numero uscito è pari.\n",
    "- \\( B \\): il numero uscito è maggiore di 2.\n",
    "\n",
    "Se vogliamo calcolare \\( P(A|B) \\), ovvero la probabilità che il numero sia pari dato che è maggiore di 2, possiamo procedere come segue:\n",
    "\n",
    "- L'insieme di \\( B \\) (i numeri maggiori di 2) è: \\( \\{3, 4, 5, 6\\} \\).\n",
    "- L'insieme di \\( A \\cap B \\) (i numeri che sono sia pari che maggiori di 2) è: \\( \\{4, 6\\} \\).\n",
    "\n",
    "Ora possiamo applicare la formula:\n",
    "\n",
    "\\[$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{\\frac{2}{6}}{\\frac{4}{6}} = \\frac{2}{4} = 0.5\n",
    "$\\]\n",
    "\n",
    "Quindi, la probabilità di ottenere un numero pari dato che è maggiore di 2 è 0.5.\n",
    "\n",
    "### Legge di Bayes\n",
    "\n",
    "Una delle applicazioni più importanti della probabilità condizionata è la **legge di Bayes**, che permette di calcolare la probabilità di un evento \\( B \\) dato un altro evento \\( A \\). La formula di Bayes è:\n",
    "\n",
    "\\[$\n",
    "P(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( P(B|A) \\) è la probabilità che \\( B \\) si verifichi dato che \\( A \\) è accaduto.\n",
    "- \\( P(A|B) \\) è la probabilità che \\( A \\) si verifichi dato che \\( B \\) è accaduto.\n",
    "- \\( P(B) \\) è la probabilità di \\( B \\).\n",
    "- \\( P(A) \\) è la probabilità di \\( A \\).\n",
    "\n",
    "La legge di Bayes è fondamentale in molti campi, tra cui l'intelligenza artificiale, la statistica e la medicina, per aggiornare le probabilità a mano a mano che si ottengono nuovi dati.\n",
    "\n",
    "### Applicazioni della Probabilità Condizionata\n",
    "La probabilità condizionata ha numerose applicazioni pratiche, come ad esempio:\n",
    "1. **Diagnosi medica**: Calcolare la probabilità che un paziente abbia una malattia dato che presenta un certo sintomo.\n",
    "2. **Machine Learning**: Viene utilizzata per la classificazione, come nel caso del **Naive Bayes**, che è un algoritmo basato sulla probabilità condizionata.\n",
    "3. **Reti Bayesian**: Sono modelli probabilistici che rappresentano variabili casuali e le loro probabilità condizionate.\n",
    "\n",
    "### Proprietà della Probabilità Condizionata\n",
    "Alcune proprietà importanti della probabilità condizionata sono:\n",
    "\n",
    "1. **Non-negatività**: \\( P(A|B) \\geq 0 \\).\n",
    "2. **Normalizzazione**: La probabilità condizionata deve essere normalizzata, cioè la somma delle probabilità condizionate su tutti gli eventi possibili deve essere uguale a 1.\n",
    "   \n",
    "   \\[$\n",
    "   \\sum_{i} P(A_i | B) = 1\n",
    "   $\\]\n",
    "\n",
    "3. **Indipendenza**: Se gli eventi \\( A \\) e \\( B \\) sono indipendenti, allora \\( P(A|B) = P(A) \\).\n",
    "\n",
    "### Riflessione sull'Indipendenza\n",
    "\n",
    "L'indipendenza tra due eventi \\( A \\) e \\( B \\) implica che la probabilità di \\( A \\) dato \\( B \\) sia la stessa di \\( A \\), cioè:\n",
    "\n",
    "\\[$\n",
    "P(A|B) = P(A)\n",
    "$\\]\n",
    "\n",
    "Questo succede quando il verificarsi di \\( B \\) non ha alcun effetto sulla probabilità che \\( A \\) si verifichi, e viceversa.\n",
    "\n",
    "### Conclusione\n",
    "\n",
    "La probabilità condizionata è uno strumento potente per analizzare la relazione tra eventi, ed è utilizzata in numerosi contesti pratici. La comprensione di come calcolare e applicare questa probabilità è essenziale per risolvere problemi complessi in statistica, data science, e machine learning.\n",
    "\n",
    "# **Probability Distributions** (Distribuzioni di probabilità).\n",
    "\n",
    "### 1. Cos'è una distribuzione di probabilità?\n",
    "\n",
    "Una **distribuzione di probabilità** è una funzione che descrive la probabilità di occorrenza di eventi possibili in un esperimento casuale. Essa fornisce la probabilità associata a ciascun risultato (o intervallo di risultati) di un esperimento.\n",
    "\n",
    "In altre parole, una distribuzione di probabilità può essere vista come una \"mappa\" che collega ciascun possibile risultato di un esperimento alla sua probabilità.\n",
    "\n",
    "Esistono due principali categorie di distribuzioni di probabilità:\n",
    "\n",
    "- **Distribuzioni discrete**: dove il numero di possibili risultati è finito o numerabile (come il lancio di un dado).\n",
    "- **Distribuzioni continue**: dove il numero di possibili risultati è infinito e non numerabile (come la misurazione della temperatura).\n",
    "\n",
    "### 2. Distribuzioni di probabilità discrete\n",
    "\n",
    "Le distribuzioni di probabilità discrete sono associate a variabili casuali discrete, cioè variabili che possono assumere solo valori specifici (ad esempio, numeri interi). Ecco alcune delle distribuzioni discrete più comuni:\n",
    "\n",
    "#### a. Distribuzione di Bernoulli\n",
    "\n",
    "La distribuzione di **Bernoulli** descrive un esperimento che ha solo due risultati possibili: successo o insuccesso (ad esempio, testa o croce in un lancio di moneta). La variabile casuale può assumere il valore 1 (successo) o 0 (insuccesso), con probabilità \\( p \\) per il successo e \\( 1 - p \\) per l'insuccesso.\n",
    "\n",
    "Funzione di probabilità:  \n",
    "\\[$\n",
    "P(X = 1) = p, \\quad P(X = 0) = 1 - p\n",
    "$\\]\n",
    "\n",
    "#### b. Distribuzione binomiale\n",
    "\n",
    "La distribuzione **binomiale** generalizza la distribuzione di Bernoulli per esperimenti ripetuti. Se eseguiamo un esperimento di Bernoulli \\( n \\) volte, la distribuzione binomiale descrive la probabilità di ottenere \\( k \\) successi in \\( n \\) prove indipendenti.\n",
    "\n",
    "Funzione di probabilità:  \n",
    "\\[$\n",
    "P(X = k) = \\binom{n}{k} p^k (1 - p)^{n-k}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( n \\) è il numero di prove,\n",
    "- \\( k \\) è il numero di successi desiderati,\n",
    "- \\( p \\) è la probabilità di successo in ogni prova.\n",
    "\n",
    "#### c. Distribuzione di Poisson\n",
    "\n",
    "La distribuzione di **Poisson** è utile per modellare eventi che accadono in un intervallo di tempo o in uno spazio continuo, ma che si verificano in modo casuale e indipendente. È utilizzata per eventi che accadono con una certa frequenza media, ma in modo casuale.\n",
    "\n",
    "Funzione di probabilità:  \n",
    "\\[$\n",
    "P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( \\lambda \\) è la media o il tasso di occorrenza dell'evento,\n",
    "- \\( k \\) è il numero di eventi osservati.\n",
    "\n",
    "#### d. Distribuzione geometrica\n",
    "\n",
    "La distribuzione **geometrica** descrive il numero di prove necessarie per ottenere il primo successo in una sequenza di esperimenti di Bernoulli.\n",
    "\n",
    "Funzione di probabilità:  \n",
    "\\[$\n",
    "P(X = k) = (1 - p)^{k-1} p\n",
    "$\\]\n",
    "\n",
    "Dove \\( p \\) è la probabilità di successo in ogni prova e \\( k \\) è il numero di prove prima del primo successo.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Distribuzioni di probabilità continue\n",
    "\n",
    "Le distribuzioni di probabilità continue sono associate a variabili casuali che possono assumere qualsiasi valore in un intervallo continuo, ad esempio la temperatura, l'altezza o il peso. Le distribuzioni più comuni includono:\n",
    "\n",
    "#### a. Distribuzione normale (Gaussiana)\n",
    "\n",
    "La distribuzione **normale** è una delle distribuzioni più importanti e ampiamente utilizzate in statistica. È una distribuzione continua a forma di campana che è simmetrica attorno al suo valore medio.\n",
    "\n",
    "Funzione di densità di probabilità:  \n",
    "\\[$\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "$\\]\n",
    "\n",
    "Dove:\n",
    "- \\( \\mu \\) è la media,\n",
    "- \\( \\sigma^2 \\) è la varianza.\n",
    "\n",
    "La distribuzione normale è utilizzata per modellare fenomeni come l'altezza di un gruppo di persone o gli errori di misurazione.\n",
    "\n",
    "#### b. Distribuzione uniforme\n",
    "\n",
    "La distribuzione **uniforme** descrive una variabile casuale che ha uguale probabilità di assumere qualsiasi valore in un intervallo definito. Ad esempio, il lancio di un dado.\n",
    "\n",
    "Funzione di densità di probabilità:  \n",
    "\\[$\n",
    "f(x) = \\frac{1}{b - a}, \\quad \\text{per } a \\leq x \\leq b\n",
    "$\\]\n",
    "\n",
    "Dove \\( a \\) e \\( b \\) sono i limiti inferiore e superiore dell'intervallo.\n",
    "\n",
    "#### c. Distribuzione esponenziale\n",
    "\n",
    "La distribuzione **esponenziale** è utilizzata per modellare il tempo che intercorre tra due eventi che accadono in un processo di Poisson (ad esempio, il tempo tra le chiamate a un call center).\n",
    "\n",
    "Funzione di densità di probabilità:  \n",
    "\\[$\n",
    "f(x) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0\n",
    "$\\]\n",
    "\n",
    "Dove \\( \\lambda \\) è il tasso di arrivo degli eventi.\n",
    "\n",
    "#### d. Distribuzione t di Student\n",
    "\n",
    "La distribuzione **t di Student** è utilizzata quando si stima la media di una popolazione da un campione, in particolare quando la dimensione del campione è piccola e la deviazione standard della popolazione è sconosciuta.\n",
    "\n",
    "Funzione di densità di probabilità:  \n",
    "La distribuzione t ha una forma simile alla normale, ma con code più spesse. La sua funzione di densità dipende da un parametro chiamato **gradi di libertà**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Parametri delle distribuzioni\n",
    "\n",
    "Ogni distribuzione di probabilità è descritta da una serie di parametri che definiscono la sua forma e proprietà. I parametri comuni includono:\n",
    "\n",
    "- **Media (\\( \\mu \\))**: la posizione centrale della distribuzione.\n",
    "- **Varianza (\\( \\sigma^2 \\))**: la misura della dispersione dei dati intorno alla media.\n",
    "- **Deviazione standard (\\( \\sigma \\))**: la radice quadrata della varianza, che è più facilmente interpretabile rispetto alla varianza.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Applicazioni delle distribuzioni di probabilità\n",
    "\n",
    "Le distribuzioni di probabilità sono fondamentali in molte aree delle scienze, ingegneria, economia, e medicina. Ad esempio:\n",
    "- **In statistica inferenziale**: per stimare parametri della popolazione e fare test statistici.\n",
    "- **In finanza**: per modellare i ritorni degli investimenti e il rischio.\n",
    "- **In machine learning**: per comprendere e costruire modelli probabilistici (es. Naive Bayes, distribuzioni gaussiane in modelli di regressione).\n",
    "- **In medicina**: per modellare la probabilità di successo di un trattamento o l'andamento di una malattia.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Conclusione\n",
    "\n",
    "Le distribuzioni di probabilità forniscono una base solida per analizzare e comprendere fenomeni casuali in vari contesti. La comprensione delle diverse distribuzioni e dei loro parametri è essenziale per affrontare problemi pratici e applicare correttamente la statistica e la probabilità in diverse discipline.\n",
    "\n",
    "# **Inferential Statistics** (Statistica Inferenziale) \n",
    "è una branca della statistica che si occupa di fare inferenze o previsioni su una popolazione a partire da un campione di dati. A differenza della statistica descrittiva, che si limita a riassumere e descrivere i dati (mediante medie, deviazioni standard, ecc.), la statistica inferenziale cerca di trarre conclusioni o di fare predizioni basate su un insieme di dati più limitato. Questo processo si basa su teorie probabilistiche per fare stime e testare ipotesi.\n",
    "\n",
    "### Concetti Fondamentali della Statistica Inferenziale\n",
    "\n",
    "1. **Popolazione vs. Campione**:\n",
    "   - **Popolazione**: È l'intero gruppo di elementi che si desidera studiare.\n",
    "   - **Campione**: È un sottoinsieme di elementi prelevato dalla popolazione. Poiché è spesso difficile o impossibile studiare tutta la popolazione, si utilizza un campione per fare delle inferenze.\n",
    "   - È essenziale che il campione sia rappresentativo della popolazione per ottenere stime accurate.\n",
    "\n",
    "2. **Inferenze Statistiche**:\n",
    "   Le inferenze statistiche includono:\n",
    "   - **Stima**: Stimare valori sconosciuti (parametri) della popolazione, come la media o la proporzione.\n",
    "   - **Test di ipotesi**: Valutare un'ipotesi sulla popolazione basandosi sul campione, determinando se ci sono prove sufficienti per accettare o rifiutare l'ipotesi.\n",
    "\n",
    "3. **Distribuzione Campionaria**:\n",
    "   La distribuzione campionaria è la distribuzione di una statistica (ad esempio, la media campionaria) ottenuta da campioni ripetuti estratti dalla stessa popolazione. È importante capire come queste distribuzioni si comportano per fare inferenze valide. Una delle teorie centrali qui è il **Teorema del Limite Centrale**, che afferma che, sotto certe condizioni, la distribuzione delle medie campionarie tende ad essere normale, indipendentemente dalla forma della distribuzione della popolazione, man mano che il campione cresce.\n",
    "\n",
    "4. **Intervallo di Confidenza (Confidence Interval)**:\n",
    "   Un intervallo di confidenza è un range di valori che, con un certo livello di probabilità, contiene il vero parametro della popolazione. Ad esempio, un intervallo di confidenza del 95% significa che, se si ripetessero gli esperimenti molte volte, il parametro della popolazione sarebbe contenuto nell'intervallo il 95% delle volte.\n",
    "   \n",
    "   Formula dell'intervallo di confidenza per la media:\n",
    "   \\[$\n",
    "   \\text{Intervallo di Confidenza} = \\hat{\\mu} \\pm Z_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}\n",
    "   $\\]\n",
    "   Dove:\n",
    "   - \\($\\hat{\\mu}\\$) è la media campionaria,\n",
    "   - \\($Z_{\\alpha/2}\\$) è il valore critico per un dato livello di confidenza (ad esempio, 1.96 per il 95% di confidenza),\n",
    "   - \\($\\sigma$\\) è la deviazione standard della popolazione (o quella campionaria, se la popolazione è sconosciuta),\n",
    "   - \\($n$\\) è la dimensione del campione.\n",
    "\n",
    "5. **Test di Ipotesi**:\n",
    "   Un test di ipotesi è un processo che consente di verificare se una certa affermazione su una popolazione è vera, basandosi su dati campionari. Si definiscono due ipotesi:\n",
    "   - **Ipotesi nulla (H₀)**: L'affermazione da testare, solitamente una dichiarazione di \"nessun effetto\" o \"nessuna differenza\".\n",
    "   - **Ipotesi alternativa (H₁)**: L'affermazione che si vuole sostenere, ovvero una differenza significativa o un effetto.\n",
    "   \n",
    "   Esempio di un test di ipotesi:\n",
    "   - **H₀**: La media della popolazione è uguale a 50.\n",
    "   - **H₁**: La media della popolazione non è uguale a 50.\n",
    "   \n",
    "   Un test di ipotesi si conclude con una decisione basata sul calcolo di una statistica di test e il suo confronto con un valore critico o tramite il p-value:\n",
    "   - **p-value**: È la probabilità di ottenere un risultato uguale o più estremo di quello osservato, assumendo che l'ipotesi nulla sia vera. Un p-value basso (solitamente inferiore a 0.05) porta al rifiuto dell'ipotesi nulla.\n",
    "\n",
    "6. **Tipo di Errori nei Test di Ipotesi**:\n",
    "   - **Errore di Tipo I (α)**: Rifiutare erroneamente l'ipotesi nulla quando è vera (falso positivo).\n",
    "   - **Errore di Tipo II (β)**: Non rifiutare l'ipotesi nulla quando è falsa (falso negativo).\n",
    "\n",
    "7. **Distribuzioni di Probabilità Utilizzate**:\n",
    "   In statistica inferenziale, le distribuzioni di probabilità sono utilizzate per modellare l'incertezza associata alle stime. Le principali distribuzioni includono:\n",
    "   - **Distribuzione Normale**: Utilizzata quando i dati seguono una distribuzione continua simmetrica.\n",
    "   - **Distribuzione t di Student**: Usata quando il campione è di dimensioni piccole e la deviazione standard della popolazione è sconosciuta.\n",
    "   - **Distribuzione Chi-quadro**: Spesso usata per testare la bontà di adattamento o l'indipendenza in tabelle di contingenza.\n",
    "   - **Distribuzione F**: Utilizzata per confrontare varianze in test di analisi della varianza (ANOVA).\n",
    "\n",
    "### Applicazioni della Statistica Inferenziale\n",
    "\n",
    "1. **Ricerca scientifica**: La statistica inferenziale è fondamentale nelle scienze per fare inferenze sui dati sperimentali e trarre conclusioni generali.\n",
    "2. **Business e Marketing**: Per analizzare i comportamenti dei consumatori e fare previsioni sulle vendite o sul successo di un prodotto.\n",
    "3. **Medicina**: Per determinare l'efficacia di un trattamento o per stimare la prevalenza di una malattia.\n",
    "4. **Politica**: Per fare sondaggi e inferenze sui comportamenti degli elettori.\n",
    "\n",
    "### Riepilogo\n",
    "\n",
    "La statistica inferenziale è un potente strumento per prendere decisioni e fare previsioni sui dati. Utilizzando campioni di dati, è possibile fare inferenze sulla popolazione, stimare parametri, testare ipotesi e calcolare intervalli di confidenza. Le tecniche di inferenza, come il test di ipotesi e gli intervalli di confidenza, si basano su una solida comprensione delle distribuzioni di probabilità e delle caratteristiche dei campioni.\n",
    "\n",
    "# **campionamento** (sampling) \n",
    "è una tecnica fondamentale in statistica e data science che consiste nel selezionare un sottoinsieme rappresentativo da un insieme di dati più grande (popolazione). L'obiettivo è raccogliere informazioni sufficienti da questo sottoinsieme per fare inferenze valide sulla popolazione. È una tecnica usata per risparmiare tempo e risorse, ma deve essere eseguita con attenzione per evitare distorsioni nei risultati.\n",
    "\n",
    "### 1. **Tipi di Campionamento**\n",
    "\n",
    "Esistono diversi metodi di campionamento, che si possono suddividere in due categorie principali: **campionamento probabilistico** e **campionamento non probabilistico**.\n",
    "\n",
    "#### A. Campionamento Probabilistico\n",
    "\n",
    "Nel campionamento probabilistico, ogni elemento della popolazione ha una probabilità conosciuta di essere selezionato. Questi metodi garantiscono che il campione sia rappresentativo della popolazione.\n",
    "\n",
    "1. **Campionamento casuale semplice (Simple Random Sampling - SRS)**:\n",
    "   - Ogni individuo della popolazione ha la stessa probabilità di essere selezionato.\n",
    "   - Può essere effettuato senza reinserimento (quando un elemento selezionato non viene rimesso nel campione) o con reinserimento (quando un elemento selezionato viene rimesso nel campione).\n",
    "   - **Esempio**: Se hai una popolazione di 100 persone e vuoi selezionare un campione di 10 persone, estrai casualmente 10 persone dalla lista.\n",
    "\n",
    "2. **Campionamento sistematico (Systematic Sampling)**:\n",
    "   - Si seleziona un punto di partenza casuale, e poi ogni k-esimo elemento della popolazione viene selezionato. \n",
    "   - **Formula**: \\( k = \\frac{N}{n} \\), dove \\( N \\) è la dimensione totale della popolazione e \\( n \\) è la dimensione del campione.\n",
    "   - **Esempio**: Se vuoi selezionare 10 persone da una popolazione di 100, puoi scegliere ogni 10a persona.\n",
    "\n",
    "3. **Campionamento stratificato (Stratified Sampling)**:\n",
    "   - La popolazione viene suddivisa in sottogruppi (strati) omogenei, e successivamente si seleziona un campione da ciascun strato. \n",
    "   - Si garantisce che tutte le caratteristiche della popolazione siano rappresentate in modo proporzionale.\n",
    "   - **Esempio**: Se una popolazione è suddivisa in gruppi in base all'età (18-30, 31-40, ecc.), un campione stratificato selezionerà un numero proporzionale di persone da ogni gruppo.\n",
    "\n",
    "4. **Campionamento a grappolo (Cluster Sampling)**:\n",
    "   - La popolazione viene suddivisa in gruppi (grappoli), e poi si selezionano alcuni grappoli in modo casuale. Tutti gli elementi di ogni grappolo selezionato vengono inclusi nel campione.\n",
    "   - È utile quando è difficile accedere a tutti gli individui della popolazione, ma è possibile accedere facilmente ai grappoli.\n",
    "   - **Esempio**: Se vuoi studiare gli studenti di diverse scuole, potresti selezionare casualmente alcune scuole (grappoli) e includere tutti gli studenti di quelle scuole nel campione.\n",
    "\n",
    "5. **Campionamento a probabilità proporzionale al peso (Probability Proportional to Size - PPS)**:\n",
    "   - È una variante del campionamento a grappolo, in cui la probabilità di selezionare un grappolo è proporzionale alla sua dimensione.\n",
    "   - **Esempio**: Se un grappolo è composto da 500 persone e un altro da 50 persone, il grappolo più grande avrà più probabilità di essere selezionato.\n",
    "\n",
    "#### B. Campionamento Non Probabilistico\n",
    "\n",
    "Nel campionamento non probabilistico, non tutti gli individui della popolazione hanno la stessa probabilità di essere selezionati. Questi metodi non sono adatti a fare inferenze generalizzabili, ma possono essere utili quando non è possibile utilizzare metodi probabilistici.\n",
    "\n",
    "1. **Campionamento di convenienza (Convenience Sampling)**:\n",
    "   - Si selezionano gli individui più facili da raggiungere, senza considerare la loro rappresentatività.\n",
    "   - **Esempio**: Se selezioni i partecipanti alla tua ricerca tra coloro che sono facilmente disponibili, come amici o colleghi.\n",
    "\n",
    "2. **Campionamento per giudizio (Judgmental or Purposive Sampling)**:\n",
    "   - Il ricercatore seleziona deliberatamente i membri del campione sulla base di conoscenze o caratteristiche specifiche.\n",
    "   - **Esempio**: Se stai studiando l'efficacia di un trattamento per una malattia rara, selezionerai solo i pazienti che soffrono di quella malattia.\n",
    "\n",
    "3. **Campionamento a valanga (Snowball Sampling)**:\n",
    "   - Un membro selezionato del campione viene utilizzato per identificare altri membri del campione, e così via. È utile per campionare popolazioni difficili da raggiungere o nascoste.\n",
    "   - **Esempio**: Se stai cercando intervistare persone in un gruppo sociale specifico e non conosci personalmente nessuno di loro, puoi chiedere a una persona di raccomandarti altre persone.\n",
    "\n",
    "### 2. **Esempi di Applicazione del Campionamento**\n",
    "\n",
    "- **In ricerche sociali**: Per raccogliere opinioni o comportamenti di una popolazione più grande senza dover intervistare ogni singolo individuo.\n",
    "- **In studi clinici**: Per testare un trattamento o una terapia, si seleziona un campione di pazienti rappresentativi dalla popolazione.\n",
    "- **In analisi dei dati**: Quando lavoriamo con set di dati molto grandi, possiamo applicare il campionamento per ridurre la complessità computazionale senza perdere informazioni cruciali.\n",
    "\n",
    "### 3. **Vantaggi e Svantaggi**\n",
    "\n",
    "#### Vantaggi:\n",
    "- Riduce il costo e il tempo rispetto a un censimento completo.\n",
    "- È più pratico quando la popolazione è troppo grande per essere studiata interamente.\n",
    "- Se eseguito correttamente, può produrre risultati che riflettono accuratamente la popolazione.\n",
    "\n",
    "#### Svantaggi:\n",
    "- Il campione potrebbe non essere perfettamente rappresentativo se non scelto correttamente.\n",
    "- I metodi non probabilistici possono introdurre bias.\n",
    "- L'errore di campionamento è una parte intrinseca dei campioni, e può limitare l'affidabilità delle inferenze.\n",
    "\n",
    "### 4. **Errori nel Campionamento**\n",
    "\n",
    "- **Errore di campionamento**: La differenza tra il risultato osservato nel campione e quello che sarebbe stato ottenuto se si fosse osservata l'intera popolazione.\n",
    "- **Bias di selezione**: Quando il campione non rappresenta adeguatamente la popolazione, influenzando i risultati.\n",
    "  \n",
    "### 5. **Leggi del Campionamento**\n",
    "\n",
    "Esistono alcune leggi matematiche che determinano la quantità di dati da campionare per ottenere un buon risultato statistico:\n",
    "\n",
    "- **Legge dei grandi numeri**: Con l'aumento della dimensione del campione, la media campionaria si avvicina alla media della popolazione.\n",
    "- **Teorema del limite centrale**: Con un numero sufficientemente grande di campioni, la distribuzione della media campionaria tende ad essere normale, indipendentemente dalla distribuzione della popolazione.\n",
    "\n",
    "### Conclusioni\n",
    "\n",
    "Il campionamento è una tecnica potente e fondamentale in statistica e data science. La scelta del metodo di campionamento dipende dal tipo di dati, dalla disponibilità della popolazione e dallo scopo della ricerca. È essenziale essere consapevoli dei potenziali bias e dell'errore di campionamento che possono influenzare la validità dei risultati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33309653-2441-4dd1-8695-37abaef03b58",
   "metadata": {},
   "source": [
    "# **Legge dei Grandi Numeri**\n",
    "\n",
    "## **Introduzione**\n",
    "La **Legge dei Grandi Numeri** (LLN, Law of Large Numbers) è un concetto fondamentale nella teoria della probabilità e nella statistica. Stabilisce che, man mano che il numero di osservazioni aumenta, la media campionaria dei valori osservati tende a convergere verso il valore atteso (la media vera della popolazione).\n",
    "\n",
    "Questa proprietà è essenziale perché giustifica l'uso delle medie campionarie per stimare le medie della popolazione in molte applicazioni pratiche, dalla statistica inferenziale all'apprendimento automatico.\n",
    "\n",
    "---\n",
    "## **Definizione Formale**\n",
    "Sia \\( $X_1, X_2, \\dots, X_n$ \\) una sequenza di variabili casuali indipendenti e identicamente distribuite (i.i.d.), con valore atteso (media):( $mu$) e varianza finita \\( $sigma^2$ ). La media campionaria è definita come:\n",
    "\n",
    "\\[\n",
    "$\\bar{X_n} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n",
    "\\$]\n",
    "\n",
    "La Legge dei Grandi Numeri afferma che:\n",
    "\n",
    "\\[\n",
    "$\\lim_{n \\to \\infty} \\bar{X_n} = \\mu\n",
    "\\$]\n",
    "\n",
    "con probabilità pari a 1, ovvero, la media campionaria converge alla media della popolazione quando \\( n \\) tende a infinito.\n",
    "\n",
    "---\n",
    "## **Tipi di Legge dei Grandi Numeri**\n",
    "Esistono due versioni principali della LLN:\n",
    "\n",
    "1. **Legge dei Grandi Numeri Debole (WLLN - Weak Law of Large Numbers)**\n",
    "   - Stabilisce che la media campionaria \\( \\bar{X_n} \\) converge in probabilità alla media della popolazione \\$( \\mu \\$), ovvero:\n",
    "     \n",
    "     \\[\n",
    "     $P(|\\bar{X_n} - \\mu| \\geq \\varepsilon) \\to 0 \\quad \\text{per ogni} \\quad \\varepsilon > 0, \\text{quando} \\quad n \\to \\infty.$\n",
    "     \\]\n",
    "     \n",
    "   - Questo significa che all'aumentare del numero di osservazioni, la probabilità che la media campionaria sia distante da \\$( \\mu \\$) diventa sempre più piccola.\n",
    "\n",
    "2. **Legge dei Grandi Numeri Forte (SLLN - Strong Law of Large Numbers)**\n",
    "   - Stabilisce che la media campionaria converge quasi certamente a \\( \\mu \\), ovvero:\n",
    "     \n",
    "     \\[\n",
    "     $P(\\lim_{n \\to \\infty} \\bar{X_n} = \\mu) = 1.$\n",
    "     \\]\n",
    "     \n",
    "   - Ciò implica che, con probabilità 1, la successione \\$( \\bar{X_n} \\)$ si avvicina a \\$( \\mu \\$) e non si allontana mai più significativamente.\n",
    "\n",
    "---\n",
    "## **Esempio Intuitivo**\n",
    "Un classico esempio per comprendere la Legge dei Grandi Numeri è il lancio di una moneta equa.\n",
    "\n",
    "- Se lanciamo una moneta, abbiamo probabilità \\( p = 0.5 \\) di ottenere testa e \\( 1 - p = 0.5 \\) di ottenere croce.\n",
    "- Se lanciamo la moneta poche volte (ad esempio 10 lanci), la proporzione di teste potrebbe discostarsi molto da 0.5.\n",
    "- Se aumentiamo il numero di lanci a 100, 1000, 10.000, la proporzione delle teste tenderà a stabilizzarsi attorno a 0.5.\n",
    "\n",
    "---\n",
    "## **Implementazione in Python**\n",
    "Ecco un codice Python che simula la Legge dei Grandi Numeri con il lancio di una moneta.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Impostiamo il seme per la riproducibilità\n",
    "np.random.seed(1)\n",
    "\n",
    "# Parametri della simulazione\n",
    "p = 0.5  # Probabilità di ottenere \"Testa\"\n",
    "n_trials = 10000  # Numero di lanci della moneta\n",
    "\n",
    "# Generazione dei risultati casuali (0 = Croce, 1 = Testa)\n",
    "results = np.random.choice([0, 1], size=n_trials)\n",
    "\n",
    "# Calcolo della media cumulativa\n",
    "cumulative_mean = np.cumsum(results) / np.arange(1, n_trials + 1)\n",
    "\n",
    "# Visualizzazione della convergenza\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(cumulative_mean, label='Media Cumulativa')\n",
    "plt.axhline(p, color='red', linestyle='--', label='Media Vera (0.5)')\n",
    "plt.title(\"Legge dei Grandi Numeri\")\n",
    "plt.xlabel(\"Numero di Lanci\")\n",
    "plt.ylabel(\"Media Cumulativa\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### **Spiegazione del Codice**\n",
    "1. **np.random.seed(1)**: Imposta un seme per rendere i risultati riproducibili.\n",
    "2. **np.random.choice([0, 1], size=n_trials)**: Genera un array di 0 e 1 casuali, simulando i lanci della moneta.\n",
    "3. **np.cumsum(results) / np.arange(1, n_trials + 1)**: Calcola la media cumulativa per ogni passo della simulazione.\n",
    "4. **plt.plot(cumulative_mean)**: Disegna il grafico della media cumulativa per mostrare la convergenza.\n",
    "5. **plt.axhline(p, color='red', linestyle='--')**: Traccia una linea orizzontale alla media teorica attesa (0.5).\n",
    "\n",
    "---\n",
    "## **Osservazioni dai Risultati**\n",
    "- Nei primi tentativi, la media cumulativa oscilla notevolmente, perché il campione è piccolo.\n",
    "- Con l'aumentare del numero di prove, la media cumulativa si stabilizza vicino a 0.5.\n",
    "- Questo dimostra empiricamente la Legge dei Grandi Numeri: più osservazioni si raccolgono, più la media campionaria si avvicina alla media teorica.\n",
    "\n",
    "---\n",
    "## **Applicazioni della Legge dei Grandi Numeri**\n",
    "1. **Statistica e inferenza**: Le medie campionarie vengono utilizzate per stimare parametri di popolazione.\n",
    "2. **Assicurazioni**: Le compagnie assicurative usano questa legge per prevedere i costi futuri.\n",
    "3. **Finanza**: Nell’analisi del rischio e nella previsione dei rendimenti.\n",
    "4. **Apprendimento automatico**: Usata per comprendere il comportamento dei modelli con grandi dataset.\n",
    "5. **Scienze mediche**: Studi clinici usano grandi campioni per stimare con precisione gli effetti dei trattamenti.\n",
    "\n",
    "---\n",
    "## **Conclusione**\n",
    "La Legge dei Grandi Numeri è un concetto chiave della probabilità che garantisce che le medie campionarie convergano verso la media vera quando il numero di osservazioni cresce. Questa proprietà è alla base di molte applicazioni pratiche, dalla statistica all'intelligenza artificiale, ed è verificabile empiricamente attraverso simulazioni come quella vista sopra.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e7f0c-0dfa-4ea9-9901-e9a99b501b7d",
   "metadata": {},
   "source": [
    "# Metodi Monte Carlo: Una Guida Dettagliata\n",
    "\n",
    "## Introduzione ai Metodi Monte Carlo\n",
    "I metodi Monte Carlo sono una classe di algoritmi computazionali che utilizzano campionamenti casuali ripetuti per ottenere risultati numerici. Questi metodi si basano sulla probabilità e sulla statistica per approssimare soluzioni a problemi complessi, spesso impossibili da risolvere analiticamente.\n",
    "\n",
    "Questi metodi prendono il nome dal famoso casinò di Monte Carlo a Monaco, noto per il gioco d'azzardo, poiché si basano sull'uso di numeri casuali proprio come nei giochi di fortuna.\n",
    "\n",
    "## Fondamenti Matematici\n",
    "I metodi Monte Carlo sfruttano il **Teorema del Limite Centrale** e la **Legge dei Grandi Numeri**:\n",
    "- **Legge dei Grandi Numeri**: Se un esperimento viene ripetuto un numero sufficiente di volte, la media dei risultati ottenuti tende al valore atteso teorico.\n",
    "- **Teorema del Limite Centrale**: La distribuzione della media campionaria di variabili casuali indipendenti e identicamente distribuite tende a una distribuzione normale quando il numero di campioni è grande.\n",
    "\n",
    "Questi principi permettono di stimare con alta precisione il valore atteso di una variabile aleatoria anche quando la funzione analitica è sconosciuta.\n",
    "\n",
    "## Passaggi Fondamentali dell'Algoritmo Monte Carlo\n",
    "Un algoritmo Monte Carlo segue questi passaggi:\n",
    "1. **Definizione del Problema**: Identificare il dominio del problema e la quantità da stimare.\n",
    "2. **Generazione di Campioni Casuali**: Creare un insieme di numeri casuali che rappresentano il sistema.\n",
    "3. **Esecuzione del Modello**: Utilizzare i campioni casuali per eseguire calcoli e ottenere risultati.\n",
    "4. **Aggregazione e Analisi dei Risultati**: Calcolare statistiche dai risultati per ottenere una stima dell'incognita.\n",
    "\n",
    "## Applicazioni dei Metodi Monte Carlo\n",
    "I metodi Monte Carlo sono utilizzati in diversi ambiti, tra cui:\n",
    "\n",
    "### 1. **Fisica e Chimica Computazionale**\n",
    "- Simulazione del comportamento di sistemi complessi (es. dinamica molecolare, fisica delle particelle, reazioni chimiche).\n",
    "- Modellazione della diffusione di particelle in un fluido.\n",
    "\n",
    "### 2. **Finanza Quantitativa**\n",
    "- Valutazione di derivati finanziari e opzioni.\n",
    "- Stima del rischio di portafoglio.\n",
    "- Ottimizzazione di strategie di investimento.\n",
    "\n",
    "### 3. **Machine Learning e AI**\n",
    "- Ottimizzazione bayesiana per il tuning di iperparametri.\n",
    "- Generazione di dati sintetici per il training di modelli.\n",
    "\n",
    "### 4. **Scienze della Salute e Epidemiologia**\n",
    "- Simulazione della diffusione di malattie infettive.\n",
    "- Analisi della farmacodinamica e farmacocinetica di nuovi farmaci.\n",
    "\n",
    "### 5. **Ingegneria e Scienze dei Materiali**\n",
    "- Modellazione di sistemi termodinamici complessi.\n",
    "- Simulazione di processi di produzione e ottimizzazione delle catene di fornitura.\n",
    "\n",
    "## Esempio Pratico: Calcolo di Pi Greco con Monte Carlo\n",
    "Uno degli esempi più noti di metodo Monte Carlo è il calcolo del valore di π.\n",
    "\n",
    "### Procedura:\n",
    "1. Disegnare un quadrato di lato 2 e un cerchio inscritto di raggio 1.\n",
    "2. Generare punti casuali all'interno del quadrato.\n",
    "3. Contare quanti punti cadono all'interno del cerchio.\n",
    "4. Stimare π usando la proporzione tra i punti nel cerchio e quelli totali:\n",
    "\n",
    "   \\[ $\\pi \\approx 4 \\times \\frac{N_{cerchio}}{N_{totale}} $\\]\n",
    "\n",
    "### Implementazione in Python:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 10000  # Numero di punti\n",
    "x = np.random.uniform(-1, 1, N)\n",
    "y = np.random.uniform(-1, 1, N)\n",
    "\n",
    "inside_circle = x**2 + y**2 <= 1\n",
    "pi_estimate = (np.sum(inside_circle) / N) * 4\n",
    "\n",
    "print(f\"Stima di Pi Greco: {pi_estimate}\")\n",
    "```\n",
    "\n",
    "## Vantaggi e Svantaggi dei Metodi Monte Carlo\n",
    "\n",
    "### **Vantaggi**:\n",
    "- **Flessibilità**: Possono essere applicati a una vasta gamma di problemi.\n",
    "- **Semplicità di Implementazione**: Facili da scrivere e comprendere.\n",
    "- **Scalabilità**: Funzionano bene con grandi dataset e problemi complessi.\n",
    "\n",
    "### **Svantaggi**:\n",
    "- **Alto Costo Computazionale**: Richiedono molte iterazioni per ottenere risultati precisi.\n",
    "- **Dipendenza dalla Generazione di Numeri Casuali**: La qualità dei risultati dipende dalla qualità dei numeri casuali generati.\n",
    "- **Convergenza Lenta**: Rispetto ad altri metodi numerici, può essere meno efficiente in alcune applicazioni.\n",
    "\n",
    "## Conclusione\n",
    "I metodi Monte Carlo rappresentano uno strumento potente per la simulazione e l'analisi di problemi complessi in molteplici discipline. Il loro principio di base, fondato su campionamenti casuali e stime statistiche, li rende versatili e ampiamente utilizzati in applicazioni scientifiche, finanziarie e ingegneristiche.\n",
    "\n",
    "Se utilizzati correttamente e con un numero adeguato di campioni, i metodi Monte Carlo forniscono risultati accurati e affidabili, contribuendo a migliorare la comprensione e la risoluzione di problemi difficili da affrontare con metodi analitici tradizionali.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb5a18-a64a-4e91-a7fd-0afa2a7ca0d7",
   "metadata": {},
   "source": [
    "Ecco una spiegazione riga per riga del codice:\n",
    "\n",
    "---\n",
    "\n",
    "### **Definizione della Funzione `roulette_spin()`**\n",
    "```python\n",
    "def roulette_spin():\n",
    "    wheel = [i for i in range(0, 37)]\n",
    "    result = np.random.choice(wheel)\n",
    "    return result\n",
    "```\n",
    "1. **`wheel = [i for i in range(0, 37)]`**  \n",
    "   - Crea una lista contenente i numeri della roulette europea, che vanno da 0 a 36.  \n",
    "\n",
    "2. **`result = np.random.choice(wheel)`**  \n",
    "   - Seleziona casualmente un numero dalla lista `wheel` simulando un giro di roulette.  \n",
    "\n",
    "3. **`return result`**  \n",
    "   - Restituisce il numero uscito dalla roulette.\n",
    "\n",
    "---\n",
    "\n",
    "### **Definizione della Funzione `play_roulette_game(n_spins)`**\n",
    "```python\n",
    "def play_roulette_game(n_spins):\n",
    "    \n",
    "    balance = 0\n",
    "    bet = 1\n",
    "```\n",
    "4. **`balance = 0`**  \n",
    "   - Inizializza il saldo del giocatore a 0€.  \n",
    "\n",
    "5. **`bet = 1`**  \n",
    "   - Fissa la puntata iniziale a 1€.  \n",
    "\n",
    "---\n",
    "```python\n",
    "    for _ in range(n_spins):\n",
    "        result = roulette_spin()\n",
    "```\n",
    "6. **`for _ in range(n_spins):`**  \n",
    "   - Ripete il ciclo `n_spins` volte (numero di giri della roulette).  \n",
    "\n",
    "7. **`result = roulette_spin()`**  \n",
    "   - Simula un giro della roulette e salva il numero uscito in `result`.\n",
    "\n",
    "---\n",
    "\n",
    "### **Determinazione del Colore del Numero Uscito**\n",
    "```python\n",
    "        if result in range(1, 11) or result in range(19, 29):\n",
    "            if result % 2 == 0:  # Win condition (black)\n",
    "                balance += bet\n",
    "            else:  # Lose condition (red)\n",
    "                balance -= bet\n",
    "```\n",
    "8. **`if result in range(1, 11) or result in range(19, 29):`**  \n",
    "   - Se il numero è tra **1-10 o 19-28**, si applicano le seguenti regole di colore:  \n",
    "     - I numeri pari sono **neri**  \n",
    "     - I numeri dispari sono **rossi**  \n",
    "\n",
    "9. **`if result % 2 == 0:`**  \n",
    "   - Se il numero è pari (nero), il giocatore vince e il saldo aumenta di 1€.  \n",
    "\n",
    "10. **`else:`**  \n",
    "   - Se il numero è dispari (rosso), il giocatore perde e il saldo diminuisce di 1€.  \n",
    "\n",
    "---\n",
    "```python\n",
    "        elif result in range(11, 19) or result in range(29, 37):\n",
    "            if result % 2 != 0:  # Win condition (black)\n",
    "                balance += bet\n",
    "            else:  # Lose condition (red)\n",
    "                balance -= bet\n",
    "```\n",
    "11. **`elif result in range(11, 19) or result in range(29, 37):`**  \n",
    "    - Se il numero è tra **11-18 o 29-36**, si applicano le seguenti regole di colore:  \n",
    "      - I numeri dispari sono **neri**  \n",
    "      - I numeri pari sono **rossi**  \n",
    "\n",
    "12. **`if result % 2 != 0:`**  \n",
    "    - Se il numero è dispari (nero), il giocatore vince e guadagna 1€.  \n",
    "\n",
    "13. **`else:`**  \n",
    "    - Se il numero è pari (rosso), il giocatore perde 1€.  \n",
    "\n",
    "---\n",
    "```python\n",
    "        else:  # Zero\n",
    "            balance -= bet  # The house wins\n",
    "```\n",
    "14. **Se il numero è 0**  \n",
    "    - Il giocatore perde automaticamente, quindi il saldo diminuisce di 1€.  \n",
    "\n",
    "---\n",
    "```python\n",
    "    return balance\n",
    "```\n",
    "15. **Restituisce il saldo finale** dopo `n_spins` giri.\n",
    "\n",
    "---\n",
    "\n",
    "### **Simulazione Monte Carlo**\n",
    "```python\n",
    "n_simulations = 10000\n",
    "n_spins = 100\n",
    "```\n",
    "16. **`n_simulations = 10000`**  \n",
    "    - Simula 10.000 partite di roulette.  \n",
    "\n",
    "17. **`n_spins = 100`**  \n",
    "    - Ogni partita consiste in 100 giri di roulette.  \n",
    "\n",
    "---\n",
    "```python\n",
    "results = [play_roulette_game(n_spins) for _ in range(n_simulations)]\n",
    "```\n",
    "18. **`[play_roulette_game(n_spins) for _ in range(n_simulations)]`**  \n",
    "    - Esegue `play_roulette_game(n_spins)` 10.000 volte e salva i risultati nella lista `results`.\n",
    "\n",
    "---\n",
    "```python\n",
    "mean_balance = np.mean(results)\n",
    "std_dev_balance = np.std(results)\n",
    "```\n",
    "19. **`np.mean(results)`**  \n",
    "    - Calcola il saldo medio dopo 100 giri di roulette.  \n",
    "\n",
    "20. **`np.std(results)`**  \n",
    "    - Calcola la deviazione standard dei saldi finali.  \n",
    "\n",
    "---\n",
    "### **Grafico della Distribuzione dei Risultati**\n",
    "```python\n",
    "plt.hist(results, bins=38, color='green', alpha=0.7, edgecolor='black')\n",
    "```\n",
    "21. **`plt.hist(results, bins=38, color='green', alpha=0.7, edgecolor='black')`**  \n",
    "    - Crea un istogramma con 38 bin (uno per ogni possibile saldo finale).  \n",
    "    - Il colore del grafico è verde con trasparenza 0.7 e bordi neri.  \n",
    "\n",
    "---\n",
    "```python\n",
    "plt.axvline(mean_balance, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_balance:.2f}')\n",
    "```\n",
    "22. **`plt.axvline(mean_balance, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_balance:.2f}')`**  \n",
    "    - Disegna una linea verticale rossa tratteggiata che indica il saldo medio.  \n",
    "\n",
    "---\n",
    "```python\n",
    "plt.title(f\"Monte Carlo Simulation of Roulette Game\\nAverage final balance after {n_spins} spins\")\n",
    "plt.xlabel(\"Final Balance ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "23. **Titolo e etichette del grafico**  \n",
    "    - **`plt.title(...)`** → Imposta il titolo del grafico.  \n",
    "    - **`plt.xlabel(\"Final Balance ($)\")`** → Etichetta dell'asse X (saldo finale).  \n",
    "    - **`plt.ylabel(\"Frequency\")`** → Etichetta dell'asse Y (frequenza).  \n",
    "    - **`plt.legend()`** → Mostra la legenda.  \n",
    "    - **`plt.show()`** → Mostra il grafico.  \n",
    "\n",
    "---\n",
    "### **Stampa dei Risultati**\n",
    "```python\n",
    "print(f\"Average balance after {n_spins} spins: ${mean_balance:.2f}\")\n",
    "print(f\"Standard deviation of balance: ${std_dev_balance:.2f}\")\n",
    "```\n",
    "24. **Stampa del saldo medio e deviazione standard**  \n",
    "    - Il saldo medio finale dopo 100 giri viene stampato con due decimali.  \n",
    "    - La deviazione standard indica la variabilità nei risultati.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusione**\n",
    "Questo codice esegue una **simulazione Monte Carlo** su un gioco di roulette in cui il giocatore punta sempre sul nero. I risultati mostrano come il saldo finale varia tra le partite e come, nel lungo periodo, la casa tende ad avere un vantaggio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064218ee-66aa-4f78-bbf7-db124653734b",
   "metadata": {},
   "source": [
    "# Teorema del Limite Centrale (Central Limit Theorem - CLT)\n",
    "\n",
    "## Introduzione\n",
    "Il **Teorema del Limite Centrale (CLT - Central Limit Theorem)** è uno dei concetti fondamentali della statistica inferenziale. Esso afferma che, indipendentemente dalla distribuzione della popolazione di partenza, la distribuzione della media campionaria si avvicina sempre di più a una distribuzione normale all'aumentare della dimensione del campione.\n",
    "\n",
    "Questo teorema è essenziale perché permette di applicare metodi statistici basati sulla normalità anche quando la distribuzione originale dei dati non è normale. In particolare, ci consente di effettuare inferenze sulle popolazioni basandoci solo su campioni.\n",
    "\n",
    "## Dichiarazione formale del CLT\n",
    "Data una popolazione con media \\(\\mu\\) e deviazione standard \\(\\sigma\\), se estraiamo molti campioni casuali di grandezza \\(n\\) e calcoliamo la media di ciascun campione, allora:\n",
    "\n",
    "1. La distribuzione delle medie campionarie tenderà a seguire una **distribuzione normale** man mano che \\(n\\) aumenta (tipicamente \\(n \\geq 30\\) è sufficiente).\n",
    "2. La media della distribuzione delle medie campionarie sarà uguale alla media della popolazione:  \n",
    "   \\[$\\mu_{\\bar{x}} = \\mu$\\]\n",
    "3. La deviazione standard della distribuzione delle medie campionarie, nota come **errore standard della media**, sarà pari a:  \n",
    "   \\[$\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}$\\]\n",
    "\n",
    "### Implicazioni del CLT\n",
    "- Anche se la popolazione originale ha una distribuzione non normale, la distribuzione delle medie campionarie sarà **approssimativamente normale**.\n",
    "- Questo è fondamentale per l'inferenza statistica, poiché consente di utilizzare test parametrici basati sulla normalità.\n",
    "\n",
    "---\n",
    "\n",
    "## Esempio Pratico con Python\n",
    "Per comprendere meglio il CLT, possiamo fare un esperimento pratico generando dati da una distribuzione **esponenziale** (che non è normale) e calcolando le medie di campioni ripetuti.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definiamo la dimensione del campione\n",
    "sample_size = 10000\n",
    "\n",
    "# Creiamo 10.000 medie campionarie da una distribuzione esponenziale\n",
    "sample_means = [np.mean(np.random.exponential(1/4, sample_size)) for _ in range(10000)]\n",
    "\n",
    "# Creiamo l'istogramma delle medie campionarie\n",
    "plt.hist(sample_means, bins=30, density=True, color='red', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"Central Limit Theorem\")\n",
    "plt.xlabel(\"Sample means\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### Spiegazione del codice\n",
    "1. Generiamo una popolazione da una distribuzione esponenziale con tasso \\(\\lambda = 4\\) (che ha una forma fortemente asimmetrica).\n",
    "2. Estraiamo 10.000 campioni di dimensione \\(n = 10000\\) e calcoliamo la media di ciascun campione.\n",
    "3. Plottiamo l'istogramma delle medie campionarie.\n",
    "4. Osserviamo che la distribuzione risultante è **approssimativamente normale**, nonostante la distribuzione di partenza fosse esponenziale.\n",
    "\n",
    "---\n",
    "\n",
    "## Dimostrazione del CLT tramite Simulazione\n",
    "Per dimostrare ulteriormente il CLT, possiamo provare con diverse distribuzioni di partenza e osservare come si comporta la distribuzione delle medie campionarie.\n",
    "\n",
    "### 1. Distribuzione Uniforme\n",
    "```python\n",
    "sample_size = 100\n",
    "sample_means = [np.mean(np.random.uniform(0, 10, sample_size)) for _ in range(10000)]\n",
    "plt.hist(sample_means, bins=30, density=True, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"CLT con distribuzione uniforme\")\n",
    "plt.xlabel(\"Sample means\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. Distribuzione di Poisson\n",
    "```python\n",
    "sample_size = 50\n",
    "sample_means = [np.mean(np.random.poisson(5, sample_size)) for _ in range(10000)]\n",
    "plt.hist(sample_means, bins=30, density=True, color='green', alpha=0.7, edgecolor='black')\n",
    "plt.title(\"CLT con distribuzione di Poisson\")\n",
    "plt.xlabel(\"Sample means\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Come si può vedere, indipendentemente dalla distribuzione originale (uniforme, esponenziale, Poisson), la distribuzione delle medie campionarie tende a una **distribuzione normale**.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusioni\n",
    "Il **Teorema del Limite Centrale** è un principio fondamentale della statistica che permette di trattare molte situazioni pratiche con strumenti basati sulla normalità. In particolare:\n",
    "\n",
    "- È alla base delle tecniche di inferenza statistica.\n",
    "- Ci permette di stimare intervalli di confidenza e condurre test statistici parametrici.\n",
    "- Dimostra che, anche se i dati originali non sono normali, le medie campionarie lo saranno per campioni sufficientemente grandi.\n",
    "\n",
    "Il CLT è un potente strumento per analizzare dati reali e fare inferenze affidabili, motivo per cui è uno dei concetti più importanti per chiunque lavori con la statistica e l'analisi dei dati.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069853a1-fd3c-4004-a22d-01252e254391",
   "metadata": {},
   "source": [
    "# Errori Standard e Intervalli di Confidenza\n",
    "\n",
    "## 1. Introduzione\n",
    "\n",
    "L'inferenza statistica ci permette di fare delle stime educative su un parametro della popolazione basandoci su un campione. Tuttavia, a causa della variabilità del campionamento, ogni stima (statistica) basata su un campione non sarà esattamente uguale al vero parametro della popolazione. Per quantificare questa incertezza, utilizziamo l'**errore standard (SE)** e gli **intervalli di confidenza (CI)**.\n",
    "\n",
    "### Errore Standard (SE)\n",
    "L'**errore standard** misura la variabilità di una statistica campionaria da un campione all'altro. Quantifica quanto una stima del campione è destinata a fluttuare a causa del campionamento casuale.\n",
    "\n",
    "Matematicamente, l'errore standard della media (SEM) è dato da:\n",
    "\\[$\n",
    "SE = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$\\]\n",
    "dove:\n",
    "- \\($ \\sigma $\\) è la deviazione standard della popolazione\n",
    "- \\($ n $\\) è la dimensione del campione\n",
    "\n",
    "Se la deviazione standard della popolazione \\( \\sigma \\) è sconosciuta, la stimiamo utilizzando la deviazione standard del campione \\( s \\):\n",
    "\\[$\n",
    "SE = \\frac{s}{\\sqrt{n}}\n",
    "$\\]\n",
    "\n",
    "L'errore standard è fondamentale perché determina la precisione della nostra stima del campione. Un SE più piccolo indica una stima più precisa.\n",
    "\n",
    "---\n",
    "## 2. Intervalli di Confidenza (CI)\n",
    "Un **intervallo di confidenza** fornisce un intervallo di valori plausibili per un parametro della popolazione con un livello di confidenza specificato (ad esempio, 95%). Esso è composto da una **stima** più o meno un **margine di errore (ME)**.\n",
    "\n",
    "### Formula Generale per gli Intervalli di Confidenza\n",
    "\\[$\n",
    "CI = \\text{stima} \\pm (\\text{valore critico} \\times \\text{errore standard})\n",
    "$\\]\n",
    "\n",
    "Ad esempio, l'intervallo di confidenza per la media della popolazione \\( \\mu \\) è dato da:\n",
    "\\[$\n",
    "CI = \\bar{x} \\pm (z^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "- \\($ \\bar{x} $\\) è la media del campione\n",
    "- \\($ z^*$ \\) è il valore critico dalla distribuzione normale standard (per campioni grandi, o quando la varianza della popolazione è conosciuta)\n",
    "- \\($ SE $\\) è l'errore standard\n",
    "\n",
    "Se la varianza della popolazione è sconosciuta e la dimensione del campione è piccola (tipicamente \\( n < 30 \\)), si utilizza la **distribuzione t** invece della distribuzione normale:\n",
    "\\[$\n",
    "CI = \\bar{x} \\pm (t^* \\times SE)\n",
    "$\\]\n",
    "dove \\($ t^* $\\) è il valore critico dalla **distribuzione t** con \\($ n - 1$ \\) gradi di libertà.\n",
    "\n",
    "### Scelta del Valore Critico\n",
    "Il valore critico corrisponde al livello di **confidenza desiderato (CL)**. I livelli di confidenza più comuni e i loro valori critici corrispondenti (per una distribuzione normale) sono:\n",
    "\n",
    "| Livello di Confidenza | Valore \\( z^* \\) |\n",
    "|-----------------------|------------------|\n",
    "| 90%                   | 1.645            |\n",
    "| 95%                   | 1.960            |\n",
    "| 99%                   | 2.576            |\n",
    "\n",
    "Per campioni piccoli, i valori \\( t^* \\) si ottengono da tabelle statistiche.\n",
    "\n",
    "---\n",
    "## 3. Interpretazione degli Intervalli di Confidenza\n",
    "Un **intervallo di confidenza del 95%** significa che se ripetessimo il nostro processo di campionamento molte volte, circa il 95% degli intervalli risultanti conterranno il vero parametro della popolazione.\n",
    "\n",
    "### Esempio:\n",
    "Supponiamo di raccogliere un campione di 50 individui per stimare l'altezza media in una popolazione. La media del campione è di \\( 170 \\) cm, e la deviazione standard del campione è di \\( 10 \\) cm.\n",
    "\n",
    "1. Calcoliamo l'errore standard (SE):\n",
    "   \\[$\n",
    "   SE = \\frac{10}{\\sqrt{50}} = 1.414\n",
    "   $\\]\n",
    "2. Determiniamo il valore critico per un intervallo di confidenza al 95%: \\( z^* = 1.96 \\)\n",
    "3. Calcoliamo il margine di errore (ME):\n",
    "   \\[$\n",
    "   ME = 1.96 \\times 1.414 = 2.77\n",
    "  $ \\]\n",
    "4. Calcoliamo l'intervallo di confidenza:\n",
    "   \\[$\n",
    "   170 \\pm 2.77 = (167.23, 172.77)\n",
    "  $ \\]\n",
    "Pertanto, stimiamo con il 95% di confidenza che la vera altezza media nella popolazione sia tra **167.23 cm e 172.77 cm**.\n",
    "\n",
    "---\n",
    "## 4. Fattori che Influenzano gli Intervalli di Confidenza\n",
    "Diversi fattori influenzano la larghezza di un intervallo di confidenza:\n",
    "1. **Dimensione del campione (n):** Un campione più grande riduce l'errore standard, portando a un **intervallo di confidenza più stretto**.\n",
    "2. **Livello di confidenza:** Livelli di confidenza più alti (ad esempio, 99%) aumentano il valore critico, portando a un **intervallo di confidenza più ampio**.\n",
    "3. **Variabilità nei dati:** Maggiore variabilità (deviazione standard più alta) porta a un **intervallo di confidenza più ampio**.\n",
    "\n",
    "---\n",
    "## 5. Intervalli di Confidenza per Altre Statistiche\n",
    "### 5.1. Intervallo di Confidenza per una Proporzione\n",
    "Per una proporzione della popolazione \\( p \\), l'intervallo di confidenza si calcola come:\n",
    "\\[$\n",
    "CI = \\hat{p} \\pm (z^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "- \\( $\\hat{p}$ \\) è la proporzione del campione\n",
    "- \\($ SE = \\sqrt{\\frac{\\hat{p} (1 - \\hat{p})}{n}} $\\)\n",
    "\n",
    "### 5.2. Intervallo di Confidenza per la Differenza tra Due Medie\n",
    "Quando si confrontano due gruppi indipendenti (ad esempio, trattamento vs. controllo), l'intervallo di confidenza per la differenza tra le medie è:\n",
    "\\[$\n",
    "CI = (\\bar{x}_1 - \\bar{x}_2) \\pm (t^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "\\[$$\n",
    "SE = \\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}\n",
    "\\]\n",
    "e \\($ s_1, s_2 $\\) sono le deviazioni standard dei campioni.\n",
    "\n",
    "### 5.3. Intervallo di Confidenza per la Differenza tra Due Proporzioni\n",
    "Per due proporzioni della popolazione \\( p_1 \\) e \\( p_2 \\):\n",
    "\\[$\n",
    "CI = (\\hat{p}_1 - \\hat{p}_2) \\pm (z^* \\times SE)\n",
    "$\\]\n",
    "dove:\n",
    "\\[$\n",
    "SE = \\sqrt{\\frac{\\hat{p}_1 (1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2 (1 - \\hat{p}_2)}{n_2}}\n",
    "$\\]\n",
    "\n",
    "---\n",
    "## 6. Conclusione\n",
    "Gli intervalli di confidenza forniscono un metodo essenziale per quantificare l'incertezza delle stime basate su un campione. Essi dipendono dall'errore standard, dalla dimensione del campione e dal livello di confidenza scelto. Una comprensione corretta e l'applicazione degli intervalli di confidenza consentono di prendere decisioni informate nella ricerca scientifica, nell'analisi aziendale e negli studi sanitari.\n",
    "\n",
    "Padroneggiando gli errori standard e gli intervalli di confidenza, è possibile valutare l'affidabilità dei dati e trarre conclusioni significative dalle analisi statistiche."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354a991a-e043-4e57-9c76-3dfcc00de40c",
   "metadata": {},
   "source": [
    "Ecco una spiegazione riga per riga del codice:\n",
    "\n",
    "---\n",
    "\n",
    "### **Importazione delle librerie**\n",
    "```python\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "- `scipy.stats`: Modulo di `SciPy` per calcolare il valore critico della distribuzione normale.\n",
    "- `numpy`: Utilizzato per generare dati casuali e calcolare statistiche.\n",
    "- `matplotlib.pyplot`: Serve per creare il grafico delle confidence intervals.\n",
    "\n",
    "---\n",
    "\n",
    "### **Generazione della popolazione**\n",
    "```python\n",
    "population = np.random.normal(loc=100, scale=15, size=100000)\n",
    "```\n",
    "- Generiamo una **popolazione** di 100.000 elementi da una distribuzione **normale** con:\n",
    "  - Media (`loc=100`)\n",
    "  - Deviazione standard (`scale=15`)\n",
    "  - Dimensione (`size=100000`).\n",
    "\n",
    "---\n",
    "\n",
    "### **Campionamento senza sostituzione**\n",
    "```python\n",
    "sample_size = 100000\n",
    "sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "```\n",
    "- Estraiamo un **campione** di dimensione 100.000 **senza sostituzione** (`replace=False`) dalla popolazione.\n",
    "\n",
    "---\n",
    "\n",
    "### **Calcolo delle statistiche campionarie**\n",
    "```python\n",
    "sample_mean = np.mean(sample)\n",
    "sample_std = np.std(sample, ddof=1)\n",
    "standard_error = sample_std / np.sqrt(sample_size)\n",
    "```\n",
    "- `sample_mean`: Media del campione.\n",
    "- `sample_std`: Deviazione standard del campione, con `ddof=1` per applicare la **correzione di Bessel** (utilizzata per stimare la deviazione standard della popolazione).\n",
    "- `standard_error`: L'**errore standard** della media è calcolato come:\n",
    "  \\[\n",
    "  SE = \\frac{\\text{sample_std}}{\\sqrt{\\text{sample_size}}}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **Determinazione del valore critico z per il 95% CI**\n",
    "```python\n",
    "confidence_level = 0.95\n",
    "z_critical = stats.norm.ppf((1 + confidence_level) / 2)\n",
    "```\n",
    "- Il **valore critico z** (z-score) per un intervallo di confidenza del **95%** viene calcolato usando `stats.norm.ppf()`, che restituisce il quantile della distribuzione normale.\n",
    "- Poiché il livello di confidenza è **95%**, calcoliamo il quantile corrispondente a:\n",
    "  \\[\n",
    "  \\frac{1 + 0.95}{2} = 0.975\n",
    "  \\]\n",
    "  Il valore di **z** per il 95% è **circa 1.96**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Calcolo del margine di errore e intervallo di confidenza**\n",
    "```python\n",
    "margin_of_error = z_critical * standard_error\n",
    "ci_lower, ci_upper = sample_mean - margin_of_error, sample_mean + margin_of_error\n",
    "```\n",
    "- `margin_of_error`: Determina l'ampiezza dell'intervallo di confidenza.\n",
    "  \\[\n",
    "  ME = z^* \\times SE\n",
    "  \\]\n",
    "- `ci_lower`, `ci_upper`: Calcoliamo il **limite inferiore** e **superiore** dell'intervallo di confidenza.\n",
    "\n",
    "---\n",
    "\n",
    "### **Stampa dei risultati**\n",
    "```python\n",
    "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n",
    "```\n",
    "- Stampiamo la **media campionaria** e l'**intervallo di confidenza** con due cifre decimali.\n",
    "\n",
    "---\n",
    "\n",
    "### **Simulazione di più intervalli di confidenza**\n",
    "```python\n",
    "n_simulations = 100  # Number of confidence intervals to generate\n",
    "sample_size = 50\n",
    "true_mean = np.mean(population)\n",
    "```\n",
    "- `n_simulations = 100`: Generiamo **100** intervalli di confidenza.\n",
    "- `sample_size = 50`: La dimensione del campione per ogni simulazione è **50**.\n",
    "- `true_mean = np.mean(population)`: Calcoliamo la **vera media della popolazione**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Creazione del grafico**\n",
    "```python\n",
    "plt.figure(figsize=(8, 6))\n",
    "```\n",
    "- Imposta la dimensione del grafico **8x6**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Generazione degli intervalli di confidenza multipli**\n",
    "```python\n",
    "for i in range(n_simulations):\n",
    "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
    "    sample_mean = np.mean(sample)\n",
    "    standard_error = np.std(sample, ddof=1) / np.sqrt(sample_size)\n",
    "    margin_of_error = z_critical * standard_error\n",
    "    ci_lower, ci_upper = sample_mean - margin_of_error, sample_mean + margin_of_error\n",
    "```\n",
    "- Per **ogni simulazione**, eseguiamo i seguenti passi:\n",
    "  1. **Estrazione di un campione** di 50 osservazioni dalla popolazione.\n",
    "  2. **Calcolo della media campionaria**.\n",
    "  3. **Calcolo dell'errore standard**.\n",
    "  4. **Determinazione del margine di errore** e dei **limiti dell'intervallo di confidenza**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Plot degli intervalli di confidenza**\n",
    "```python\n",
    "plt.plot([ci_lower, ci_upper], [i, i], color='blue' if (ci_lower <= true_mean <= ci_upper) else 'red')\n",
    "plt.plot(sample_mean, i, 'bo')  # Sample mean point\n",
    "```\n",
    "- Disegniamo **una linea orizzontale** per ogni intervallo di confidenza:\n",
    "  - Se l'intervallo contiene la vera media della popolazione (`true_mean`), la linea è **blu**.\n",
    "  - Se l'intervallo **non** contiene la vera media, la linea è **rossa** (questo dovrebbe accadere in circa il 5% dei casi, in base alla teoria degli intervalli di confidenza al 95%).\n",
    "- `plt.plot(sample_mean, i, 'bo')`: Plotta la **media campionaria** come un punto **blu**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Linea della media della popolazione**\n",
    "```python\n",
    "plt.axvline(true_mean, color='black', linestyle=\"--\", label=\"True Mean\")\n",
    "```\n",
    "- Disegniamo una **linea verticale tratteggiata nera** per rappresentare la **vera media della popolazione**.\n",
    "\n",
    "---\n",
    "\n",
    "### **Etichette e visualizzazione del grafico**\n",
    "```python\n",
    "plt.xlabel(\"Sample Mean with Confidence Interval\")\n",
    "plt.ylabel(\"Simulation Index\")\n",
    "plt.title(\"Multiple 95% Confidence Intervals\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "- `plt.xlabel(\"Sample Mean with Confidence Interval\")`: Etichetta dell'asse X.\n",
    "- `plt.ylabel(\"Simulation Index\")`: Etichetta dell'asse Y.\n",
    "- `plt.title(\"Multiple 95% Confidence Intervals\")`: Titolo del grafico.\n",
    "- `plt.legend()`: Aggiunge la legenda.\n",
    "- `plt.show()`: Mostra il grafico.\n",
    "\n",
    "---\n",
    "\n",
    "### **Risultato atteso**\n",
    "- Il grafico mostra **100 intervalli di confidenza**.\n",
    "- Circa **95 su 100** dovrebbero contenere la vera media della popolazione (**blu**).\n",
    "- Circa **5 su 100** potrebbero **non** contenere la vera media (**rosso**).\n",
    "\n",
    "Questa simulazione aiuta a **visualizzare il concetto degli intervalli di confidenza** e a comprendere l'incertezza nelle stime statistiche. 🎯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b1b41-a53c-4c0f-811e-18e607ad0555",
   "metadata": {},
   "source": [
    "# **Lezione dettagliata sul Bootstrap**\n",
    "\n",
    "## **Introduzione**\n",
    "\n",
    "Il **Bootstrap** è un metodo di **ri campionamento** utilizzato per stimare la distribuzione di una statistica (media, mediana, varianza, ecc.) attraverso campionamenti ripetuti con riposizionamento (*with replacement*) dai dati originali.\n",
    "\n",
    "Questa tecnica è particolarmente utile quando:\n",
    "- La distribuzione della popolazione è **sconosciuta** o complessa.\n",
    "- La dimensione del campione è **piccola** e i metodi teorici tradizionali potrebbero non essere affidabili.\n",
    "- Si desidera **costruire intervalli di confidenza** o stimare l'errore standard di una statistica senza dover fare assunzioni parametriche.\n",
    "\n",
    "## **Principi Fondamentali**\n",
    "\n",
    "1. **Campionamento con riposizionamento**: ogni osservazione ha la possibilità di essere selezionata più volte in ogni campione bootstrap.\n",
    "2. **Ripetizione del processo**: si ripete il processo di campionamento molte volte (tipicamente 1000 o più iterazioni).\n",
    "3. **Calcolo delle statistiche**: su ogni campione estratto si calcola la statistica di interesse (es. media, mediana, varianza).\n",
    "4. **Distribuzione delle statistiche**: dopo aver generato molti valori della statistica, possiamo approssimare la sua distribuzione empirica.\n",
    "5. **Stima dell'incertezza**: si usano i dati ottenuti per calcolare errori standard, intervalli di confidenza e altre misure di incertezza.\n",
    "\n",
    "## **Esempio pratico con Python**\n",
    "\n",
    "Utilizziamo Python per implementare il bootstrap su dati generati da una distribuzione esponenziale.\n",
    "\n",
    "### **Passo 1: Importazione delle librerie**\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "### **Passo 2: Creazione del dataset**\n",
    "Per il nostro esempio, generiamo 100 dati da una distribuzione **esponenziale** con parametro \\( \\lambda = 1/3 \\).\n",
    "```python\n",
    "np.random.seed(42)  # Per rendere i risultati riproducibili\n",
    "lambda_param = 1 / 3\n",
    "\n",
    "# Generazione dei dati\n",
    "n_samples = 100\n",
    "data = np.random.exponential(scale=1/lambda_param, size=n_samples)\n",
    "```\n",
    "\n",
    "### **Passo 3: Implementazione del Bootstrap**\n",
    "Scriviamo una funzione che esegua il ri campionamento bootstrap e calcoli la statistica desiderata (in questo caso la **mediana**).\n",
    "```python\n",
    "def bootstrap_resample(data, statistic_func, n_bootstrap_samples):\n",
    "    \"\"\"\n",
    "    Esegue il Bootstrap per stimare la distribuzione di una statistica.\n",
    "    \n",
    "    Parametri:\n",
    "    - data: array di dati originali\n",
    "    - statistic_func: funzione statistica da applicare ai campioni\n",
    "    - n_bootstrap_samples: numero di campioni bootstrap da generare\n",
    "    \n",
    "    Ritorna:\n",
    "    - Un array contenente i valori della statistica su ogni campione bootstrap\n",
    "    \"\"\"\n",
    "    bootstrap_stats = []\n",
    "    n = len(data)\n",
    "    \n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        sample = np.random.choice(data, size=n, replace=True)  # Estrazione con riposizionamento\n",
    "        bootstrap_stats.append(statistic_func(sample))\n",
    "    \n",
    "    return np.array(bootstrap_stats)\n",
    "```\n",
    "\n",
    "### **Passo 4: Calcolo dell'errore standard e intervallo di confidenza**\n",
    "Ora applichiamo il metodo per stimare la distribuzione della mediana dei dati e calcolare un **intervallo di confidenza del 95%**.\n",
    "```python\n",
    "n_bootstrap_samples = 10000  # Numero di campioni bootstrap\n",
    "bootstrap_medians = bootstrap_resample(data, np.median, n_bootstrap_samples)\n",
    "\n",
    "# Calcolo dell'errore standard\n",
    "standard_error = np.std(bootstrap_medians)\n",
    "\n",
    "# Intervallo di confidenza al 95%\n",
    "ci_lower = np.percentile(bootstrap_medians, 2.5)\n",
    "ci_upper = np.percentile(bootstrap_medians, 97.5)\n",
    "\n",
    "print(f\"Bootstrap Standard Error: {standard_error:.3f}\")\n",
    "print(f\"95% Bootstrap Confidence Interval: [{ci_lower:.3f}, {ci_upper:.3f}]\")\n",
    "```\n",
    "#### **Risultati attesi (variano leggermente a seconda del campione generato):**\n",
    "```\n",
    "Bootstrap Standard Error: 0.345\n",
    "95% Bootstrap Confidence Interval: [1.193, 2.520]\n",
    "```\n",
    "\n",
    "### **Passo 5: Visualizzazione della distribuzione bootstrap**\n",
    "Per avere un'idea della distribuzione della mediana stimata:\n",
    "```python\n",
    "plt.hist(bootstrap_medians, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(ci_lower, color='red', linestyle='dashed', label='2.5 percentile')\n",
    "plt.axvline(ci_upper, color='red', linestyle='dashed', label='97.5 percentile')\n",
    "plt.xlabel('Mediana Bootstrap')\n",
    "plt.ylabel('Frequenza')\n",
    "plt.title('Distribuzione Bootstrap della Mediana')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## **Vantaggi del Bootstrap**\n",
    "- **Non richiede ipotesi sulla distribuzione**: Funziona bene anche quando la distribuzione dei dati è sconosciuta.\n",
    "- **Facile da implementare**: Non richiede formule matematiche complesse.\n",
    "- **Adattabile a molte statistiche**: Può essere usato per medie, mediane, deviazioni standard e molte altre metriche.\n",
    "- **Utile per piccoli campioni**: Permette di ottenere stime affidabili anche quando il dataset è ridotto.\n",
    "\n",
    "## **Svantaggi e Limiti**\n",
    "- **Computazionalmente intensivo**: Richiede molte iterazioni, quindi è più lento rispetto ai metodi analitici tradizionali.\n",
    "- **Non sempre applicabile**: Se i dati hanno forte dipendenza tra loro (es. serie temporali), il metodo potrebbe non essere affidabile.\n",
    "\n",
    "## **Conclusione**\n",
    "Il Bootstrap è una tecnica estremamente potente e flessibile per stimare la distribuzione di una statistica e costruire intervalli di confidenza senza fare forti assunzioni sui dati. Grazie alla sua semplicità e robustezza, è uno strumento essenziale nell'analisi dei dati e nella statistica computazionale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22102413-0bc1-457f-ad09-12c1080233d0",
   "metadata": {},
   "source": [
    "# Test delle ipotesi e t-test\n",
    "\n",
    "## Introduzione\n",
    "Il **test delle ipotesi** (\n",
    "Hypothesis Testing) è una tecnica statistica utilizzata per valutare se un'asserzione riguardante un insieme di dati è supportata dall'evidenza empirica.\n",
    "Esistono diversi tipi di test di significatività, che variano a seconda del tipo di dati, del numero di campioni e della misura che si desidera confrontare.\n",
    "Uno dei test più comuni è il **t-test**, utilizzato per confrontare le medie di due gruppi quando i dati sono numerici e seguono una distribuzione normale.\n",
    "\n",
    "---\n",
    "## Definizione delle ipotesi\n",
    "Prima di condurre un test statistico, si formulano due ipotesi:\n",
    "- **Ipotesi nulla (H₀)**: afferma che non c'è differenza significativa tra i gruppi.\n",
    "- **Ipotesi alternativa (H₁)**: afferma che esiste una differenza significativa tra i gruppi.\n",
    "\n",
    "Nel caso del nostro esempio:\n",
    "- **H₀**: Il trattamento non ha effetto sulla pressione sanguigna (le due medie sono uguali).\n",
    "- **H₁**: Il trattamento ha un effetto sulla pressione sanguigna (le due medie sono diverse).\n",
    "\n",
    "---\n",
    "## Il t-test per il confronto delle medie\n",
    "Il **t-test indipendente** (\n",
    "t-test for independent samples) viene utilizzato quando vogliamo confrontare le medie di due gruppi indipendenti tra loro.\n",
    "\n",
    "La formula del test t è:\n",
    "\\[$\n",
    "t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n",
    "$\\]\n",
    "dove:\n",
    "- \\($\\bar{X_1}\\) e \\(\\bar{X_2}$\\) sono le medie dei due gruppi,\n",
    "- \\($s_1^2\\) e \\(s_2^2$\\) sono le varianze campionarie,\n",
    "- \\($n_1\\) e \\(n_2$\\) sono le dimensioni campionarie dei due gruppi.\n",
    "\n",
    "Il valore di t ottenuto viene confrontato con una distribuzione **t di Student** per determinare se la differenza tra le medie è statisticamente significativa.\n",
    "\n",
    "---\n",
    "## Implementazione in Python\n",
    "Eseguiamo ora un esempio pratico con Python utilizzando `numpy` e `scipy.stats`.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Impostiamo il seed per la riproducibilità\n",
    "np.random.seed(42)\n",
    "\n",
    "# Definiamo la dimensione del campione\n",
    "sample_size = 50\n",
    "\n",
    "# Generiamo dati casuali per due gruppi\n",
    "placebo_group = np.random.normal(loc=120, scale=10, size=sample_size)  # Media 120, deviazione standard 10\n",
    "treatment_group = np.random.normal(loc=115, scale=10, size=sample_size)  # Media 115, deviazione standard 10\n",
    "\n",
    "# Calcoliamo il test t\n",
    "t_stat, p_value = stats.ttest_ind(placebo_group, treatment_group)\n",
    "\n",
    "# Definiamo il livello di significatività\n",
    "alpha = 0.05\n",
    "\n",
    "# Interpretazione del risultato\n",
    "test_result = \"Reject H0\" if p_value < alpha else \"Failed to reject H0\"\n",
    "print(test_result)\n",
    "\n",
    "# Visualizziamo la distribuzione t con le regioni critiche\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf = stats.t.pdf(x, df=len(placebo_group) + len(treatment_group) - 2)\n",
    "\n",
    "# Valori critici per il test a due code\n",
    "t_critical_two_tailed = stats.t.ppf(1 - alpha / 2, df=len(placebo_group) + len(treatment_group) - 2)\n",
    "\n",
    "# Grafico\n",
    "plt.plot(x, pdf, label=\"t-Distribution\", color=\"blue\")\n",
    "plt.fill_between(x, pdf, where=(x <= -t_critical_two_tailed) | (x >= t_critical_two_tailed),\n",
    "                 color=\"red\", alpha=0.5, label=\"Rejection Region\")\n",
    "plt.axvline(-t_critical_two_tailed, color=\"red\", linestyle=\"--\", label=f\"Critical Value (-{t_critical_two_tailed:.2f})\")\n",
    "plt.axvline(t_critical_two_tailed, color=\"red\", linestyle=\"--\", label=f\"Critical Value (+{t_critical_two_tailed:.2f})\")\n",
    "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"Test Statistic ({t_stat:.2f})\")\n",
    "plt.title(\"Two-Tailed Test (H₀: No BP Difference)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "## Interpretazione dei risultati\n",
    "Dopo aver eseguito il codice, otteniamo:\n",
    "1. **Valore di t-statistic**: misura la distanza tra le due medie rispetto alla variabilità dei dati.\n",
    "2. **p-value**: indica la probabilità di ottenere un risultato uguale o più estremo sotto l'ipotesi nulla.\n",
    "3. **Decisione**:\n",
    "   - Se \\($p < \\alpha$\\), rifiutiamo H₀ (evidenza a favore dell'effetto del trattamento).\n",
    "   - Se \\($p \\geq \\alpha$\\), non possiamo rifiutare H₀ (non abbiamo abbastanza evidenza per affermare che il trattamento abbia effetto).\n",
    "\n",
    "Nel nostro esempio, il test potrebbe concludere con **\"Failed to reject H0\"**, suggerendo che non ci sia abbastanza evidenza per affermare che il trattamento abbia un effetto significativo sulla pressione sanguigna.\n",
    "\n",
    "---\n",
    "## Conclusione\n",
    "Il **t-test** è uno strumento potente per confrontare le medie di due gruppi indipendenti. Tuttavia, bisogna assicurarsi che le sue **assunzioni** siano soddisfatte:\n",
    "- **Normalità**: i dati devono seguire una distribuzione normale (verificabile con un test di Shapiro-Wilk o un grafico Q-Q).\n",
    "- **Omogeneità delle varianze**: le varianze dei due gruppi dovrebbero essere simili (verificabile con il test di Levene o Bartlett).\n",
    "\n",
    "Se queste condizioni non sono rispettate, si possono usare test alternativi come il **test di Mann-Whitney U** o test di permutazione.\n",
    "\n",
    "Questa lezione offre una panoramica dettagliata del t-test e della sua implementazione in Python, utile per chiunque voglia approfondire l'analisi statistica nei dati biomedici e farmaceutici.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0df491-ec2b-4816-96dd-737f55163ea4",
   "metadata": {},
   "source": [
    "**Test di Ipotesi**\n",
    "\n",
    "Il test di ipotesi è un concetto fondamentale in statistica che aiuta a determinare se ci sono prove sufficienti in un campione per inferire una particolare condizione su una popolazione. Esistono numerosi tipi di test di significatività, a seconda del tipo di dati, del numero di campioni e di cosa si sta misurando.\n",
    "\n",
    "Uno dei test più comuni è il **t-test**, utilizzato per confrontare due set di dati numerici.\n",
    "\n",
    "### **Esempio: t-test per l'analisi della pressione sanguigna**\n",
    "\n",
    "Supponiamo che stiamo testando un nuovo trattamento per vedere se ha un effetto sulla pressione sanguigna. Le nostre ipotesi nulla e alternativa sono:\n",
    "\n",
    "- **H₀ (Ipotesi Nulla):** Il trattamento non ha effetto sulla pressione sanguigna.\n",
    "- **H₁ (Ipotesi Alternativa):** Il trattamento ha effetto sulla pressione sanguigna.\n",
    "\n",
    "#### **Generazione dei Dati del Campione**\n",
    "```python\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dimensione_campione = 50\n",
    "gruppo_placebo = np.random.normal(loc=120, scale=10, size=dimensione_campione)\n",
    "gruppo_trattamento = np.random.normal(loc=115, scale=10, size=dimensione_campione)\n",
    "```\n",
    "\n",
    "#### **Esecuzione del t-test Indipendente**\n",
    "```python\n",
    "t_stat, p_value = stats.ttest_ind(gruppo_placebo, gruppo_trattamento)\n",
    "```\n",
    "\n",
    "#### **Decisione (Test a Due Code)**\n",
    "```python\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Rifiutiamo H₀\")\n",
    "else:\n",
    "    print(\"Non possiamo rifiutare H₀\")\n",
    "```\n",
    "\n",
    "#### **Visualizzazione della distribuzione t**\n",
    "```python\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "pdf = stats.t.pdf(x, df=len(gruppo_placebo) + len(gruppo_trattamento) - 2)\n",
    "\n",
    "t_critico_due_code = stats.t.ppf(1 - alpha / 2, df=len(gruppo_placebo) + len(gruppo_trattamento) - 2)\n",
    "\n",
    "plt.plot(x, pdf, label=\"Distribuzione t\", color=\"blue\")\n",
    "plt.fill_between(x, pdf, where=(x <= -t_critico_due_code) | (x >= t_critico_due_code),\n",
    "                 color=\"red\", alpha=0.5, label=\"Zona di Rifiuto\")\n",
    "plt.axvline(-t_critico_due_code, color=\"red\", linestyle=\"--\", label=f\"Valore Critico (-{t_critico_due_code:.2f})\")\n",
    "plt.axvline(t_critico_due_code, color=\"red\", linestyle=\"--\", label=f\"Valore Critico (+{t_critico_due_code:.2f})\")\n",
    "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"Statistica del Test ({t_stat:.2f})\")\n",
    "plt.title(\"Test a Due Code (H₀: Nessuna Differenza BP)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Interpretazione:** Se la statistica del test cade nella zona di rifiuto (in rosso), rifiutiamo H₀; altrimenti, non possiamo rifiutarla.\n",
    "\n",
    "---\n",
    "\n",
    "### **t-test a Una Coda**\n",
    "Se vogliamo testare se il trattamento **abbassa** la pressione sanguigna (non solo se ha effetto in qualche modo), eseguiamo un **test a una coda**:\n",
    "\n",
    "```python\n",
    "p_value_una_coda = p_value / 2\n",
    "\n",
    "if p_value_una_coda < alpha:\n",
    "    print(\"Rifiutiamo H₀\")\n",
    "else:\n",
    "    print(\"Non possiamo rifiutare H₀\")\n",
    "```\n",
    "\n",
    "#### **Visualizzazione del Test a Una Coda**\n",
    "```python\n",
    "t_critico_una_coda = stats.t.ppf(1 - alpha, df=len(gruppo_placebo) + len(gruppo_trattamento) - 2)\n",
    "\n",
    "plt.plot(x, pdf, label=\"Distribuzione t\", color=\"blue\")\n",
    "plt.fill_between(x, pdf, where=(x <= -t_critico_una_coda), color=\"red\", alpha=0.5, label=\"Zona di Rifiuto\")\n",
    "plt.axvline(-t_critico_una_coda, color=\"red\", linestyle=\"--\", label=f\"Valore Critico ({-t_critico_una_coda:.2f})\")\n",
    "plt.axvline(t_stat, color=\"green\", linestyle=\"--\", label=f\"Statistica del Test ({t_stat:.2f})\")\n",
    "plt.title(\"Test a Una Coda (H₀: BP Non Inferiore)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Errore di Tipo I e Tipo II**\n",
    "- **Errore di Tipo I (Falso Positivo):** Rifiutare erroneamente un'ipotesi nulla vera.\n",
    "- **Errore di Tipo II (Falso Negativo):** Non rifiutare un'ipotesi nulla falsa.\n",
    "- **Potenza del Test:** La probabilità di rifiutare correttamente H₀ quando H₁ è vera.\n",
    "\n",
    "#### **Analisi della Potenza per il t-test**\n",
    "```python\n",
    "import statsmodels.stats.power as smp\n",
    "\n",
    "dimensione_effetto = 0.5  # Dimensione dell'effetto media\n",
    "potenza = 0.8\n",
    "\n",
    "dimensione_campione = smp.tt_ind_solve_power(effect_size=dimensione_effetto, alpha=alpha, power=potenza, alternative='two-sided')\n",
    "dimensione_campione_una_coda = smp.tt_ind_solve_power(effect_size=dimensione_effetto, alpha=alpha, power=potenza, alternative='larger')\n",
    "\n",
    "print(f\"Dimensione del campione richiesta per una potenza dell'80%: {dimensione_campione:.0f}\")\n",
    "print(f\"Dimensione del campione richiesta per una potenza dell'80% nel caso a una coda: {dimensione_campione_una_coda:.0f}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **ANOVA (Analisi della Varianza)**\n",
    "Per confrontare più di due gruppi, utilizziamo **ANOVA**, basato sulla **statistica F**.\n",
    "\n",
    "```python\n",
    "np.random.seed(42)\n",
    "\n",
    "dieta_1 = np.random.normal(loc=5, scale=2, size=30)\n",
    "dieta_2 = np.random.normal(loc=6, scale=2, size=30)\n",
    "dieta_3 = np.random.normal(loc=7, scale=2, size=30)\n",
    "\n",
    "f_stat, p_value_anova = stats.f_oneway(dieta_1, dieta_2, dieta_3)\n",
    "\n",
    "print(f\"Statistica F ANOVA: {f_stat:.3f}, p-value: {p_value_anova:.3f}\")\n",
    "```\n",
    "\n",
    "Se il p-value è inferiore a 0.05, rifiutiamo H₀ e concludiamo che almeno una media di gruppo è significativamente diversa.\n",
    "\n",
    "---\n",
    "\n",
    "### **Test Chi-Square per Dati Categoriali**\n",
    "Per i dati categoriali, utilizziamo il **test chi-quadrato** per verificare se c'è un'associazione tra variabili.\n",
    "\n",
    "```python\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "osservato = np.array([[50, 30],\n",
    "                      [20, 60]])\n",
    "\n",
    "chi2, p_value, _, _ = chi2_contingency(osservato)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Rifiutiamo H₀: C'è un'associazione significativa tra genere e preferenza di voto.\")\n",
    "else:\n",
    "    print(\"Non possiamo rifiutare H₀: Nessuna associazione significativa rilevata.\")\n",
    "```\n",
    "\n",
    "Se il p-value è maggiore di 0.05, **non rifiutiamo** H₀, il che significa che non c'è una relazione significativa tra le due variabili."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d841867f-b1a3-4ffa-a586-1bd466561f62",
   "metadata": {},
   "source": [
    "### Correlazione Lineare vs Monotonica\n",
    "\n",
    "1. **Introduzione alla Correlazione**  \n",
    "La correlazione è una misura statistica che descrive la forza e la direzione della relazione tra due variabili. È un concetto fondamentale nell'analisi dei dati, poiché consente di comprendere come due variabili si influenzano reciprocamente.\n",
    "\n",
    "Esistono diversi tipi di correlazione, ma i più comuni sono la correlazione lineare e la correlazione monotona. Questi due tipi di correlazione vengono utilizzati in contesti diversi e hanno applicazioni specifiche.\n",
    "\n",
    "2. **Correlazione Lineare**  \n",
    "La correlazione lineare è una relazione tra due variabili che segue una retta. In altre parole, quando due variabili sono correlate linearmente, il cambiamento in una variabile è associato a un cambiamento costante nell'altra variabile. Ad esempio, se una variabile aumenta, anche l'altra aumenterà (o diminuirà) in modo prevedibile.\n",
    "\n",
    "Il coefficiente di correlazione di Pearson è la misura più comune per calcolare la correlazione lineare. Esso assume valori compresi tra -1 e +1:\n",
    "\n",
    "- **+1**: correlazione positiva perfetta (le variabili aumentano insieme in modo proporzionale).\n",
    "- **-1**: correlazione negativa perfetta (una variabile aumenta mentre l'altra diminuisce in modo proporzionale).\n",
    "- **0**: nessuna correlazione lineare.\n",
    "\n",
    "Matematicamente, il coefficiente di Pearson è definito come:\n",
    "\n",
    "\\[$\n",
    "r = \\frac{n \\sum{x y} - \\left( \\sum{x} \\right) \\left( \\sum{y} \\right)}{\\sqrt{n \\sum{x^2} - \\left( \\sum{x} \\right)^2} \\cdot \\sqrt{n \\sum{y^2} - \\left( \\sum{y} \\right)^2}}\n",
    "$\\]\n",
    "\n",
    "3. **Correlazione Monotona**  \n",
    "La correlazione monotona indica una relazione tra due variabili in cui una variabile tende a crescere o decrescere in modo coerente con l'altra, ma non necessariamente in modo lineare. La funzione che lega le due variabili può essere crescente o decrescente, ma la velocità di cambiamento può non essere costante, come avviene nella correlazione lineare.\n",
    "\n",
    "Il coefficiente di correlazione di Spearman è utilizzato per misurare la correlazione monotona. La correlazione di Spearman si basa sui ranghi (o posizioni) delle variabili, piuttosto che sui loro valori reali. Anche in questo caso, i valori del coefficiente vanno da -1 a +1:\n",
    "\n",
    "- **+1**: relazione monotona crescente perfetta.\n",
    "- **-1**: relazione monotona decrescente perfetta.\n",
    "- **0**: nessuna correlazione monotona.\n",
    "\n",
    "4. **Differenze tra Correlazione Lineare e Monotona**\n",
    "\n",
    "- **Linearità**: La correlazione lineare implica che la relazione tra le variabili sia una retta, mentre la correlazione monotona non richiede una relazione retta.\n",
    "- **Tipo di relazione**: La correlazione lineare misura la relazione in cui il cambiamento di una variabile corrisponde a un cambiamento costante nell'altra variabile. La correlazione monotona, invece, non richiede questa costanza nel cambiamento, ma solo che l'ordine delle variabili sia coerente.\n",
    "- **Resistenza ai valori anomali (outliers)**: La correlazione di Pearson è più sensibile agli outliers rispetto alla correlazione di Spearman. Se ci sono dati anomali che deviano la relazione lineare, il coefficiente di Pearson potrebbe non essere un buon indicatore, mentre il coefficiente di Spearman può essere più robusto.\n",
    "\n",
    "5. **Esempio Pratico con Codice Python**  \n",
    "Nel codice seguente, esploreremo un esempio di dati con una relazione monotona ma non lineare tra due variabili. I dati seguiranno una funzione esponenziale, ma con l'aggiunta di rumore casuale per simulare un comportamento più realistico.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Creiamo un dataset con una relazione monotona ma non lineare\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.exp(x) + np.random.normal(0, 50, size=len(x))  # Relazione esponenziale con rumore\n",
    "\n",
    "# Calcoliamo i coefficienti di Pearson e Spearman\n",
    "pearson_coeff, _ = pearsonr(x, y)\n",
    "spearman_coeff, _ = spearmanr(x, y)\n",
    "\n",
    "# Creiamo il grafico dei dati\n",
    "plt.scatter(x, y, label=f'Pearson Coefficient: {pearson_coeff:.2f}, Spearman Coefficient: {spearman_coeff:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "5.1 **Descrizione del Codice**\n",
    "\n",
    "- **Generazione dei Dati**: In questo esempio, abbiamo creato una variabile `x` che va da 0 a 10 e una variabile `y` che segue una relazione esponenziale con `x`, aggiungendo un po' di rumore casuale per rendere il modello più realistico.\n",
    "- **Calcolo dei Coefficienti di Correlazione**:\n",
    "  - Il coefficiente di Pearson è calcolato con `pearsonr(x, y)`, che restituisce una misura di quanto la relazione tra `x` e `y` sia lineare.\n",
    "  - Il coefficiente di Spearman è calcolato con `spearmanr(x, y)`, che misura la forza della relazione monotona tra `x` e `y`, anche se non è lineare.\n",
    "- **Visualizzazione dei Dati**: Abbiamo visualizzato i dati tramite un grafico a dispersione (scatter plot) per esaminare la relazione tra `x` e `y`.\n",
    "\n",
    "5.2 **Interpretazione del Grafico**\n",
    "\n",
    "Nel grafico, possiamo osservare come i punti siano distribuiti lungo una curva crescente, ma non seguano una retta. Questo suggerisce una relazione monotona crescente, ma non lineare.\n",
    "\n",
    "- **Coefficiente di Pearson**: Il coefficiente di Pearson potrebbe essere relativamente basso (approssimativamente vicino a 0) poiché la relazione non è lineare.\n",
    "- **Coefficiente di Spearman**: Il coefficiente di Spearman sarà invece più alto, indicando che, anche se la relazione non è lineare, le variabili tendono a seguire un ordine crescente coerente.\n",
    "\n",
    "6. **Conclusione**  \n",
    "La correlazione lineare è adatta per dati che mostrano una relazione diretta e proporzionale, mentre la correlazione monotona è utile per misurare relazioni che non sono lineari, ma che comunque seguono un comportamento monotono (ovvero, un aumento o una diminuzione costante).  \n",
    "La correlazione di Pearson è più adatta per dati lineari, mentre la correlazione di Spearman è più robusta e utile per dati con una relazione monotona non lineare.  \n",
    "In conclusione, scegliere tra Pearson e Spearman dipende dalla natura dei dati che si stanno analizzando e dal tipo di relazione che si ipotizza tra le variabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3234-0313-4764-9c57-ed5dfe59858f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
